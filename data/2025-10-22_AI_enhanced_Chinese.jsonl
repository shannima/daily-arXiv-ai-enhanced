{"id": "2510.17902", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17902", "abs": "https://arxiv.org/abs/2510.17902", "authors": ["Al Kari"], "title": "Activation Manifold Projection: Liberating Task-Specific Behaviors from LLM Architectures", "comment": null, "summary": "The proliferation of Large Language Model (LLM) architectures presents a\nfundamental challenge: valuable, task-specific behaviors learned through\nfine-tuning methods like Low-Rank Adaptation (LoRA) are effectively trapped\nwithin their source model's architecture, herein referred to architectural\nlock-in. Existing transfer methods attempt to bridge this gap by aligning the\nstatic weight spaces of models, a brittle and indirect approach that relies on\ntenuous correlations between parameter geometries. This paper introduces a\nfundamentally different and more direct paradigm: the Cartridge Activation\nSpace Transfer (CAST), a novel framework that liberates LoRA-encoded behaviors\nby learning a direct, nonlinear mapping between the activation manifolds, the\ngeometric structures formed by the model's internal neuron activations, of two\ndistinct LLM architectures. CAST treats a pre-trained LoRA as a frozen\n\"behavioral kernel.\" It learns a set of lightweight, bidirectional projection\nheads that translate the target model's activation stream into the source\nmodel's latent space, apply the frozen kernel, and project the result back.\nThis process, trained on a general text corpus without any task-specific data,\neffectively decouples the learned skill from the source architecture. We\ndemonstrate that CAST enables true \"zero-shot\" translation of any standard LoRA\nadapter. Our experiments, including transfers between heterogeneous model\nfamilies like Llama-2 and Mistral, show that CAST-translated adapters achieve\n85-95\\% of the performance of a LoRA fully retrained on the target model,\nquantitatively outperforming current weight-space transfer techniques and\nestablishing a new state-of-the-art in model interoperability.", "AI": {"tldr": "CAST\u6846\u67b6\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u6620\u5c04\u5b9e\u73b0LoRA\u9002\u914d\u5668\u7684\u8de8\u67b6\u6784\u8fc1\u79fb\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u67b6\u6784\u9501\u5b9a\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6743\u91cd\u7a7a\u95f4\u5bf9\u9f50\u7684\u8fc1\u79fb\u65b9\u6cd5\u8106\u5f31\u4e14\u95f4\u63a5\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u4e0d\u540cLLM\u67b6\u6784\u95f4LoRA\u9002\u914d\u5668\u7684\u8fc1\u79fb\u95ee\u9898\u3002", "method": "\u5b66\u4e60\u8f7b\u91cf\u7ea7\u53cc\u5411\u6295\u5f71\u5934\uff0c\u5728\u6fc0\u6d3b\u6d41\u5c42\u9762\u8fdb\u884c\u975e\u7ebf\u6027\u6620\u5c04\uff0c\u5c06\u76ee\u6807\u6a21\u578b\u6fc0\u6d3b\u8f6c\u6362\u4e3a\u6e90\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e94\u7528\u51bb\u7ed3\u7684\u884c\u4e3a\u6838\uff0c\u518d\u6295\u5f71\u56de\u76ee\u6807\u6a21\u578b\u3002", "result": "\u5728Llama-2\u548cMistral\u7b49\u5f02\u6784\u6a21\u578b\u95f4\u8fc1\u79fbLoRA\u9002\u914d\u5668\uff0c\u6027\u80fd\u8fbe\u5230\u76ee\u6807\u6a21\u578b\u4e0a\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3LoRA\u768485-95%\uff0c\u4f18\u4e8e\u73b0\u6709\u6743\u91cd\u7a7a\u95f4\u8fc1\u79fb\u6280\u672f\u3002", "conclusion": "CAST\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u96f6\u6837\u672cLoRA\u9002\u914d\u5668\u8fc1\u79fb\uff0c\u4e3a\u6a21\u578b\u4e92\u64cd\u4f5c\u6027\u5efa\u7acb\u4e86\u65b0\u7684\u6280\u672f\u6807\u51c6\u3002"}}
{"id": "2510.17940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17940", "abs": "https://arxiv.org/abs/2510.17940", "authors": ["Zhiming Lin"], "title": "Beyond More Context: Retrieval Diversity Boosts Multi-Turn Intent Understanding", "comment": "15 pages,6 figs", "summary": "Multi turn intent understanding is central to task oriented chatbots, yet\nreal deployments face tight token budgets and noisy contexts, and most\nretrieval pipelines emphasize relevance while overlooking set level diversity\nand confounds such as more context or exemplar order. We ask whether retrieval\ndiversity, rather than longer prompts, systematically improves LLM intent\nunderstanding under fixed budgets. We present a diversity aware retrieval\nframework that selects in context exemplars to balance intent coverage and\nlinguistic variety, and integrates this selection with standard LLM decoders;\nthe evaluation enforces budget matched prompts and randomized positions, and\nincludes sensitivity analyses over exemplar count, diversity strength, and\nbackbone size. On MultiWOZ 2.4 and SGD, the approach achieves strong gains in\nJoint Goal Accuracy under equal token budgets, surpassing strong LLM/DST\nbaselines, with consistent improvements across K from 4 to 7 and moderate\nlatency. Overall, the study isolates and validates the impact of content\ndiversity in retrieval and offers a simple, deployable selection principle for\nbuilding accurate, budget constrained multi turn intent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6837\u6027\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff0c\u5728\u56fa\u5b9atoken\u9884\u7b97\u4e0b\u901a\u8fc7\u9009\u62e9\u8986\u76d6\u610f\u56fe\u591a\u6837\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u7684\u793a\u4f8b\u6765\u63d0\u5347LLM\u7684\u591a\u8f6e\u610f\u56fe\u7406\u89e3\u6027\u80fd\uff0c\u5728MultiWOZ 2.4\u548cSGD\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4efb\u52a1\u578b\u804a\u5929\u673a\u5668\u4eba\u7684\u591a\u8f6e\u610f\u56fe\u7406\u89e3\u9762\u4e34token\u9884\u7b97\u9650\u5236\u548c\u566a\u58f0\u4e0a\u4e0b\u6587\u95ee\u9898\uff0c\u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u8fc7\u4e8e\u5173\u6ce8\u76f8\u5173\u6027\u800c\u5ffd\u7565\u4e86\u96c6\u5408\u5c42\u9762\u7684\u591a\u6837\u6027\u548c\u6df7\u6742\u56e0\u7d20\uff08\u5982\u4e0a\u4e0b\u6587\u957f\u5ea6\u3001\u793a\u4f8b\u987a\u5e8f\uff09\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u6837\u6027\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff0c\u9009\u62e9\u4e0a\u4e0b\u6587\u793a\u4f8b\u65f6\u5e73\u8861\u610f\u56fe\u8986\u76d6\u548c\u8bed\u8a00\u591a\u6837\u6027\uff0c\u5e76\u4e0e\u6807\u51c6LLM\u89e3\u7801\u5668\u96c6\u6210\uff1b\u8bc4\u4f30\u65f6\u5f3a\u5236\u6267\u884c\u9884\u7b97\u5339\u914d\u63d0\u793a\u548c\u968f\u673a\u4f4d\u7f6e\uff0c\u5e76\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u5728MultiWOZ 2.4\u548cSGD\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540ctoken\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86Joint Goal Accuracy\u7684\u663e\u8457\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u5f3aLLM/DST\u57fa\u7ebf\uff0c\u5728K=4\u52307\u8303\u56f4\u5185\u8868\u73b0\u4e00\u81f4\uff0c\u5ef6\u8fdf\u9002\u4e2d\u3002", "conclusion": "\u7814\u7a76\u5206\u79bb\u5e76\u9a8c\u8bc1\u4e86\u68c0\u7d22\u4e2d\u5185\u5bb9\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u6784\u5efa\u51c6\u786e\u3001\u9884\u7b97\u53d7\u9650\u7684\u591a\u8f6e\u610f\u56fe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u53ef\u90e8\u7f72\u7684\u9009\u62e9\u539f\u5219\u3002"}}
{"id": "2510.17995", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17995", "abs": "https://arxiv.org/abs/2510.17995", "authors": ["Abhigya Verma", "Seganrasan Subramanian", "Nandhakumar Kandasamy", "Naman Gupta"], "title": "FABRIC: Framework for Agent-Based Realistic Intelligence Creation", "comment": "51 Pages, 38 Listings, 5 Figures", "summary": "Large language models (LLMs) are increasingly deployed as agents, expected to\ndecompose goals, invoke tools, and verify results in dynamic environments.\nRealizing these capabilities requires access to agentic data- structured\ninteraction records that couple user intents with tool specifications,\nargument-grounded calls, and verifiable execution traces. However, collecting\nsuch data from human annotators is costly, time-consuming, and difficult to\nscale.\n  We present a unified framework for synthesizing agentic data using only LLMs,\nwithout any human-in-the-loop supervision. This framework decomposes generation\ninto modular pipelines that produce complete interaction records spanning task\nspecifications, tool definitions, policy pseudocode, natural language\nexchanges, and execution traces. Records conform to strict syntactic and\nsemantic constraints, ensuring machine-parseability and faithful alignment\nacross inputs, outputs, and tool calls.\n  Beyond single tasks, there is support for both multi-task and multi-turn\nagent interactions, enabling the construction of datasets that reflect the full\nspectrum of tool-use competencies. To ensure quality and consistency, the\nframework integrates constrained generation formats, JSON-schema validation,\nand judge-based filtering.\n  This paper formalizes the schema for agentic records, details the prompt\ndesign principles that guide generation, and introduces scalable pipelines for\nhigh-quality synthetic data. By providing a reproducible, LLM-only alternative\nto manual collection, hence advancing the development of agentic LLMs capable\nof robust tool use.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ec5\u4f7f\u7528LLM\u5408\u6210\u667a\u80fd\u4f53\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u5373\u53ef\u751f\u6210\u5305\u542b\u4efb\u52a1\u89c4\u8303\u3001\u5de5\u5177\u5b9a\u4e49\u3001\u7b56\u7565\u4f2a\u4ee3\u7801\u3001\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u6267\u884c\u8f68\u8ff9\u7684\u5b8c\u6574\u4ea4\u4e92\u8bb0\u5f55\u3002", "motivation": "\u6536\u96c6\u667a\u80fd\u4f53\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u751f\u6210\u7ed3\u6784\u5316\u4ea4\u4e92\u8bb0\u5f55\u4ee5\u652f\u6301\u667a\u80fd\u4f53LLM\u7684\u5f00\u53d1\u3002", "method": "\u4f7f\u7528\u6a21\u5757\u5316\u6d41\u6c34\u7ebf\u751f\u6210\u7b26\u5408\u4e25\u683c\u8bed\u6cd5\u548c\u8bed\u4e49\u7ea6\u675f\u7684\u4ea4\u4e92\u8bb0\u5f55\uff0c\u652f\u6301\u591a\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\uff0c\u96c6\u6210\u7ea6\u675f\u751f\u6210\u683c\u5f0f\u3001JSON\u6a21\u5f0f\u9a8c\u8bc1\u548c\u57fa\u4e8e\u8bc4\u5224\u5668\u7684\u8fc7\u6ee4\u3002", "result": "\u6846\u67b6\u80fd\u591f\u751f\u6210\u673a\u5668\u53ef\u89e3\u6790\u4e14\u5fe0\u5b9e\u5bf9\u9f50\u8f93\u5165\u3001\u8f93\u51fa\u548c\u5de5\u5177\u8c03\u7528\u7684\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\uff0c\u652f\u6301\u6784\u5efa\u53cd\u6620\u5b8c\u6574\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u624b\u52a8\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u91cd\u73b0\u7684LLM\u66ff\u4ee3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u80fd\u591f\u8fdb\u884c\u7a33\u5065\u5de5\u5177\u4f7f\u7528\u7684\u667a\u80fd\u4f53LLM\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.18032", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.18032", "abs": "https://arxiv.org/abs/2510.18032", "authors": ["Zhenyu Bi", "Meng Lu", "Yang Li", "Swastik Roy", "Weijie Guan", "Morteza Ziyadi", "Xuan Wang"], "title": "OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning", "comment": "8 pages for main content", "summary": "Large Language Models (LLMs) have shown remarkable reasoning capabilities in\nmathematical and scientific tasks. To enhance complex reasoning, multi-agent\nsystems have been proposed to harness the collective intelligence of LLM\nagents. However, existing collaboration structures are either predefined or\nrely on majority voting or round-table debates, which can suppress correct but\nless dominant agent contributions. Recent approaches model multi-agent systems\nas graph networks but optimize purely for agent performance, neglecting the\nquality of interactions. We hypothesize that effective agent communication is\ncrucial for multi-agent reasoning and that debating quality plays a significant\nrole. To address this, we propose $\\ours$, a multi-agent verbal reinforcement\nlearning algorithm that dynamically constructs and refines multi-agent\ncollaboration structures. Our method defines action spaces and a feedback\nmechanism that evaluates communication robustness and coherence throughout the\ndebate. The final decision is achieved through a majority vote over all the\nagents. We assess $\\ours$ on various reasoning tasks, including mathematical\nreasoning, creative writing, scientific reasoning, and numerical sorting.\nResults demonstrate that our approach significantly outperforms single-agent\nprompting methods and state-of-the-art multi-agent frameworks on diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u548c\u4f18\u5316\u534f\u4f5c\u7ed3\u6784\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8981\u4e48\u91c7\u7528\u9884\u5b9a\u4e49\u7ed3\u6784\uff0c\u8981\u4e48\u4f9d\u8d56\u591a\u6570\u6295\u7968\u6216\u5706\u684c\u8fa9\u8bba\uff0c\u8fd9\u4f1a\u538b\u5236\u6b63\u786e\u4f46\u975e\u4e3b\u5bfc\u7684\u667a\u80fd\u4f53\u8d21\u732e\u3002\u73b0\u6709\u56fe\u7f51\u7edc\u65b9\u6cd5\u53ea\u4f18\u5316\u667a\u80fd\u4f53\u6027\u80fd\u800c\u5ffd\u89c6\u4ea4\u4e92\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9a\u4e49\u52a8\u4f5c\u7a7a\u95f4\u548c\u53cd\u9988\u673a\u5236\u6765\u8bc4\u4f30\u6c9f\u901a\u7684\u9c81\u68d2\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u901a\u8fc7\u591a\u6570\u6295\u7968\u8fbe\u6210\u6700\u7ec8\u51b3\u7b56\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u521b\u610f\u5199\u4f5c\u3001\u79d1\u5b66\u63a8\u7406\u548c\u6570\u503c\u6392\u5e8f\u7b49\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u63d0\u793a\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "conclusion": "\u6709\u6548\u7684\u667a\u80fd\u4f53\u6c9f\u901a\u5bf9\u591a\u667a\u80fd\u4f53\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0c\u8fa9\u8bba\u8d28\u91cf\u5728\u5176\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u52a8\u6001\u4f18\u5316\u7684\u534f\u4f5c\u7ed3\u6784\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2510.18040", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.18040", "abs": "https://arxiv.org/abs/2510.18040", "authors": ["Alexander Boldachev"], "title": "Subject-Event Ontology Without Global Time: Foundations and Execution Semantics", "comment": "32 pages", "summary": "A formalization of a subject-event ontology is proposed for modeling complex\ndynamic systems without reliance on global time. Key principles: (1) event as\nan act of fixation - a subject discerns and fixes changes according to models\n(conceptual templates) available to them; (2) causal order via happens-before -\nthe order of events is defined by explicit dependencies, not timestamps; (3)\nmaking the ontology executable via a declarative dataflow mechanism, ensuring\ndeterminism; (4) models as epistemic filters - a subject can only fix what\nfalls under its known concepts and properties; (5) presumption of truth - the\ndeclarative content of an event is available for computation from the moment of\nfixation, without external verification. The formalization includes nine axioms\n(A1-A9), ensuring the correctness of executable ontologies: monotonicity of\nhistory (I1), acyclicity of causality (I2), traceability (I3). Special\nattention is given to the model-based approach (A9): event validation via\nschemas, actor authorization, automatic construction of causal chains (W3)\nwithout global time. Practical applicability is demonstrated on the boldsea\nsystem - a workflow engine for executable ontologies, where the theoretical\nconstructs are implemented in BSL (Boldsea Semantic Language). The\nformalization is applicable to distributed systems, microservice architectures,\nDLT platforms, and multiperspectivity scenarios (conflicting facts from\ndifferent subjects).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u4f53-\u4e8b\u4ef6\u7684\u672c\u4f53\u8bba\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\uff0c\u4e0d\u4f9d\u8d56\u5168\u5c40\u65f6\u95f4\u3002\u6838\u5fc3\u539f\u5219\u5305\u62ec\u4e8b\u4ef6\u4f5c\u4e3a\u56fa\u5b9a\u884c\u4e3a\u3001\u56e0\u679c\u987a\u5e8f\u901a\u8fc7happens-before\u5b9a\u4e49\u3001\u53ef\u6267\u884c\u672c\u4f53\u8bba\u3001\u6a21\u578b\u4f5c\u4e3a\u8ba4\u77e5\u8fc7\u6ee4\u5668\u3001\u4ee5\u53ca\u771f\u503c\u5047\u5b9a\u3002", "motivation": "\u4e3a\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e0d\u4f9d\u8d56\u5168\u5c40\u65f6\u95f4\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5fae\u670d\u52a1\u67b6\u6784\u3001DLT\u5e73\u53f0\u548c\u591a\u89c6\u89d2\u573a\u666f\uff0c\u89e3\u51b3\u4e0d\u540c\u4e3b\u4f53\u95f4\u4e8b\u5b9e\u51b2\u7a81\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e5d\u6761\u516c\u7406(A1-A9)\u786e\u4fdd\u53ef\u6267\u884c\u672c\u4f53\u8bba\u7684\u6b63\u786e\u6027\uff1a\u5386\u53f2\u5355\u8c03\u6027(I1)\u3001\u56e0\u679c\u65e0\u73af\u6027(I2)\u3001\u53ef\u8ffd\u6eaf\u6027(I3)\u3002\u91c7\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5(A9)\uff0c\u901a\u8fc7\u6a21\u5f0f\u8fdb\u884c\u4e8b\u4ef6\u9a8c\u8bc1\u3001\u53c2\u4e0e\u8005\u6388\u6743\uff0c\u81ea\u52a8\u6784\u5efa\u56e0\u679c\u94fe(W3)\u3002", "result": "\u5728boldsea\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u7406\u8bba\u6784\u5efa\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u53ef\u6267\u884c\u672c\u4f53\u8bba\u7684\u5de5\u4f5c\u6d41\u5f15\u64ce\uff0c\u4f7f\u7528BSL\u8bed\u8a00\u5b9e\u73b0\u3002\u5c55\u793a\u4e86\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5fae\u670d\u52a1\u67b6\u6784\u7b49\u573a\u666f\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e3a\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u7279\u522b\u5728\u4e0d\u4f9d\u8d56\u5168\u5c40\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u591a\u4e3b\u4f53\u89c6\u89d2\u548c\u56e0\u679c\u5173\u7cfb\u7684\u6311\u6218\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.18043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18043", "abs": "https://arxiv.org/abs/2510.18043", "authors": ["Joong Ho Choi", "Jiayang Zhao", "Jeel Shah", "Ritvika Sonawane", "Vedant Singh", "Avani Appalla", "Will Flanagan", "Filipe Condessa"], "title": "CompactPrompt: A Unified Pipeline for Prompt Data Compression in LLM Workflows", "comment": "Workshop on LLMs and Generative AI for Finance at ACM ICAIF 2025", "summary": "Large Language Models (LLMs) deliver powerful reasoning and generation\ncapabilities but incur substantial run-time costs when operating in agentic\nworkflows that chain together lengthy prompts and process rich data streams. We\nintroduce CompactPrompt, an end-to-end pipeline that merges hard prompt\ncompression with lightweight file-level data compression. CompactPrompt first\nprunes low-information tokens from prompts using self-information scoring and\ndependency-based phrase grouping. In parallel, it applies n-gram abbreviation\nto recurrent textual patterns in attached documents and uniform quantization to\nnumerical columns, yielding compact yet semantically faithful representations.\nIntegrated into standard LLM agents, CompactPrompt reduces total token usage\nand inference cost by up to 60% on benchmark dataset like TAT-QA and FinQA,\nwhile preserving output quality (Results in less than 5% accuracy drop for\nClaude-3.5-Sonnet, and GPT-4.1-Mini) CompactPrompt helps visualize real-time\ncompression decisions and quantify cost-performance trade-offs, laying the\ngroundwork for leaner generative AI pipelines.", "AI": {"tldr": "CompactPrompt\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u901a\u8fc7\u786c\u63d0\u793a\u538b\u7f29\u548c\u8f7b\u91cf\u7ea7\u6587\u4ef6\u7ea7\u6570\u636e\u538b\u7f29\u76f8\u7ed3\u5408\uff0c\u5c06LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u603b\u4ee4\u724c\u4f7f\u7528\u91cf\u548c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\uff0c\u540c\u65f6\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u8fd0\u884c\u65f6\u4f1a\u4ea7\u751f\u9ad8\u6602\u6210\u672c\uff0c\u56e0\u4e3a\u9700\u8981\u94fe\u63a5\u957f\u63d0\u793a\u548c\u5904\u7406\u4e30\u5bcc\u6570\u636e\u6d41\u3002", "method": "\u4f7f\u7528\u81ea\u4fe1\u606f\u8bc4\u5206\u548c\u57fa\u4e8e\u4f9d\u8d56\u7684\u77ed\u8bed\u5206\u7ec4\u4fee\u526a\u63d0\u793a\u4e2d\u7684\u4f4e\u4fe1\u606f\u4ee4\u724c\uff0c\u540c\u65f6\u5bf9\u9644\u52a0\u6587\u6863\u5e94\u7528n-gram\u7f29\u5199\u548c\u6570\u503c\u5217\u7684\u7edf\u4e00\u91cf\u5316\u3002", "result": "\u5728TAT-QA\u548cFinQA\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u603b\u4ee4\u724c\u4f7f\u7528\u91cf\u548c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\uff0c\u8f93\u51fa\u8d28\u91cf\u4fdd\u6301\uff08Claude-3.5-Sonnet\u548cGPT-4.1-Mini\u7684\u51c6\u786e\u7387\u4e0b\u964d\u5c0f\u4e8e5%\uff09\u3002", "conclusion": "CompactPrompt\u4e3a\u66f4\u7cbe\u7b80\u7684\u751f\u6210AI\u7ba1\u9053\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u53ef\u89c6\u5316\u5b9e\u65f6\u538b\u7f29\u51b3\u7b56\u5e76\u91cf\u5316\u6210\u672c\u6027\u80fd\u6743\u8861\u3002"}}
{"id": "2510.18087", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18087", "abs": "https://arxiv.org/abs/2510.18087", "authors": ["Daniel Israel", "Tian Jin", "Ellie Cheng", "Guy Van den Broeck", "Aditya Grover", "Suvinay Subramanian", "Michael Carbin"], "title": "Planned Diffusion", "comment": "10 pages, 8 figures", "summary": "A central challenge in large language model inference is the trade-off\nbetween generation speed and output quality. Autoregressive models produce\nhigh-quality text but generate tokens sequentially. Diffusion models can\ngenerate tokens in parallel but often need many iterations to match the same\nquality. We propose planned diffusion, a hybrid method that combines the\nstrengths of both paradigms. Planned diffusion works in two stages: first, the\nmodel creates a short autoregressive plan that breaks the output into smaller,\nindependent spans. Second, the model generates these spans simultaneously using\ndiffusion. This approach expands the speed-quality Pareto frontier and provides\na practical path to faster, high-quality text generation. On AlpacaEval, a\nsuite of 805 instruction-following prompts, planned diffusion achieves\nPareto-optimal trade-off between quality and latency, achieving 1.27x to 1.81x\nspeedup over autoregressive generation with only 0.87\\% to 5.4\\% drop in win\nrate, respectively. Our sensitivity analysis shows that the planning mechanism\nof planned diffusion is minimal and reliable, and simple runtime knobs exist to\nprovide flexible control of the quality-latency trade-off.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b\u7684\u6df7\u5408\u65b9\u6cd5\u2014\u2014\u8ba1\u5212\u6269\u6563\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u751f\u6210\u5b9e\u73b0\u66f4\u5feb\u7684\u6587\u672c\u751f\u6210\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u8f93\u51fa\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u751f\u6210\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u8d28\u91cf\u9ad8\u4f46\u901f\u5ea6\u6162\uff0c\u6269\u6563\u6a21\u578b\u53ef\u5e76\u884c\u751f\u6210\u4f46\u9700\u8981\u591a\u6b21\u8fed\u4ee3\u624d\u80fd\u8fbe\u5230\u76f8\u540c\u8d28\u91cf\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u81ea\u56de\u5f52\u5730\u521b\u5efa\u77ed\u8ba1\u5212\u5c06\u8f93\u51fa\u5206\u89e3\u4e3a\u72ec\u7acb\u7247\u6bb5\uff0c\u7136\u540e\u4f7f\u7528\u6269\u6563\u6a21\u578b\u540c\u65f6\u751f\u6210\u8fd9\u4e9b\u7247\u6bb5\u3002", "result": "\u5728AlpacaEval\u8bc4\u4f30\u4e2d\u5b9e\u73b0\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861\uff0c\u76f8\u6bd4\u81ea\u56de\u5f52\u751f\u6210\u83b7\u5f971.27x\u52301.81x\u52a0\u901f\uff0c\u80dc\u7387\u4ec5\u4e0b\u964d0.87%\u52305.4%\u3002", "conclusion": "\u8ba1\u5212\u6269\u6563\u6269\u5c55\u4e86\u901f\u5ea6-\u8d28\u91cf\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u4e3a\u66f4\u5feb\u3001\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5176\u89c4\u5212\u673a\u5236\u7b80\u6d01\u53ef\u9760\u4e14\u5177\u6709\u7075\u6d3b\u7684\u8d28\u91cf-\u5ef6\u8fdf\u6743\u8861\u63a7\u5236\u3002"}}
{"id": "2510.18095", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18095", "abs": "https://arxiv.org/abs/2510.18095", "authors": ["Nikhil Verma", "Manasa Bharadwaj", "Wonjun Jang", "Harmanpreet Singh", "Yixiao Wang", "Homa Fashandi", "Chul Lee"], "title": "SMaRT: Select, Mix, and ReinvenT - A Strategy Fusion Framework for LLM-Driven Reasoning and Planning", "comment": null, "summary": "Large Language Models (LLMs) have redefined complex task automation with\nexceptional generalization capabilities. Despite these advancements,\nstate-of-the-art methods rely on single-strategy prompting, missing the synergy\nof diverse reasoning approaches. No single strategy excels universally,\nhighlighting the need for frameworks that fuse strategies to maximize\nperformance and ensure robustness. We introduce the Select, Mix, and ReinvenT\n(SMaRT) framework, an innovative strategy fusion approach designed to overcome\nthis constraint by creating balanced and efficient solutions through the\nseamless integration of diverse reasoning strategies. Unlike existing methods,\nwhich employ LLMs merely as evaluators, SMaRT uses them as intelligent\nintegrators, unlocking the \"best of all worlds\" across tasks. Extensive\nempirical evaluations across benchmarks in reasoning, planning, and sequential\ndecision-making highlight the robustness and adaptability of SMaRT. The\nframework consistently outperforms state-of-the-art baselines in solution\nquality, constraint adherence, and performance metrics. This work redefines\nLLM-driven decision-making by pioneering a new paradigm in cross-strategy\ncalibration, unlocking superior outcomes for reasoning systems and advancing\nthe boundaries of self-refining methodologies.", "AI": {"tldr": "SMaRT\u6846\u67b6\u901a\u8fc7\u878d\u5408\u591a\u79cd\u63a8\u7406\u7b56\u7565\u6765\u63d0\u5347LLM\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u8d85\u8d8a\u5355\u4e00\u7b56\u7565\u65b9\u6cd5", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u7b56\u7565\u63d0\u793a\uff0c\u7f3a\u4e4f\u4e0d\u540c\u63a8\u7406\u65b9\u6cd5\u7684\u534f\u540c\u6548\u5e94\uff0c\u9700\u8981\u878d\u5408\u591a\u79cd\u7b56\u7565\u6765\u6700\u5927\u5316\u6027\u80fd\u548c\u786e\u4fdd\u9c81\u68d2\u6027", "method": "\u63d0\u51faSMaRT\uff08\u9009\u62e9\u3001\u6df7\u5408\u548c\u91cd\u5851\uff09\u6846\u67b6\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u667a\u80fd\u96c6\u6210\u5668\u800c\u975e\u8bc4\u4f30\u5668\uff0c\u65e0\u7f1d\u6574\u5408\u591a\u6837\u63a8\u7406\u7b56\u7565", "result": "\u5728\u63a8\u7406\u3001\u89c4\u5212\u548c\u987a\u5e8f\u51b3\u7b56\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSMaRT\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3001\u7ea6\u675f\u9075\u5faa\u548c\u6027\u80fd\u6307\u6807\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5f00\u521b\u8de8\u7b56\u7565\u6821\u51c6\u65b0\u8303\u5f0f\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86LLM\u9a71\u52a8\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u4e3a\u63a8\u7406\u7cfb\u7edf\u89e3\u9501\u4e86\u66f4\u4f18\u7ed3\u679c\u5e76\u63a8\u8fdb\u4e86\u81ea\u7cbe\u70bc\u65b9\u6cd5\u7684\u8fb9\u754c"}}
{"id": "2510.18134", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18134", "abs": "https://arxiv.org/abs/2510.18134", "authors": ["Soheil Abbasloo"], "title": "Measuring Reasoning in LLMs: a New Dialectical Angle", "comment": null, "summary": "What does it truly mean for a language model to \"reason\"? Most current\nevaluations and benchmarks reward models' correct standalone answers--but\ncorrectness alone reveals little about the process that produced them. In this\nwork, we explore a different perspective: reasoning is not a static chain of\nsteps, but a dynamic trajectory where ideas interact, clash, and evolve into\ndeeper insights. To capture this dynamic, we draw on a well-established\nphilosophical tradition: \\textit{dialectics}, where reasoning unfolds through\nthesis, antithesis, and synthesis. Building on this, we present SIEV, a\nstructured framework that evaluates reasoning of LLMs through dialectics.\nUnlike conventional evaluations, SIEV assesses not only the conclusion a model\nreaches, but how it gets there: its ability to resolve tension, integrate\ndistinct ideas, and synthesize higher-order reasoning. This lens uncovers\nsignificant reasoning gaps in state-of-the-art models even under saturated\nbenchmarks like GSM and MMLU. For instance, GPT-5-chat, a recent model, loses\nover 40 points (out of 100) when evaluated with SIEV on GSM. Our findings\nhighlight that adopting a process-oriented, philosophically grounded approach\nenables a deeper, more rigorous, and more discriminative assessment of LLM\nreasoning.", "AI": {"tldr": "\u63d0\u51faSIEV\u6846\u67b6\uff0c\u57fa\u4e8e\u8fa9\u8bc1\u6cd5\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7b54\u6848\u6b63\u786e\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7f3a\u9677", "motivation": "\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u53ea\u5173\u6ce8\u6a21\u578b\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u4f46\u65e0\u6cd5\u63ed\u793a\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\u3002\u63a8\u7406\u5e94\u8be5\u662f\u52a8\u6001\u7684\u3001\u601d\u60f3\u78b0\u649e\u548c\u8fdb\u5316\u7684\u8fc7\u7a0b", "method": "\u57fa\u4e8e\u8fa9\u8bc1\u6cd5\uff08thesis, antithesis, synthesis\uff09\u6784\u5efaSIEV\u6846\u67b6\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u89e3\u51b3\u77db\u76fe\u3001\u6574\u5408\u89c2\u70b9\u548c\u8fdb\u884c\u9ad8\u9636\u7efc\u5408\u7684\u80fd\u529b", "result": "\u5728GSM\u548cMMLU\u7b49\u9971\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGPT-5-chat\u7b49\u5148\u8fdb\u6a21\u578b\u5728SIEV\u8bc4\u4f30\u4e0b\u5f97\u5206\u4e0b\u964d\u8d85\u8fc740\u5206\uff08\u6ee1\u5206100\uff09\uff0c\u63ed\u793a\u4e86\u663e\u8457\u7684\u63a8\u7406\u7f3a\u9677", "conclusion": "\u91c7\u7528\u8fc7\u7a0b\u5bfc\u5411\u3001\u54f2\u5b66\u57fa\u7840\u7684\u65b9\u6cd5\u80fd\u591f\u5bf9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fdb\u884c\u66f4\u6df1\u5165\u3001\u4e25\u8c28\u548c\u533a\u5206\u6027\u7684\u8bc4\u4f30"}}
{"id": "2510.18143", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18143", "abs": "https://arxiv.org/abs/2510.18143", "authors": ["Huan Song", "Deeksha Razdan", "Yiyue Qian", "Arijit Ghosh Chowdhury", "Parth Patwa", "Aman Chadha", "Shinan Zhang", "Sharlina Keshava", "Hannah Marlowe"], "title": "Learning from Generalization Patterns: An Evaluation-Driven Approach to Enhanced Data Augmentation for Fine-Tuning Small Language Models", "comment": "Neural Information Processing Systems (NeurIPS 2025) Workshop:\n  Evaluating the Evolving LLM Lifecycle", "summary": "Small Language Models (SLMs) offer compelling advantages in deployment cost\nand latency, but their accuracy often lags behind larger models, particularly\nfor complex domain-specific tasks. While supervised fine-tuning can help bridge\nthis performance gap, it requires substantial manual effort in data preparation\nand iterative optimization. We present PaDA-Agent (Pattern-guided Data\nAugmentation Agent), an evaluation-driven approach that streamlines the data\naugmentation process for SLMs through coordinated operations. Unlike\nstate-of-the-art approaches that focus on model training errors only and\ngenerating error-correcting samples, PaDA-Agent discovers failure patterns from\nthe validation data via evaluations and drafts targeted data augmentation\nstrategies aiming to directly reduce the generalization gap. Our experimental\nresults demonstrate significant improvements over state-of-the-art LLM-based\ndata augmentation approaches for Llama 3.2 1B Instruct model fine-tuning.", "AI": {"tldr": "PaDA-Agent\u662f\u4e00\u79cd\u8bc4\u4f30\u9a71\u52a8\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d1\u73b0\u9a8c\u8bc1\u6570\u636e\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u6765\u5236\u5b9a\u9488\u5bf9\u6027\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u90e8\u7f72\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u590d\u6742\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u5f80\u5f80\u843d\u540e\u4e8e\u5927\u6a21\u578b\u3002\u867d\u7136\u76d1\u7763\u5fae\u8c03\u53ef\u4ee5\u5f25\u8865\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46\u9700\u8981\u5927\u91cf\u624b\u52a8\u6570\u636e\u51c6\u5907\u548c\u8fed\u4ee3\u4f18\u5316\u5de5\u4f5c\u3002", "method": "PaDA-Agent\u901a\u8fc7\u8bc4\u4f30\u53d1\u73b0\u9a8c\u8bc1\u6570\u636e\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5236\u5b9a\u9488\u5bf9\u6027\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u76f4\u63a5\u51cf\u5c11\u6cdb\u5316\u5dee\u8ddd\u3002\u4e0e\u4ec5\u5173\u6ce8\u6a21\u578b\u8bad\u7ec3\u9519\u8bef\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u5b83\u901a\u8fc7\u534f\u8c03\u64cd\u4f5c\u7b80\u5316SLM\u7684\u6570\u636e\u589e\u5f3a\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cPaDA-Agent\u5728Llama 3.2 1B Instruct\u6a21\u578b\u5fae\u8c03\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "PaDA-Agent\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bc4\u4f30\u9a71\u52a8\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u7b80\u5316\u6570\u636e\u589e\u5f3a\u8fc7\u7a0b\u3002"}}
{"id": "2510.18154", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.18154", "abs": "https://arxiv.org/abs/2510.18154", "authors": ["Antonio-Gabriel Chac\u00f3n Menke", "Phan Xuan Tan", "Eiji Kamioka"], "title": "Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety", "comment": null, "summary": "Recent work has highlighted the importance of monitoring chain-of-thought\nreasoning for AI safety; however, current approaches that analyze textual\nreasoning steps can miss subtle harmful patterns and may be circumvented by\nmodels that hide unsafe reasoning. We present a sentence-level labeled dataset\nthat enables activation-based monitoring of safety behaviors during LLM\nreasoning. Our dataset contains reasoning sequences with sentence-level\nannotations of safety behaviors such as expression of safety concerns or\nspeculation on user intent, which we use to extract steering vectors for\ndetecting and influencing these behaviors within model activations. The dataset\nfills a key gap in safety research: while existing datasets label reasoning\nholistically, effective application of steering vectors for safety monitoring\ncould be improved by identifying precisely when specific behaviors occur within\nreasoning chains. We demonstrate the dataset's utility by extracting\nrepresentations that both detect and steer safety behaviors in model\nactivations, showcasing the potential of activation-level techniques for\nimproving safety oversight on reasoning.\n  Content Warning: This paper discusses AI safety in the context of harmful\nprompts and may contain references to potentially harmful content.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53e5\u5b50\u7ea7\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u5728LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u57fa\u4e8e\u6fc0\u6d3b\u7684\u5b89\u5168\u884c\u4e3a\u76d1\u63a7\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u53ea\u80fd\u6574\u4f53\u6807\u6ce8\u63a8\u7406\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6587\u672c\u63a8\u7406\u6b65\u9aa4\u7684\u5b89\u5168\u76d1\u63a7\u65b9\u6cd5\u53ef\u80fd\u9057\u6f0f\u7ec6\u5fae\u7684\u6709\u5bb3\u6a21\u5f0f\uff0c\u4e14\u53ef\u80fd\u88ab\u9690\u85cf\u4e0d\u5b89\u5168\u63a8\u7406\u7684\u6a21\u578b\u89c4\u907f\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u6fc0\u6d3b\u7ea7\u76d1\u63a7\u6280\u672f\u3002", "method": "\u6784\u5efa\u5305\u542b\u63a8\u7406\u5e8f\u5217\u7684\u53e5\u5b50\u7ea7\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u5b89\u5168\u884c\u4e3a\uff08\u5982\u5b89\u5168\u62c5\u5fe7\u8868\u8fbe\u3001\u7528\u6237\u610f\u56fe\u63a8\u6d4b\uff09\uff0c\u5e76\u4ece\u4e2d\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u548c\u5f71\u54cd\u8fd9\u4e9b\u884c\u4e3a\u7684\u5f15\u5bfc\u5411\u91cf\u3002", "result": "\u5c55\u793a\u4e86\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\uff0c\u63d0\u53d6\u7684\u8868\u5f81\u80fd\u591f\u5728\u6a21\u578b\u6fc0\u6d3b\u4e2d\u68c0\u6d4b\u548c\u5f15\u5bfc\u5b89\u5168\u884c\u4e3a\uff0c\u8bc1\u660e\u4e86\u6fc0\u6d3b\u7ea7\u6280\u672f\u5728\u6539\u8fdb\u63a8\u7406\u5b89\u5168\u76d1\u7763\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u6fc0\u6d3b\u7ea7\u76d1\u63a7\u6280\u672f\u6709\u671b\u6539\u8fdbAI\u63a8\u7406\u5b89\u5168\u76d1\u7763\uff0c\u8be5\u6570\u636e\u96c6\u4e3a\u5b89\u5168\u7814\u7a76\u586b\u8865\u4e86\u5173\u952e\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u884c\u4e3a\u8bc6\u522b\u65b9\u6cd5\u3002"}}
{"id": "2510.18155", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.18155", "abs": "https://arxiv.org/abs/2510.18155", "authors": ["Man-Lin Chu", "Lucian Terhorst", "Kadin Reed", "Tom Ni", "Weiwei Chen", "Rongyu Lin"], "title": "LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior", "comment": "Accepted for publication at IEEE International Conference on\n  e-Business Engineering ICEBE 2025, November 10-12, Buraydah, Saudi Arabia. 8\n  pages, 5 figures", "summary": "Simulating consumer decision-making is vital for designing and evaluating\nmarketing strategies before costly real- world deployment. However, post-event\nanalyses and rule-based agent-based models (ABMs) struggle to capture the\ncomplexity of human behavior and social interaction. We introduce an\nLLM-powered multi-agent simulation framework that models consumer decisions and\nsocial dynamics. Building on recent advances in large language model simulation\nin a sandbox envi- ronment, our framework enables generative agents to\ninteract, express internal reasoning, form habits, and make purchasing\ndecisions without predefined rules. In a price-discount marketing scenario, the\nsystem delivers actionable strategy-testing outcomes and reveals emergent\nsocial patterns beyond the reach of con- ventional methods. This approach\noffers marketers a scalable, low-risk tool for pre-implementation testing,\nreducing reliance on time-intensive post-event evaluations and lowering the\nrisk of underperforming campaigns.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u6d88\u8d39\u8005\u51b3\u7b56\u548c\u793e\u4ea4\u52a8\u6001\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u89c4\u5219\u5373\u53ef\u6d4b\u8bd5\u8425\u9500\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u7684\u4e8b\u540e\u5206\u6790\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u4f53\u6a21\u578b\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\u548c\u793e\u4ea4\u4e92\u52a8\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u6a21\u62df\u5de5\u5177\u6765\u964d\u4f4e\u8425\u9500\u6d3b\u52a8\u98ce\u9669\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6c99\u76d2\u73af\u5883\u4e2d\u6784\u5efa\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u4e92\u52a8\u3001\u8868\u8fbe\u5185\u90e8\u63a8\u7406\u3001\u5f62\u6210\u4e60\u60ef\u5e76\u505a\u51fa\u8d2d\u4e70\u51b3\u7b56\u3002", "result": "\u5728\u4ef7\u683c\u6298\u6263\u8425\u9500\u573a\u666f\u4e2d\uff0c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u7b56\u7565\u6d4b\u8bd5\u7ed3\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u53d1\u73b0\u7684\u6d8c\u73b0\u793e\u4ea4\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8425\u9500\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u4f4e\u98ce\u9669\u7684\u9884\u5b9e\u65bd\u6d4b\u8bd5\u5de5\u5177\uff0c\u51cf\u5c11\u4e86\u5bf9\u8017\u65f6\u7684\u4e8b\u540e\u8bc4\u4f30\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u8425\u9500\u6d3b\u52a8\u8868\u73b0\u4e0d\u4f73\u7684\u98ce\u9669\u3002"}}
{"id": "2510.18165", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18165", "abs": "https://arxiv.org/abs/2510.18165", "authors": ["Yihong Dong", "Zhaoyu Ma", "Xue Jiang", "Zhiyuan Fan", "Jiaru Qian", "Yongmin Li", "Jianha Xiao", "Zhi Jin", "Rongyu Cao", "Binhua Li", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model", "comment": null, "summary": "Diffusion language models (DLMs) are emerging as a powerful and promising\nalternative to the dominant autoregressive paradigm, offering inherent\nadvantages in parallel generation and bidirectional context modeling. However,\nthe performance of DLMs on code generation tasks, which have stronger\nstructural constraints, is significantly hampered by the critical trade-off\nbetween inference speed and output quality. We observed that accelerating the\ncode generation process by reducing the number of sampling steps usually leads\nto a catastrophic collapse in performance. In this paper, we introduce\nefficient Sampling with Adaptive acceleration and Backtracking Enhanced\nRemasking (i.e., Saber), a novel training-free sampling algorithm for DLMs to\nachieve better inference speed and output quality in code generation.\nSpecifically, Saber is motivated by two key insights in the DLM generation\nprocess: 1) it can be adaptively accelerated as more of the code context is\nestablished; 2) it requires a backtracking mechanism to reverse the generated\ntokens. Extensive experiments on multiple mainstream code generation benchmarks\nshow that Saber boosts Pass@1 accuracy by an average improvement of 1.9% over\nmainstream DLM sampling methods, meanwhile achieving an average 251.4%\ninference speedup. By leveraging the inherent advantages of DLMs, our work\nsignificantly narrows the performance gap with autoregressive models in code\ngeneration.", "AI": {"tldr": "\u63d0\u51fa\u4e86Saber\u7b97\u6cd5\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u578b\u91c7\u6837\u65b9\u6cd5\uff0c\u7528\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u5e73\u8861\u63a8\u7406\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5b58\u5728\u63a8\u7406\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\uff0c\u51cf\u5c11\u91c7\u6837\u6b65\u9aa4\u901a\u5e38\u5bfc\u81f4\u6027\u80fd\u707e\u96be\u6027\u4e0b\u964d\u3002", "method": "Saber\u7b97\u6cd5\u57fa\u4e8e\u4e24\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a1\uff09\u968f\u7740\u4ee3\u7801\u4e0a\u4e0b\u6587\u5efa\u7acb\u53ef\u4ee5\u81ea\u9002\u5e94\u52a0\u901f\uff1b2\uff09\u9700\u8981\u56de\u6eaf\u673a\u5236\u6765\u53cd\u8f6c\u751f\u6210\u7684\u6807\u8bb0\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSaber\u6bd4\u4e3b\u6d41DLM\u91c7\u6837\u65b9\u6cd5\u5e73\u5747\u63d0\u53471.9%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u5e73\u5747251.4%\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528DLM\u7684\u56fa\u6709\u4f18\u52bf\uff0c\u8be5\u5de5\u4f5c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2510.18170", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SE", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.18170", "abs": "https://arxiv.org/abs/2510.18170", "authors": ["Manik Rana", "Calissa Man", "Anotida Expected Msiiwa", "Jeffrey Paine", "Kevin Zhu", "Sunishchal Dev", "Vasu Sharma", "Ahan M R"], "title": "AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI", "comment": "Accepted to 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: Multi-Turn Interactions in Large Language Models", "summary": "Goal changes are a defining feature of real world multi-turn interactions,\nyet current agent benchmarks primarily evaluate static objectives or one-shot\ntool use. We introduce AgentChangeBench, a benchmark explicitly designed to\nmeasure how tool augmented language model agents adapt to mid dialogue goal\nshifts across three enterprise domains. Our framework formalizes evaluation\nthrough four complementary metrics: Task Success Rate (TSR) for effectiveness,\nTool Use Efficiency (TUE) for reliability, Tool Call Redundancy Rate (TCRR) for\nwasted effort, and Goal-Shift Recovery Time (GSRT) for adaptation latency.\nAgentChangeBench comprises 2,835 task sequences and five user personas, each\ndesigned to trigger realistic shift points in ongoing workflows. Using this\nsetup, we evaluate several frontier models and uncover sharp contrasts obscured\nby traditional $\\text{pass}@k$ scores: for example, GPT-4o reaches $92.2\\%$\nrecovery on airline booking shifts while Gemini collapses to $48.6\\%$, and\nretail tasks show near perfect parameter validity yet redundancy rates above\n$80\\%$, revealing major inefficiencies. These findings demonstrate that high\nraw accuracy does not imply robustness under dynamic goals, and that explicit\nmeasurement of recovery time and redundancy is essential. AgentChangeBench\nestablishes a reproducible testbed for diagnosing and improving agent\nresilience in realistic enterprise settings.", "AI": {"tldr": "AgentChangeBench\u662f\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5de5\u5177\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5bf9\u8bdd\u4e2d\u9002\u5e94\u76ee\u6807\u53d8\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b2,835\u4e2a\u4efb\u52a1\u5e8f\u5217\u548c\u56db\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u63ed\u793a\u4e86\u9ad8\u51c6\u786e\u7387\u4e0d\u7b49\u4e8e\u52a8\u6001\u76ee\u6807\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u76ee\u6807\u53d8\u5316\u662f\u5e38\u89c1\u7279\u5f81\uff0c\u4f46\u73b0\u6709\u4ee3\u7406\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u9759\u6001\u76ee\u6807\u6216\u4e00\u6b21\u6027\u5de5\u5177\u4f7f\u7528\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u76ee\u6807\u9002\u5e94\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u6784\u5efaAgentChangeBench\u57fa\u51c6\uff0c\u5305\u542b\u4e09\u4e2a\u4f01\u4e1a\u9886\u57df\u76842,835\u4e2a\u4efb\u52a1\u5e8f\u5217\u548c\u4e94\u4e2a\u7528\u6237\u89d2\u8272\uff0c\u901a\u8fc7\u56db\u4e2a\u4e92\u8865\u6307\u6807\uff08\u4efb\u52a1\u6210\u529f\u7387\u3001\u5de5\u5177\u4f7f\u7528\u6548\u7387\u3001\u5de5\u5177\u8c03\u7528\u5197\u4f59\u7387\u3001\u76ee\u6807\u8f6c\u79fb\u6062\u590d\u65f6\u95f4\uff09\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u524d\u6cbf\u6a21\u578b\u5728\u52a8\u6001\u76ee\u6807\u9002\u5e94\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1aGPT-4o\u5728\u822a\u7a7a\u9884\u8ba2\u4efb\u52a1\u4e2d\u8fbe\u523092.2%\u6062\u590d\u7387\uff0c\u800cGemini\u964d\u81f348.6%\uff1b\u96f6\u552e\u4efb\u52a1\u53c2\u6570\u6709\u6548\u6027\u63a5\u8fd1\u5b8c\u7f8e\u4f46\u5197\u4f59\u7387\u8d85\u8fc780%\uff0c\u63ed\u793a\u4e3b\u8981\u6548\u7387\u95ee\u9898\u3002", "conclusion": "\u9ad8\u539f\u59cb\u51c6\u786e\u7387\u5e76\u4e0d\u4fdd\u8bc1\u52a8\u6001\u76ee\u6807\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u660e\u786e\u6d4b\u91cf\u6062\u590d\u65f6\u95f4\u548c\u5197\u4f59\u7387\u5bf9\u4e8e\u8bc4\u4f30\u4ee3\u7406\u5728\u73b0\u5b9e\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u5f39\u6027\u81f3\u5173\u91cd\u8981\uff0cAgentChangeBench\u4e3a\u8bca\u65ad\u548c\u6539\u8fdb\u4ee3\u7406\u97e7\u6027\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2510.18176", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18176", "abs": "https://arxiv.org/abs/2510.18176", "authors": ["Soumya Rani Samineni", "Durgesh Kalwar", "Vardaan Gangal", "Siddhant Bhambri", "Subbarao Kambhampati"], "title": "Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains", "comment": "4 pages, 2 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR)-based post-training of\nLarge Language Models (LLMs) has been shown to improve accuracy on reasoning\ntasks and continues to attract significant attention. Existing RLVR methods,\nhowever, typically treat all tokens uniformly without accounting for\ntoken-level advantages. These methods primarily evaluate performance based on\nfinal answer correctness or Pass@K accuracy, and yet make claims about RL\npost-training leading to improved reasoning traces. This motivates our\ninvestigation into the effect of RL post-training on intermediate tokens which\nare not directly incentivized. To study this, we design an experimental setup\nusing the GRPO algorithm with Qwen-2.5-0.5B model on the GSM8K dataset. We\nintroduce trace coherence, a First-Order Logic (FOL)-based measure to capture\nthe consistency of reasoning steps by identifying errors in the traces. We\ndistinguish between trace validity and trace coherence, noting that the former\nimplies logical soundness while the latter measures local coherence via lack of\nerrors. Our results show that RL post-training overall improves trace coherence\nwith the most significant gains on problems where the base model fails but the\nRL model succeeds. Surprisingly, RL enhances local coherence without\nnecessarily producing valid or correct solutions. This highlights a crucial\ndistinction: improved local coherence in reasoning steps does not guarantee\nfinal answer correctness. We argue that claims of improved reasoning via RL\nmust be examined with care, as these may be based on improved trace coherence,\nwhich may not translate into fully valid mathematical proofs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60(RLVR)\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u672a\u76f4\u63a5\u6fc0\u52b1\u7684\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u3002\u7814\u7a76\u53d1\u73b0RL\u540e\u8bad\u7ec3\u63d0\u9ad8\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u5c40\u90e8\u8fde\u8d2f\u6027\uff0c\u4f46\u8fd9\u5e76\u4e0d\u4fdd\u8bc1\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u901a\u5e38\u5bf9\u6240\u6709token\u4e00\u89c6\u540c\u4ec1\uff0c\u4ec5\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u8bc4\u4f30\u6027\u80fd\uff0c\u5374\u58f0\u79f0RL\u540e\u8bad\u7ec3\u80fd\u6539\u5584\u63a8\u7406\u8f68\u8ff9\u3002\u8fd9\u4fc3\u4f7f\u6211\u4eec\u7814\u7a76RL\u540e\u8bad\u7ec3\u5bf9\u672a\u76f4\u63a5\u6fc0\u52b1\u7684\u4e2d\u95f4token\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528GRPO\u7b97\u6cd5\u5728Qwen-2.5-0.5B\u6a21\u578b\u548cGSM8K\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5f15\u5165\u57fa\u4e8e\u4e00\u9636\u903b\u8f91\u7684\u8f68\u8ff9\u8fde\u8d2f\u6027\u5ea6\u91cf\u6765\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u7684\u4e00\u81f4\u6027\uff0c\u533a\u5206\u8f68\u8ff9\u6709\u6548\u6027\u548c\u8f68\u8ff9\u8fde\u8d2f\u6027\u3002", "result": "RL\u540e\u8bad\u7ec3\u6574\u4f53\u63d0\u9ad8\u4e86\u8f68\u8ff9\u8fde\u8d2f\u6027\uff0c\u5728\u57fa\u7840\u6a21\u578b\u5931\u8d25\u4f46RL\u6a21\u578b\u6210\u529f\u7684\u95ee\u9898\u4e0a\u6539\u8fdb\u6700\u663e\u8457\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0cRL\u589e\u5f3a\u4e86\u5c40\u90e8\u8fde\u8d2f\u6027\uff0c\u4f46\u4e0d\u4e00\u5b9a\u4ea7\u751f\u6709\u6548\u6216\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "RL\u6539\u5584\u63a8\u7406\u7684\u4e3b\u5f20\u9700\u8981\u8c28\u614e\u5ba1\u89c6\uff0c\u56e0\u4e3a\u57fa\u4e8e\u6539\u8fdb\u7684\u8f68\u8ff9\u8fde\u8d2f\u6027\u53ef\u80fd\u65e0\u6cd5\u8f6c\u5316\u4e3a\u5b8c\u5168\u6709\u6548\u7684\u6570\u5b66\u8bc1\u660e\u3002\u6539\u8fdb\u7684\u63a8\u7406\u6b65\u9aa4\u5c40\u90e8\u8fde\u8d2f\u6027\u5e76\u4e0d\u4fdd\u8bc1\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u3002"}}
{"id": "2510.18193", "categories": ["cs.AI", "cs.CV", "cs.LG", "stat.ML", "68T01", "I.2.8"], "pdf": "https://arxiv.org/pdf/2510.18193", "abs": "https://arxiv.org/abs/2510.18193", "authors": ["Keivan Shariatmadar", "Ahmad Osman", "Ramin Ray", "Usman Dildar", "Kisam Kim"], "title": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "comment": "23 pages, 12 figures", "summary": "Fair, transparent, and explainable decision-making remains a critical\nchallenge in Olympic and Paralympic combat sports. This paper presents\n\\emph{FST.ai 2.0}, an explainable AI ecosystem designed to support referees,\ncoaches, and athletes in real time during Taekwondo competitions and training.\nThe system integrates {pose-based action recognition} using graph convolutional\nnetworks (GCNs), {epistemic uncertainty modeling} through credal sets, and\n{explainability overlays} for visual decision support. A set of {interactive\ndashboards} enables human--AI collaboration in referee evaluation, athlete\nperformance analysis, and Para-Taekwondo classification. Beyond automated\nscoring, FST.ai~2.0 incorporates modules for referee training, fairness\nmonitoring, and policy-level analytics within the World Taekwondo ecosystem.\nExperimental validation on competition data demonstrates an {85\\% reduction in\ndecision review time} and {93\\% referee trust} in AI-assisted decisions. The\nframework thus establishes a transparent and extensible pipeline for\ntrustworthy, data-driven officiating and athlete assessment. By bridging\nreal-time perception, explainable inference, and governance-aware design,\nFST.ai~2.0 represents a step toward equitable, accountable, and human-aligned\nAI in sports.", "AI": {"tldr": "FST.ai 2.0\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684AI\u751f\u6001\u7cfb\u7edf\uff0c\u7528\u4e8e\u652f\u6301\u8dc6\u62f3\u9053\u6bd4\u8d5b\u548c\u8bad\u7ec3\u4e2d\u7684\u88c1\u5224\u3001\u6559\u7ec3\u548c\u8fd0\u52a8\u5458\uff0c\u901a\u8fc7\u59ff\u6001\u8bc6\u522b\u3001\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u53ef\u89c6\u5316\u89e3\u91ca\u6765\u63d0\u5347\u51b3\u7b56\u900f\u660e\u5ea6\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u89e3\u51b3\u5965\u6797\u5339\u514b\u548c\u6b8b\u5965\u4f1a\u683c\u6597\u8fd0\u52a8\u4e2d\u516c\u5e73\u3001\u900f\u660e\u548c\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u6311\u6218\uff0c\u63d0\u5347\u88c1\u5224\u51b3\u7b56\u7684\u53ef\u4fe1\u5ea6\u548c\u8fd0\u52a8\u5458\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "method": "\u96c6\u6210\u57fa\u4e8e\u59ff\u6001\u7684\u52a8\u4f5c\u8bc6\u522b\uff08\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff09\u3001\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff08\u901a\u8fc7\u7f6e\u4fe1\u96c6\uff09\u548c\u53ef\u89e3\u91ca\u6027\u8986\u76d6\u5c42\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u652f\u6301\u4eba\u673a\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u51b3\u7b56\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1185%\uff0c\u88c1\u5224\u5bf9AI\u8f85\u52a9\u51b3\u7b56\u7684\u4fe1\u4efb\u5ea6\u8fbe\u523093%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u900f\u660e\u4e14\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u53ef\u4fe1\u8d56\u7684\u6570\u636e\u9a71\u52a8\u88c1\u5224\u548c\u8fd0\u52a8\u5458\u8bc4\u4f30\uff0c\u4ee3\u8868\u4e86\u4f53\u80b2\u9886\u57df\u516c\u5e73\u3001\u8d1f\u8d23\u548c\u4ee5\u4eba\u4e3a\u672c\u7684AI\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.18212", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18212", "abs": "https://arxiv.org/abs/2510.18212", "authors": ["Dan Hendrycks", "Dawn Song", "Christian Szegedy", "Honglak Lee", "Yarin Gal", "Erik Brynjolfsson", "Sharon Li", "Andy Zou", "Lionel Levine", "Bo Han", "Jie Fu", "Ziwei Liu", "Jinwoo Shin", "Kimin Lee", "Mantas Mazeika", "Long Phan", "George Ingebretsen", "Adam Khoja", "Cihang Xie", "Olawale Salaudeen", "Matthias Hein", "Kevin Zhao", "Alexander Pan", "David Duvenaud", "Bo Li", "Steve Omohundro", "Gabriel Alfour", "Max Tegmark", "Kevin McGrew", "Gary Marcus", "Jaan Tallinn", "Eric Schmidt", "Yoshua Bengio"], "title": "A Definition of AGI", "comment": null, "summary": "The lack of a concrete definition for Artificial General Intelligence (AGI)\nobscures the gap between today's specialized AI and human-level cognition. This\npaper introduces a quantifiable framework to address this, defining AGI as\nmatching the cognitive versatility and proficiency of a well-educated adult. To\noperationalize this, we ground our methodology in Cattell-Horn-Carroll theory,\nthe most empirically validated model of human cognition. The framework dissects\ngeneral intelligence into ten core cognitive domains-including reasoning,\nmemory, and perception-and adapts established human psychometric batteries to\nevaluate AI systems. Application of this framework reveals a highly \"jagged\"\ncognitive profile in contemporary models. While proficient in\nknowledge-intensive domains, current AI systems have critical deficits in\nfoundational cognitive machinery, particularly long-term memory storage. The\nresulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 58%) concretely quantify\nboth rapid progress and the substantial gap remaining before AGI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u91cf\u5316\u7684AGI\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8eCattell-Horn-Carroll\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\uff0c\u5c06\u901a\u7528\u667a\u80fd\u5206\u89e3\u4e3a10\u4e2a\u6838\u5fc3\u8ba4\u77e5\u9886\u57df\uff0c\u5e76\u5e94\u7528\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u5de5\u5177\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u5bf9AGI\u7684\u5177\u4f53\u5b9a\u4e49\uff0c\u5f53\u524d\u4e13\u4e1aAI\u4e0e\u4eba\u7c7b\u6c34\u5e73\u8ba4\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\u96be\u4ee5\u8861\u91cf\u3002", "method": "\u57fa\u4e8eCattell-Horn-Carroll\u7406\u8bba\uff0c\u5c06\u901a\u7528\u667a\u80fd\u5206\u89e3\u4e3a10\u4e2a\u8ba4\u77e5\u9886\u57df\uff0c\u5e76\u91c7\u7528\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u5de5\u5177\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u663e\u793a\u5f53\u4ee3AI\u6a21\u578b\u5177\u6709\u9ad8\u5ea6\"\u952f\u9f7f\u72b6\"\u8ba4\u77e5\u7279\u5f81\uff1a\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u57fa\u7840\u8ba4\u77e5\u673a\u5236\uff08\u7279\u522b\u662f\u957f\u671f\u8bb0\u5fc6\u5b58\u50a8\uff09\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002GPT-4\u5f97\u5206\u4e3a27%\uff0cGPT-5\u4e3a58%\u3002", "conclusion": "\u8be5\u6846\u67b6\u91cf\u5316\u4e86AGI\u7684\u53d1\u5c55\u8fdb\u7a0b\uff0c\u65e2\u663e\u793a\u4e86\u5feb\u901f\u8fdb\u6b65\uff0c\u4e5f\u660e\u786e\u4e86\u8ddd\u79bb\u5b9e\u73b0\u771f\u6b63AGI\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2510.18250", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18250", "abs": "https://arxiv.org/abs/2510.18250", "authors": ["Xiaohan Qin", "Xiaoxing Wang", "Ning Liao", "Cancheng Zhang", "Xiangdong Zhang", "Mingquan Feng", "Jingzhi Wang", "Junchi Yan"], "title": "ssToken: Self-modulated and Semantic-aware Token Selection for LLM Fine-tuning", "comment": null, "summary": "Data quality plays a critical role in enhancing supervised fine-tuning (SFT)\nfor large language models (LLMs), and token-level data selection has emerged as\na promising direction for its fine-grained nature. Despite their strong\nempirical performance, existing token-level selection methods share two key\nlimitations: (1) requiring training or accessing an additional reference model,\nand (2) relying solely on loss information for token selection, which cannot\nwell preserve semantically important tokens that are not favored by loss-based\nmetrics. To address these challenges, we propose ssToken, a Self-modulated and\nSemantic-aware Token Selection approach. ssToken leverages readily accessible\nhistory models to compute the per-token loss difference with the current model,\nwhich serves as a self-modulated signal that enables the model to adaptively\nselect tokens along its optimization trajectory, rather than relying on excess\nloss from an offline-trained reference model as in prior works. We further\nintroduce a semantic-aware, attention-based token importance estimation metric,\northogonal to loss-based selection and providing complementary semantic\ninformation for more effective filtering. Extensive experiments across\ndifferent model families and scales demonstrate that both self-modulated\nselection and semantic-aware selection alone outperform full-data fine-tuning,\nwhile their integration--ssToken--achieves synergistic gains and further\nsurpasses prior token-level selection methods, delivering performance\nimprovements while maintaining training efficiency.", "AI": {"tldr": "\u63d0\u51fassToken\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u8c03\u5236\u548c\u8bed\u4e49\u611f\u77e5\u7684token\u9009\u62e9\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u5fae\u8c03\u6548\u679c\uff0c\u65e0\u9700\u989d\u5916\u53c2\u8003\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u4e0a\u4f18\u4e8e\u5168\u6570\u636e\u5fae\u8c03\u548c\u73b0\u6709token\u7ea7\u9009\u62e9\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709token\u7ea7\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u9700\u8981\u989d\u5916\u53c2\u8003\u6a21\u578b\u4e14\u4ec5\u4f9d\u8d56\u635f\u5931\u4fe1\u606f\uff0c\u65e0\u6cd5\u5f88\u597d\u4fdd\u7559\u8bed\u4e49\u91cd\u8981\u7684token\u3002", "method": "\u4f7f\u7528\u5386\u53f2\u6a21\u578b\u8ba1\u7b97\u5f53\u524d\u6a21\u578b\u7684token\u635f\u5931\u5dee\u5f02\u4f5c\u4e3a\u81ea\u8c03\u5236\u4fe1\u53f7\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u8bed\u4e49\u611f\u77e5token\u91cd\u8981\u6027\u4f30\u8ba1\u6307\u6807\u3002", "result": "\u81ea\u8c03\u5236\u9009\u62e9\u548c\u8bed\u4e49\u611f\u77e5\u9009\u62e9\u5355\u72ec\u4f7f\u7528\u5747\u4f18\u4e8e\u5168\u6570\u636e\u5fae\u8c03\uff0c\u4e24\u8005\u7ed3\u5408\u4ea7\u751f\u534f\u540c\u589e\u76ca\uff0c\u8d85\u8d8a\u73b0\u6709token\u7ea7\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "ssToken\u901a\u8fc7\u81ea\u8c03\u5236\u548c\u8bed\u4e49\u611f\u77e5token\u9009\u62e9\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u5e76\u4fdd\u6301\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u6570\u636e\u8d28\u91cf\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18254", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18254", "abs": "https://arxiv.org/abs/2510.18254", "authors": ["Sion Weatherhead", "Flora Salim", "Aaron Belbasis"], "title": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "comment": null, "summary": "Humans do not just find mistakes after the fact -- we often catch them\nmid-stream because 'reflection' is tied to the goal and its constraints.\nToday's large language models produce reasoning tokens and 'reflective' text,\nbut is it functionally equivalent with human reflective reasoning? Prior work\non closed-ended tasks -- with clear, external 'correctness' signals -- can make\n'reflection' look effective while masking limits in self-correction. We\ntherefore test eight frontier models on a simple, real-world task that is\nopen-ended yet rule-constrained, with auditable success criteria: to produce\nvalid scientific test items, then revise after considering their own critique.\nFirst-pass performance is poor (often zero valid items out of 4 required; mean\n$\\approx$ 1), and reflection yields only modest gains (also $\\approx$ 1).\nCrucially, the second attempt frequently repeats the same violation of\nconstraint, indicating 'corrective gains' arise largely from chance production\nof a valid item rather than error detection and principled,\nconstraint-sensitive repair. Performance before and after reflection\ndeteriorates as open-endedness increases, and models marketed for 'reasoning'\nshow no advantage. Our results suggest that current LLM 'reflection' lacks\nfunctional evidence of the active, goal-driven monitoring that helps humans\nrespect constraints even on a first pass. Until such mechanisms are\ninstantiated in the model itself, reliable performance requires external\nstructure that enforces constraints.", "AI": {"tldr": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684'\u53cd\u601d'\u529f\u80fd\u4e0e\u4eba\u7c7b\u53cd\u601d\u63a8\u7406\u5728\u529f\u80fd\u4e0a\u5e76\u4e0d\u7b49\u6548\uff0c\u6a21\u578b\u5728\u5f00\u653e\u4f46\u89c4\u5219\u7ea6\u675f\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u53cd\u601d\u540e\u6539\u8fdb\u6709\u9650\uff0c\u4e14\u7ecf\u5e38\u91cd\u590d\u76f8\u540c\u7684\u7ea6\u675f\u8fdd\u53cd\u9519\u8bef\u3002", "motivation": "\u7814\u7a76\u5f53\u524dLLM\u7684'\u53cd\u601d'\u80fd\u529b\u662f\u5426\u771f\u6b63\u7b49\u540c\u4e8e\u4eba\u7c7b\u7684\u53cd\u601d\u63a8\u7406\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u4f46\u89c4\u5219\u7ea6\u675f\u7684\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u5176\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u3002", "method": "\u5728\u516b\u4e2a\u524d\u6cbf\u6a21\u578b\u4e0a\u6d4b\u8bd5\u4e00\u4e2a\u7b80\u5355\u4f46\u5f00\u653e\u4e14\u89c4\u5219\u7ea6\u675f\u7684\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\uff1a\u751f\u6210\u6709\u6548\u7684\u79d1\u5b66\u6d4b\u8bd5\u9879\u76ee\uff0c\u7136\u540e\u57fa\u4e8e\u81ea\u6211\u6279\u8bc4\u8fdb\u884c\u4fee\u8ba2\u3002", "result": "\u9996\u6b21\u5c1d\u8bd5\u8868\u73b0\u5f88\u5dee\uff08\u901a\u5e384\u4e2a\u9879\u76ee\u4e2d0\u4e2a\u6709\u6548\uff0c\u5e73\u5747\u7ea61\u4e2a\uff09\uff0c\u53cd\u601d\u540e\u53ea\u6709\u9002\u5ea6\u6539\u8fdb\uff08\u4e5f\u7ea61\u4e2a\uff09\u3002\u7b2c\u4e8c\u6b21\u5c1d\u8bd5\u7ecf\u5e38\u91cd\u590d\u76f8\u540c\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u8868\u660e'\u4fee\u6b63\u6536\u76ca'\u4e3b\u8981\u6765\u81ea\u5076\u7136\u4ea7\u751f\u6709\u6548\u9879\u76ee\u800c\u975e\u9519\u8bef\u68c0\u6d4b\u548c\u539f\u5219\u6027\u4fee\u590d\u3002", "conclusion": "\u5f53\u524dLLM\u7684'\u53cd\u601d'\u7f3a\u4e4f\u4eba\u7c7b\u4e3b\u52a8\u3001\u76ee\u6807\u9a71\u52a8\u7684\u76d1\u63a7\u673a\u5236\u7684\u8bc1\u636e\uff0c\u53ef\u9760\u6027\u80fd\u9700\u8981\u5916\u90e8\u7ed3\u6784\u6765\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u3002"}}
{"id": "2510.18314", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18314", "abs": "https://arxiv.org/abs/2510.18314", "authors": ["Zheng Zhang", "Jiarui He", "Yuchen Cai", "Deheng Ye", "Peilin Zhao", "Ruili Feng", "Hao Wang"], "title": "Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming", "comment": null, "summary": "As large language model (LLM) agents increasingly automate complex web tasks,\nthey boost productivity while simultaneously introducing new security risks.\nHowever, relevant studies on web agent attacks remain limited. Existing\nred-teaming approaches mainly rely on manually crafted attack strategies or\nstatic models trained offline. Such methods fail to capture the underlying\nbehavioral patterns of web agents, making it difficult to generalize across\ndiverse environments. In web agent attacks, success requires the continuous\ndiscovery and evolution of attack strategies. To this end, we propose Genesis,\na novel agentic framework composed of three modules: Attacker, Scorer, and\nStrategist. The Attacker generates adversarial injections by integrating the\ngenetic algorithm with a hybrid strategy representation. The Scorer evaluates\nthe target web agent's responses to provide feedback. The Strategist\ndynamically uncovers effective strategies from interaction logs and compiles\nthem into a continuously growing strategy library, which is then re-deployed to\nenhance the Attacker's effectiveness. Extensive experiments across various web\ntasks show that our framework discovers novel strategies and consistently\noutperforms existing attack baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86Genesis\u6846\u67b6\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u548c\u6df7\u5408\u7b56\u7565\u8868\u793a\u751f\u6210\u5bf9\u6297\u6027\u6ce8\u5165\uff0c\u52a8\u6001\u53d1\u73b0\u5e76\u7f16\u8bd1\u6709\u6548\u653b\u51fb\u7b56\u7565\uff0c\u6301\u7eed\u63d0\u5347\u5bf9\u7f51\u7edc\u4ee3\u7406\u7684\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u81ea\u52a8\u5316\u590d\u6742\u7f51\u7edc\u4efb\u52a1\uff0c\u5b83\u4eec\u5728\u63d0\u9ad8\u751f\u4ea7\u529b\u7684\u540c\u65f6\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u5236\u5b9a\u7684\u653b\u51fb\u7b56\u7565\u6216\u79bb\u7ebf\u8bad\u7ec3\u7684\u9759\u6001\u6a21\u578b\uff0c\u96be\u4ee5\u6355\u6349\u7f51\u7edc\u4ee3\u7406\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u65e0\u6cd5\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u6cdb\u5316\u3002", "method": "\u63d0\u51faGenesis\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u653b\u51fb\u8005\uff08\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u548c\u6df7\u5408\u7b56\u7565\u8868\u793a\u751f\u6210\u5bf9\u6297\u6027\u6ce8\u5165\uff09\u3001\u8bc4\u5206\u5668\uff08\u8bc4\u4f30\u76ee\u6807\u7f51\u7edc\u4ee3\u7406\u7684\u54cd\u5e94\u63d0\u4f9b\u53cd\u9988\uff09\u3001\u7b56\u7565\u5e08\uff08\u4ece\u4ea4\u4e92\u65e5\u5fd7\u4e2d\u52a8\u6001\u53d1\u73b0\u6709\u6548\u7b56\u7565\u5e76\u7f16\u8bd1\u5230\u6301\u7eed\u589e\u957f\u7684\u6218\u7565\u5e93\u4e2d\uff09\u3002", "result": "\u5728\u5404\u79cd\u7f51\u7edc\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u53d1\u73b0\u65b0\u9896\u7b56\u7565\uff0c\u5e76\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u653b\u51fb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Genesis\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u53d1\u73b0\u548c\u6f14\u5316\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u4ee3\u7406\u653b\u51fb\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u679c\u3002"}}
{"id": "2510.18318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18318", "abs": "https://arxiv.org/abs/2510.18318", "authors": ["Aaron Bell", "Amit Aides", "Amr Helmy", "Arbaaz Muslim", "Aviad Barzilai", "Aviv Slobodkin", "Bolous Jaber", "David Schottlander", "George Leifman", "Joydeep Paul", "Mimi Sun", "Nadav Sherman", "Natalie Williams", "Per Bjornsson", "Roy Lee", "Ruth Alcantara", "Thomas Turnbull", "Tomer Shekel", "Vered Silverman", "Yotam Gigi", "Adam Boulanger", "Alex Ottenwess", "Ali Ahmadalipour", "Anna Carter", "Charles Elliott", "David Andre", "Elad Aharoni", "Gia Jung", "Hassler Thurston", "Jacob Bien", "Jamie McPike", "Juliet Rothenberg", "Kartik Hegde", "Kel Markert", "Kim Philipp Jablonski", "Luc Houriez", "Monica Bharel", "Phing VanLee", "Reuven Sayag", "Sebastian Pilarski", "Shelley Cazares", "Shlomi Pasternak", "Siduo Jiang", "Stone Jiang", "Thomas Colthurst", "Yang Chen", "Yehonathan Refael", "Yochai Blau", "Yuval Carny", "Yael Maguire", "Avinatan Hassidim", "James Manyika", "Tim Thelin", "Genady Beryozkin", "Gautam Prasad", "Luke Barrington", "Yossi Matias", "Niv Efron", "Shravya Shetty"], "title": "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning", "comment": null, "summary": "Geospatial data offers immense potential for understanding our planet.\nHowever, the sheer volume and diversity of this data along with its varied\nresolutions, timescales, and sparsity pose significant challenges for thorough\nanalysis and interpretation. This paper introduces Earth AI, a family of\ngeospatial AI models and agentic reasoning that enables significant advances in\nour ability to unlock novel and profound insights into our planet. This\napproach is built upon foundation models across three key domains--Planet-scale\nImagery, Population, and Environment--and an intelligent Gemini-powered\nreasoning engine. We present rigorous benchmarks showcasing the power and novel\ncapabilities of our foundation models and validate that when used together,\nthey provide complementary value for geospatial inference and their synergies\nunlock superior predictive capabilities. To handle complex, multi-step queries,\nwe developed a Gemini-powered agent that jointly reasons over our multiple\nfoundation models along with large geospatial data sources and tools. On a new\nbenchmark of real-world crisis scenarios, our agent demonstrates the ability to\ndeliver critical and timely insights, effectively bridging the gap between raw\ngeospatial data and actionable understanding.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Earth AI\uff0c\u4e00\u4e2a\u7ed3\u5408\u5730\u7406\u7a7a\u95f4AI\u6a21\u578b\u548c\u667a\u80fd\u63a8\u7406\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u57fa\u7840\u6a21\u578b\u548cGemini\u9a71\u52a8\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u89e3\u51b3\u5730\u7406\u6570\u636e\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5e9e\u5927\u7684\u6570\u91cf\u3001\u591a\u6837\u6027\u4ee5\u53ca\u4e0d\u540c\u7684\u5206\u8fa8\u7387\u3001\u65f6\u95f4\u5c3a\u5ea6\u548c\u7a00\u758f\u6027\u7ed9\u6df1\u5165\u5206\u6790\u548c\u89e3\u91ca\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e86\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u57fa\u7840\u6a21\u578b\uff08\u884c\u661f\u5c3a\u5ea6\u5f71\u50cf\u3001\u4eba\u53e3\u3001\u73af\u5883\uff09\u548cGemini\u9a71\u52a8\u7684\u667a\u80fd\u63a8\u7406\u5f15\u64ce\uff0c\u5f00\u53d1\u4e86\u80fd\u591f\u8054\u5408\u63a8\u7406\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u3001\u5927\u578b\u5730\u7406\u7a7a\u95f4\u6570\u636e\u6e90\u548c\u5de5\u5177\u7684Gemini\u9a71\u52a8\u4ee3\u7406\u3002", "result": "\u5728\u4e25\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u57fa\u7840\u6a21\u578b\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u5728\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u4e92\u8865\u4ef7\u503c\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u5371\u673a\u573a\u666f\u7684\u65b0\u57fa\u51c6\u4e0a\uff0c\u4ee3\u7406\u80fd\u591f\u63d0\u4f9b\u5173\u952e\u53ca\u65f6\u7684\u6d1e\u5bdf\u3002", "conclusion": "Earth AI\u7cfb\u7edf\u6709\u6548\u5f25\u5408\u4e86\u539f\u59cb\u5730\u7406\u7a7a\u95f4\u6570\u636e\u4e0e\u53ef\u64cd\u4f5c\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u89e3\u9501\u4e86\u5bf9\u5730\u7403\u7684\u65b0\u9896\u6df1\u523b\u6d1e\u5bdf\u3002"}}
{"id": "2510.18342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18342", "abs": "https://arxiv.org/abs/2510.18342", "authors": ["Peng Tang", "Xiaoxiao Yan", "Xiaobin Hu", "Yuning Cui", "Donghao Luo", "Jiangning Zhang", "Pengcheng Xu", "Jinlong Peng", "Qingdong He", "Feiyue Huang", "Song Xue", "Tobias Lasser"], "title": "ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection", "comment": "Under Review", "summary": "Multi-class unsupervised anomaly detection (MUAD) has garnered growing\nresearch interest, as it seeks to develop a unified model for anomaly detection\nacross multiple classes, i.e., eliminating the need to train separate models\nfor distinct objects and thereby saving substantial computational resources.\nUnder the MUAD setting, while advanced Transformer-based architectures have\nbrought significant performance improvements, identity shortcuts persist: they\ndirectly copy inputs to outputs, narrowing the gap in reconstruction errors\nbetween normal and abnormal cases, and thereby making the two harder to\ndistinguish. Therefore, we propose ShortcutBreaker, a novel unified\nfeature-reconstruction framework for MUAD tasks, featuring two key innovations\nto address the issue of shortcuts. First, drawing on matrix rank inequality, we\ndesign a low-rank noisy bottleneck (LRNB) to project highdimensional features\ninto a low-rank latent space, and theoretically demonstrate its capacity to\nprevent trivial identity reproduction. Second, leveraging ViTs global modeling\ncapability instead of merely focusing on local features, we incorporate a\nglobal perturbation attention to prevent information shortcuts in the decoders.\nExtensive experiments are performed on four widely used anomaly detection\nbenchmarks, including three industrial datasets (MVTec-AD, ViSA, and Real-IAD)\nand one medical dataset (Universal Medical). The proposed method achieves a\nremarkable image-level AUROC of 99.8%, 98.9%, 90.6%, and 87.8% on these four\ndatasets, respectively, consistently outperforming previous MUAD methods across\ndifferent scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86ShortcutBreaker\u6846\u67b6\uff0c\u901a\u8fc7\u4f4e\u79e9\u566a\u58f0\u74f6\u9888\u548c\u5168\u5c40\u6270\u52a8\u6ce8\u610f\u529b\u89e3\u51b3\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u9700\u8981\u7edf\u4e00\u6a21\u578b\u5904\u7406\u591a\u4e2a\u7c7b\u522b\uff0c\u4f46\u73b0\u6709Transformer\u67b6\u6784\u5b58\u5728\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5373\u76f4\u63a5\u590d\u5236\u8f93\u5165\u5230\u8f93\u51fa\uff0c\u5bfc\u81f4\u6b63\u5e38\u4e0e\u5f02\u5e38\u6837\u672c\u7684\u91cd\u5efa\u8bef\u5dee\u5dee\u5f02\u53d8\u5c0f\uff0c\u96be\u4ee5\u533a\u5206\u3002", "method": "1. \u57fa\u4e8e\u77e9\u9635\u79e9\u4e0d\u7b49\u5f0f\u8bbe\u8ba1\u4f4e\u79e9\u566a\u58f0\u74f6\u9888\uff0c\u5c06\u9ad8\u7ef4\u7279\u5f81\u6295\u5f71\u5230\u4f4e\u79e9\u6f5c\u5728\u7a7a\u95f4\uff0c\u9632\u6b62\u5e73\u51e1\u8eab\u4efd\u590d\u5236\uff1b2. \u5229\u7528ViT\u7684\u5168\u5c40\u5efa\u6a21\u80fd\u529b\uff0c\u5f15\u5165\u5168\u5c40\u6270\u52a8\u6ce8\u610f\u529b\u9632\u6b62\u89e3\u7801\u5668\u4e2d\u7684\u4fe1\u606f\u6377\u5f84\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff1aMVTec-AD(99.8%)\u3001ViSA(98.9%)\u3001Real-IAD(90.6%)\u548cUniversal Medical(87.8%)\u7684\u56fe\u50cf\u7ea7AUROC\uff0c\u5747\u4f18\u4e8e\u73b0\u6709MUAD\u65b9\u6cd5\u3002", "conclusion": "ShortcutBreaker\u901a\u8fc7\u89e3\u51b3\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5728\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.18395", "categories": ["cs.AI", "68T42, 68T37, 91A35", "I.2.6; I.2.11; I.2.8; K.8.0"], "pdf": "https://arxiv.org/pdf/2510.18395", "abs": "https://arxiv.org/abs/2510.18395", "authors": ["Runnan Qi", "Yanan Ni", "Lumin Jiang", "Zongyuan Li", "Kuihua Huang", "Xian Guo"], "title": "Memory-Augmented State Machine Prompting: A Novel LLM Agent Framework for Real-Time Strategy Games", "comment": "10 pages, 4 figures, 1 table, 1 algorithm. Submitted to conference", "summary": "This paper proposes Memory-Augmented State Machine Prompting (MASMP), a novel\nframework for LLM agents in real-time strategy games. Addressing key challenges\nlike hallucinations and fragmented decision-making in existing approaches,\nMASMP integrates state machine prompting with memory mechanisms to unify\nstructured actions with long-term tactical coherence. The framework features:\n(1) a natural language-driven state machine architecture that guides LLMs to\nemulate finite state machines and behavior trees through prompts, and (2) a\nlightweight memory module preserving strategic variables (e.g., tactics,\npriority units) across decision cycles. Experiments in StarCraft II demonstrate\nMASMP's 60% win rate against the hardest built-in AI (Lv7), vastly\noutperforming baselines (0%). Case studies reveal the method retains LLMs'\nsemantic comprehension while resolving the \"Knowing-Doing Gap\" through strict\nstate-action mapping, achieving both interpretability and FSM-like reliability.\nThis work establishes a new paradigm for combining neural and symbolic AI in\ncomplex decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86Memory-Augmented State Machine Prompting (MASMP)\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3LLM\u667a\u80fd\u4f53\u5728\u5b9e\u65f6\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u5e7b\u89c9\u548c\u51b3\u7b56\u788e\u7247\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u63d0\u793a\u548c\u8bb0\u5fc6\u673a\u5236\u5b9e\u73b0\u7ed3\u6784\u5316\u884c\u52a8\u4e0e\u957f\u671f\u6218\u672f\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u788e\u7247\u5316\u51b3\u7b56\u95ee\u9898\uff0c\u9700\u8981\u7edf\u4e00\u7ed3\u6784\u5316\u884c\u52a8\u4e0e\u957f\u671f\u6218\u672f\u8fde\u8d2f\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u72b6\u6001\u673a\u67b6\u6784\u548c\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u6a21\u5757\uff0c\u901a\u8fc7\u63d0\u793a\u5f15\u5bfcLLM\u6a21\u62df\u6709\u9650\u72b6\u6001\u673a\u548c\u884c\u4e3a\u6811\uff0c\u4fdd\u6301\u6218\u7565\u53d8\u91cf\u8de8\u51b3\u7b56\u5468\u671f\u7684\u8fde\u7eed\u6027\u3002", "result": "\u5728StarCraft II\u5b9e\u9a8c\u4e2d\uff0c\u5bf9\u6700\u5f3a\u5185\u7f6eAI (Lv7)\u8fbe\u523060%\u80dc\u7387\uff0c\u8fdc\u8d85\u57fa\u7ebf(0%)\uff0c\u6709\u6548\u89e3\u51b3\u4e86\"\u77e5\u884c\u5dee\u8ddd\"\u95ee\u9898\u3002", "conclusion": "\u5efa\u7acb\u4e86\u7ed3\u5408\u795e\u7ecf\u548c\u7b26\u53f7AI\u5728\u590d\u6742\u51b3\u7b56\u4e2d\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u7c7b\u4f3cFSM\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18407", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18407", "abs": "https://arxiv.org/abs/2510.18407", "authors": ["Manjie Xu", "Xinyi Yang", "Jiayu Zhan", "Wei Liang", "Chi Zhang", "Yixin Zhu"], "title": "Heterogeneous Adversarial Play in Interactive Environments", "comment": "NeurIPS 2025", "summary": "Self-play constitutes a fundamental paradigm for autonomous skill\nacquisition, whereby agents iteratively enhance their capabilities through\nself-directed environmental exploration. Conventional self-play frameworks\nexploit agent symmetry within zero-sum competitive settings, yet this approach\nproves inadequate for open-ended learning scenarios characterized by inherent\nasymmetry. Human pedagogical systems exemplify asymmetric instructional\nframeworks wherein educators systematically construct challenges calibrated to\nindividual learners' developmental trajectories. The principal challenge\nresides in operationalizing these asymmetric, adaptive pedagogical mechanisms\nwithin artificial systems capable of autonomously synthesizing appropriate\ncurricula without predetermined task hierarchies. Here we present Heterogeneous\nAdversarial Play (HAP), an adversarial Automatic Curriculum Learning framework\nthat formalizes teacher-student interactions as a minimax optimization wherein\ntask-generating instructor and problem-solving learner co-evolve through\nadversarial dynamics. In contrast to prevailing ACL methodologies that employ\nstatic curricula or unidirectional task selection mechanisms, HAP establishes a\nbidirectional feedback system wherein instructors continuously recalibrate task\ncomplexity in response to real-time learner performance metrics. Experimental\nvalidation across multi-task learning domains demonstrates that our framework\nachieves performance parity with SOTA baselines while generating curricula that\nenhance learning efficacy in both artificial agents and human subjects.", "AI": {"tldr": "\u63d0\u51faHeterogeneous Adversarial Play (HAP)\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u6559\u5e08-\u5b66\u751f\u7684\u4e0d\u5bf9\u79f0\u4ea4\u4e92\uff0c\u89e3\u51b3\u4f20\u7edf\u81ea\u535a\u5f08\u5728\u5f00\u653e\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u81ea\u535a\u5f08\u65b9\u6cd5\u5728\u96f6\u548c\u7ade\u4e89\u573a\u666f\u4e2d\u4f9d\u8d56\u667a\u80fd\u4f53\u5bf9\u79f0\u6027\uff0c\u4f46\u5728\u5f00\u653e\u5b66\u4e60\u573a\u666f\u4e2d\u5b58\u5728\u56fa\u6709\u4e0d\u5bf9\u79f0\u6027\u3002\u4eba\u7c7b\u6559\u5b66\u7cfb\u7edf\u5c55\u793a\u4e86\u4e0d\u5bf9\u79f0\u7684\u6559\u5b66\u6846\u67b6\uff0c\u6559\u5e08\u6839\u636e\u5b66\u751f\u53d1\u5c55\u8f68\u8ff9\u7cfb\u7edf\u6784\u5efa\u6311\u6218\u3002", "method": "HAP\u5c06\u6559\u5e08-\u5b66\u751f\u4ea4\u4e92\u5f62\u5f0f\u5316\u4e3a\u6781\u5c0f\u6781\u5927\u4f18\u5316\uff0c\u4efb\u52a1\u751f\u6210\u6559\u5e08\u548c\u95ee\u9898\u89e3\u51b3\u5b66\u751f\u901a\u8fc7\u5bf9\u6297\u52a8\u6001\u5171\u540c\u8fdb\u5316\u3002\u5efa\u7acb\u53cc\u5411\u53cd\u9988\u7cfb\u7edf\uff0c\u6559\u5e08\u6839\u636e\u5b9e\u65f6\u5b66\u4e60\u8005\u8868\u73b0\u6307\u6807\u6301\u7eed\u91cd\u65b0\u6821\u51c6\u4efb\u52a1\u590d\u6742\u5ea6\u3002", "result": "\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u9886\u57df\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u8fbe\u5230\u6700\u5148\u8fdb\u57fa\u7ebf\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u540c\u65f6\u751f\u6210\u7684\u8bfe\u7a0b\u63d0\u9ad8\u4e86\u4eba\u5de5\u667a\u80fd\u4f53\u548c\u4eba\u7c7b\u53d7\u8bd5\u8005\u7684\u5b66\u4e60\u6548\u7387\u3002", "conclusion": "HAP\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4e0d\u5bf9\u79f0\u3001\u81ea\u9002\u5e94\u6559\u5b66\u673a\u5236\u5728\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u64cd\u4f5c\u5316\uff0c\u80fd\u591f\u81ea\u4e3b\u5408\u6210\u9002\u5f53\u8bfe\u7a0b\u800c\u65e0\u9700\u9884\u5b9a\u4e49\u4efb\u52a1\u5c42\u6b21\u7ed3\u6784\u3002"}}
{"id": "2510.18412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18412", "abs": "https://arxiv.org/abs/2510.18412", "authors": ["Mattia Pujatti", "Andrea Di Luca", "Nicola Peghini", "Federico Monegaglia", "Marco Cristoforetti"], "title": "Deep Learning-Based Control Optimization for Glass Bottle Forming", "comment": "37 pages, 17 figures, accepted for publication in \"Expert Systems\n  With Applications\"", "summary": "In glass bottle manufacturing, precise control of forming machines is\ncritical for ensuring quality and minimizing defects. This study presents a\ndeep learning-based control algorithm designed to optimize the forming process\nin real production environments. Using real operational data from active\nmanufacturing plants, our neural network predicts the effects of parameter\nchanges based on the current production setup. Through a specifically designed\ninversion mechanism, the algorithm identifies the optimal machine settings\nrequired to achieve the desired glass gob characteristics. Experimental results\non historical datasets from multiple production lines show that the proposed\nmethod yields promising outcomes, suggesting potential for enhanced process\nstability, reduced waste, and improved product consistency. These results\nhighlight the potential of deep learning to process control in glass\nmanufacturing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u73bb\u7483\u74f6\u5236\u9020\u4e2d\u7684\u6210\u578b\u8fc7\u7a0b\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53c2\u6570\u53d8\u5316\u7684\u5f71\u54cd\u5e76\u786e\u5b9a\u6700\u4f73\u673a\u5668\u8bbe\u7f6e\u3002", "motivation": "\u5728\u73bb\u7483\u74f6\u5236\u9020\u4e2d\uff0c\u6210\u578b\u673a\u5668\u7684\u7cbe\u786e\u63a7\u5236\u5bf9\u4e8e\u786e\u4fdd\u8d28\u91cf\u548c\u51cf\u5c11\u7f3a\u9677\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4f18\u5316\u6210\u578b\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u5b9e\u9645\u751f\u4ea7\u5de5\u5382\u7684\u8fd0\u884c\u6570\u636e\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53c2\u6570\u53d8\u5316\u7684\u5f71\u54cd\uff0c\u5e76\u8bbe\u8ba1\u7279\u5b9a\u7684\u53cd\u6f14\u673a\u5236\u6765\u786e\u5b9a\u5b9e\u73b0\u6240\u9700\u73bb\u7483\u6599\u7279\u6027\u7684\u6700\u4f73\u673a\u5668\u8bbe\u7f6e\u3002", "result": "\u5728\u591a\u4e2a\u751f\u4ea7\u7ebf\u7684\u5386\u53f2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u8868\u660e\u5177\u6709\u589e\u5f3a\u8fc7\u7a0b\u7a33\u5b9a\u6027\u3001\u51cf\u5c11\u6d6a\u8d39\u548c\u63d0\u9ad8\u4ea7\u54c1\u4e00\u81f4\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u73bb\u7483\u5236\u9020\u8fc7\u7a0b\u63a7\u5236\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.18424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18424", "abs": "https://arxiv.org/abs/2510.18424", "authors": ["Guangfu Guo", "Xiaoqian Lu", "Yue Feng"], "title": "Med-VRAgent: A Framework for Medical Visual Reasoning-Enhanced Agents", "comment": null, "summary": "Visual Language Models (VLMs) achieve promising results in medical reasoning\nbut struggle with hallucinations, vague descriptions, inconsistent logic and\npoor localization. To address this, we propose a agent framework named Medical\nVisual Reasoning Agent (\\textbf{Med-VRAgent}). The approach is based on Visual\nGuidance and Self-Reward paradigms and Monte Carlo Tree Search (MCTS). By\ncombining the Visual Guidance with tree search, Med-VRAgent improves the\nmedical visual reasoning capabilities of VLMs. We use the trajectories\ncollected by Med-VRAgent as feedback to further improve the performance by\nfine-tuning the VLMs with the proximal policy optimization (PPO) objective.\nExperiments on multiple medical VQA benchmarks demonstrate that our method\noutperforms existing approaches.", "AI": {"tldr": "\u63d0\u51faMed-VRAgent\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9\u5f15\u5bfc\u3001\u81ea\u5956\u52b1\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7PPO\u5fae\u8c03\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u7684\u5e7b\u89c9\u3001\u6a21\u7cca\u63cf\u8ff0\u3001\u903b\u8f91\u4e0d\u4e00\u81f4\u548c\u5b9a\u4f4d\u80fd\u529b\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u89c6\u89c9\u5f15\u5bfc\u548c\u81ea\u5956\u52b1\u8303\u5f0f\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u4f7f\u7528PPO\u76ee\u6807\u5bf9VLMs\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u591a\u4e2a\u533b\u5b66VQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Med-VRAgent\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86VLMs\u5728\u533b\u5b66\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.18425", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18425", "abs": "https://arxiv.org/abs/2510.18425", "authors": ["Chenxu Zhang", "Fuxiang Huang", "Lei Zhang"], "title": "Automated urban waterlogging assessment and early warning through a mixture of foundation models", "comment": "Submitted to Nature", "summary": "With climate change intensifying, urban waterlogging poses an increasingly\nsevere threat to global public safety and infrastructure. However, existing\nmonitoring approaches rely heavily on manual reporting and fail to provide\ntimely and comprehensive assessments. In this study, we present Urban\nWaterlogging Assessment (UWAssess), a foundation model-driven framework that\nautomatically identifies waterlogged areas in surveillance images and generates\nstructured assessment reports. To address the scarcity of labeled data, we\ndesign a semi-supervised fine-tuning strategy and a chain-of-thought (CoT)\nprompting strategy to unleash the potential of the foundation model for\ndata-scarce downstream tasks. Evaluations on challenging visual benchmarks\ndemonstrate substantial improvements in perception performance. GPT-based\nevaluations confirm the ability of UWAssess to generate reliable textual\nreports that accurately describe waterlogging extent, depth, risk and impact.\nThis dual capability enables a shift of waterlogging monitoring from perception\nto generation, while the collaborative framework of multiple foundation models\nlays the groundwork for intelligent and scalable systems, supporting urban\nmanagement, disaster response and climate resilience.", "AI": {"tldr": "UWAssess\u662f\u4e00\u4e2a\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u57ce\u5e02\u5185\u6d9d\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u8bc6\u522b\u76d1\u63a7\u56fe\u50cf\u4e2d\u7684\u79ef\u6c34\u533a\u57df\u5e76\u751f\u6210\u7ed3\u6784\u5316\u8bc4\u4f30\u62a5\u544a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4eba\u5de5\u76d1\u6d4b\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u6c14\u5019\u53d8\u5316\u52a0\u5267\uff0c\u57ce\u5e02\u5185\u6d9d\u5bf9\u5168\u7403\u516c\u5171\u5b89\u5168\u548c\u57fa\u7840\u8bbe\u65bd\u6784\u6210\u65e5\u76ca\u4e25\u91cd\u7684\u5a01\u80c1\u3002\u73b0\u6709\u76d1\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u62a5\u544a\uff0c\u65e0\u6cd5\u63d0\u4f9b\u53ca\u65f6\u5168\u9762\u7684\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u534a\u76d1\u7763\u5fae\u8c03\u7b56\u7565\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u89e3\u51b3\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u91ca\u653e\u57fa\u7840\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u611f\u77e5\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002\u57fa\u4e8eGPT\u7684\u8bc4\u4f30\u8bc1\u5b9e\u4e86UWAssess\u751f\u6210\u53ef\u9760\u6587\u672c\u62a5\u544a\u7684\u80fd\u529b\uff0c\u80fd\u591f\u51c6\u786e\u63cf\u8ff0\u79ef\u6c34\u8303\u56f4\u3001\u6df1\u5ea6\u3001\u98ce\u9669\u548c\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u79cd\u53cc\u91cd\u80fd\u529b\u4f7f\u5185\u6d9d\u76d1\u6d4b\u4ece\u611f\u77e5\u8f6c\u5411\u751f\u6210\uff0c\u800c\u591a\u57fa\u7840\u6a21\u578b\u7684\u534f\u4f5c\u6846\u67b6\u4e3a\u667a\u80fd\u53ef\u6269\u5c55\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u652f\u6301\u57ce\u5e02\u7ba1\u7406\u3001\u707e\u5bb3\u54cd\u5e94\u548c\u6c14\u5019\u97e7\u6027\u3002"}}
{"id": "2510.18428", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18428", "abs": "https://arxiv.org/abs/2510.18428", "authors": ["Minwei Kong", "Ao Qu", "Xiaotong Guo", "Wenbin Ouyang", "Chonghe Jiang", "Han Zheng", "Yining Ma", "Dingyi Zhuang", "Yuhan Tang", "Junyi Li", "Hai Wang", "Cathy Wu", "Jinhua Zhao"], "title": "AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library", "comment": null, "summary": "Optimization modeling enables critical decisions across industries but\nremains difficult to automate: informal language must be mapped to precise\nmathematical formulations and executable solver code. Prior LLM approaches\neither rely on brittle prompting or costly retraining with limited\ngeneralization. We present AlphaOPT, a self-improving experience library that\nenables an LLM to learn from limited demonstrations (even answers alone,\nwithout gold-standard programs) and solver feedback - without annotated\nreasoning traces or parameter updates. AlphaOPT operates in a continual\ntwo-phase cycle: (i) a Library Learning phase that reflects on failed attempts,\nextracting solver-verified, structured insights as {taxonomy, condition,\nexplanation, example}; and (ii) a Library Evolution phase that diagnoses\nretrieval misalignments and refines the applicability conditions of stored\ninsights, improving transfer across tasks. This design (1) learns efficiently\nfrom limited demonstrations without curated rationales, (2) expands continually\nwithout costly retraining by updating the library rather than model weights,\nand (3) makes knowledge explicit and interpretable for human inspection and\nintervention. Experiments show that AlphaOPT steadily improves with more data\n(65% to 72% from 100 to 300 training items) and surpasses the strongest\nbaseline by 7.7% on the out-of-distribution OptiBench dataset when trained only\non answers. Code and data are available at:\nhttps://github.com/Minw913/AlphaOPT.", "AI": {"tldr": "AlphaOPT\u662f\u4e00\u4e2a\u81ea\u6539\u8fdb\u7684\u7ecf\u9a8c\u5e93\u7cfb\u7edf\uff0c\u4f7fLLM\u80fd\u591f\u4ece\u6709\u9650\u6f14\u793a\u548c\u6c42\u89e3\u5668\u53cd\u9988\u4e2d\u5b66\u4e60\u4f18\u5316\u5efa\u6a21\uff0c\u65e0\u9700\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\u6216\u53c2\u6570\u66f4\u65b0\u3002", "motivation": "\u4f18\u5316\u5efa\u6a21\u5728\u5de5\u4e1a\u51b3\u7b56\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u96be\u4ee5\u81ea\u52a8\u5316\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u4f9d\u8d56\u8106\u5f31\u63d0\u793a\u6216\u4ee3\u4ef7\u9ad8\u6602\u7684\u91cd\u8bad\u7ec3\u4e14\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u91c7\u7528\u6301\u7eed\u4e24\u9636\u6bb5\u5faa\u73af\uff1a\u5e93\u5b66\u4e60\u9636\u6bb5\u4ece\u5931\u8d25\u5c1d\u8bd5\u4e2d\u63d0\u53d6\u6c42\u89e3\u5668\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u6d1e\u5bdf\uff1b\u5e93\u6f14\u5316\u9636\u6bb5\u8bca\u65ad\u68c0\u7d22\u504f\u5dee\u5e76\u7cbe\u70bc\u5b58\u50a8\u6d1e\u5bdf\u7684\u9002\u7528\u6761\u4ef6\u3002", "result": "AlphaOPT\u968f\u6570\u636e\u589e\u52a0\u7a33\u6b65\u6539\u8fdb\uff08\u4ece100\u5230300\u8bad\u7ec3\u9879\uff0c\u6027\u80fd\u4ece65%\u63d0\u5347\u523072%\uff09\uff0c\u5728\u4ec5\u4f7f\u7528\u7b54\u6848\u8bad\u7ec3\u65f6\uff0c\u5728OOD OptiBench\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u6700\u5f3a\u57fa\u7ebf7.7%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u4ece\u6709\u9650\u6f14\u793a\u4e2d\u5b66\u4e60\u800c\u65e0\u9700\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63a8\u7406\uff0c\u901a\u8fc7\u66f4\u65b0\u5e93\u800c\u975e\u6a21\u578b\u6743\u91cd\u5b9e\u73b0\u6301\u7eed\u6269\u5c55\uff0c\u4f7f\u77e5\u8bc6\u660e\u786e\u4e14\u53ef\u89e3\u91ca\u3002"}}
{"id": "2510.18442", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18442", "abs": "https://arxiv.org/abs/2510.18442", "authors": ["Ziwei Deng", "Mian Deng", "Chenjing Liang", "Zeming Gao", "Chennan Ma", "Chenxing Lin", "Haipeng Zhang", "Songzhu Mei", "Cheng Wang", "Siqi Shen"], "title": "PlanU: Large Language Model Decision Making through Planning under Uncertainty", "comment": "38 pages, 19 figures, NeurIPS 2025 Accepted", "summary": "Large Language Models (LLMs) are increasingly being explored across a range\nof decision-making tasks. However, LLMs sometimes struggle with decision-making\ntasks under uncertainty that are relatively easy for humans, such as planning\nactions in stochastic environments. The adoption of LLMs for decision-making is\nimpeded by uncertainty challenges, such as LLM uncertainty and environmental\nuncertainty. LLM uncertainty arises from the stochastic sampling process\ninherent to LLMs. Most LLM-based Decision-Making (LDM) approaches address LLM\nuncertainty through multiple reasoning chains or search trees. However, these\napproaches overlook environmental uncertainty, which leads to poor performance\nin environments with stochastic state transitions. Some recent LDM approaches\ndeal with uncertainty by forecasting the probability of unknown variables.\nHowever, they are not designed for multi-step decision-making tasks that\nrequire interaction with the environment. To address uncertainty in LLM\ndecision-making, we introduce PlanU, an LLM-based planning method that captures\nuncertainty within Monte Carlo Tree Search (MCTS). PlanU models the return of\neach node in the MCTS as a quantile distribution, which uses a set of quantiles\nto represent the return distribution. To balance exploration and exploitation\nduring tree search, PlanU introduces an Upper Confidence Bounds with Curiosity\n(UCC) score which estimates the uncertainty of MCTS nodes. Through extensive\nexperiments, we demonstrate the effectiveness of PlanU in LLM-based\ndecision-making tasks under uncertainty.", "AI": {"tldr": "\u63d0\u51fa\u4e86PlanU\u65b9\u6cd5\uff0c\u5728MCTS\u4e2d\u901a\u8fc7\u5206\u4f4d\u6570\u5206\u5e03\u5efa\u6a21\u56de\u62a5\u5206\u5e03\uff0c\u4f7f\u7528UCC\u8bc4\u5206\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u89e3\u51b3LLM\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218", "motivation": "LLM\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u51b3\u7b56\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u53ea\u5173\u6ce8LLM\u4e0d\u786e\u5b9a\u6027\u800c\u5ffd\u7565\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff0c\u8981\u4e48\u4e0d\u9002\u5408\u591a\u6b65\u51b3\u7b56\u4efb\u52a1", "method": "\u57fa\u4e8eMCTS\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5c06\u8282\u70b9\u56de\u62a5\u5efa\u6a21\u4e3a\u5206\u4f4d\u6570\u5206\u5e03\uff0c\u5f15\u5165UCC\u8bc4\u5206\u6765\u4f30\u8ba1\u8282\u70b9\u4e0d\u786e\u5b9a\u6027\u5e76\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528", "result": "\u5b9e\u9a8c\u8bc1\u660ePlanU\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684LLM\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u6548", "conclusion": "PlanU\u901a\u8fc7\u7ed3\u5408\u5206\u4f4d\u6570\u5206\u5e03\u548cUCC\u8bc4\u5206\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218"}}
{"id": "2510.18470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18470", "abs": "https://arxiv.org/abs/2510.18470", "authors": ["Shaobo Wang", "Yongliang Miao", "Yuancheng Liu", "and Qianli Ma", "Ning Liao", "Linfeng Zhang"], "title": "CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs", "comment": "14 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated impressive reasoning\ncapabilities, but scaling their performance often relies on massive reasoning\ndatasets that are computationally expensive to train on. Existing data\nselection methods aim to curate smaller, high-quality subsets but often rely on\ncostly external models or opaque heuristics. In this work, we shift the focus\nfrom external heuristics to the model's internal mechanisms. We find that\ncomplex reasoning tasks consistently activate a sparse, specialized subset of\nattention heads, forming core reasoning circuits. Building on this insight, we\npropose CircuitSeer, a novel data selection method that quantifies the\nreasoning complexity of data by measuring its influence on these crucial\ncircuits. Extensive experiments on 4 models and 9 datasets demonstrate\nCircuitSeer's superiority. Notably, fine-tuning Qwen2.5-Math-7B on just 10% of\ndata selected by our method achieves a 1.4-point gain in average Pass@1 over\ntraining on the full dataset, highlighting its efficiency and effectiveness.", "AI": {"tldr": "CircuitSeer\uff1a\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u6ce8\u610f\u529b\u673a\u5236\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u6838\u5fc3\u63a8\u7406\u7535\u8def\u6765\u9009\u62e9\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5916\u90e8\u6a21\u578b\u6216\u4e0d\u900f\u660e\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u8f6c\u5411\u5229\u7528\u6a21\u578b\u5185\u90e8\u673a\u5236\u6765\u66f4\u6709\u6548\u5730\u9009\u62e9\u63a8\u7406\u6570\u636e", "method": "\u53d1\u73b0\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4f1a\u6fc0\u6d3b\u7a00\u758f\u7684\u4e13\u7528\u6ce8\u610f\u529b\u5934\uff0c\u5f62\u6210\u6838\u5fc3\u63a8\u7406\u7535\u8def\u3002CircuitSeer\u901a\u8fc7\u6d4b\u91cf\u6570\u636e\u5bf9\u8fd9\u4e9b\u5173\u952e\u7535\u8def\u7684\u5f71\u54cd\u6765\u91cf\u5316\u63a8\u7406\u590d\u6742\u5ea6", "result": "\u57284\u4e2a\u6a21\u578b\u548c9\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cCircuitSeer\u4ec5\u4f7f\u752810%\u7684\u6570\u636e\u5c31\u80fd\u5728Qwen2.5-Math-7B\u4e0a\u83b7\u5f97\u6bd4\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u9ad81.4\u4e2a\u767e\u5206\u70b9\u7684Pass@1\u5e73\u5747\u63d0\u5347", "conclusion": "CircuitSeer\u901a\u8fc7\u5229\u7528\u6a21\u578b\u5185\u90e8\u63a8\u7406\u7535\u8def\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u9009\u62e9\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u6210\u672c\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd"}}
{"id": "2510.18476", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18476", "abs": "https://arxiv.org/abs/2510.18476", "authors": ["Feifan Xia", "Yuyang Fang", "Defang Li", "Yantong Xie", "Weikang Li", "Yang Li", "Deguo Xia", "Jizhou Huang"], "title": "Probabilistic Modeling of Intentions in Socially Intelligent LLM Agents", "comment": null, "summary": "We present a probabilistic intent modeling framework for large language model\n(LLM) agents in multi-turn social dialogue. The framework maintains a belief\ndistribution over a partner's latent intentions, initialized from contextual\npriors and dynamically updated through likelihood estimation after each\nutterance. The evolving distribution provides additional contextual grounding\nfor the policy, enabling adaptive dialogue strategies under uncertainty.\nPreliminary experiments in the SOTOPIA environment show consistent\nimprovements: the proposed framework increases the Overall score by 9.0% on\nSOTOPIA-All and 4.1% on SOTOPIA-Hard compared with the Qwen2.5-7B baseline, and\nslightly surpasses an oracle agent that directly observes partner intentions.\nThese early results suggest that probabilistic intent modeling can contribute\nto the development of socially intelligent LLM agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u8f6e\u793e\u4ea4\u5bf9\u8bdd\u4e2dLLM\u4ee3\u7406\u7684\u6982\u7387\u610f\u56fe\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7ef4\u62a4\u5bf9\u4f19\u4f34\u6f5c\u5728\u610f\u56fe\u7684\u4fe1\u5ff5\u5206\u5e03\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u5bf9\u8bdd\u7b56\u7565\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3LLM\u4ee3\u7406\u5728\u591a\u8f6e\u793e\u4ea4\u5bf9\u8bdd\u4e2d\u7406\u89e3\u4f19\u4f34\u610f\u56fe\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u5347\u793e\u4ea4\u667a\u80fd\u5bf9\u8bdd\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5148\u9a8c\u521d\u59cb\u5316\u610f\u56fe\u4fe1\u5ff5\u5206\u5e03\uff0c\u901a\u8fc7\u6bcf\u8f6e\u5bf9\u8bdd\u540e\u7684\u4f3c\u7136\u4f30\u8ba1\u52a8\u6001\u66f4\u65b0\uff0c\u4e3a\u7b56\u7565\u63d0\u4f9b\u989d\u5916\u7684\u4e0a\u4e0b\u6587\u57fa\u7840\u3002", "result": "\u5728SOTOPIA\u73af\u5883\u4e2d\uff0c\u76f8\u6bd4Qwen2.5-7B\u57fa\u7ebf\uff0c\u603b\u4f53\u5f97\u5206\u63d0\u53479.0%\uff08SOTOPIA-All\uff09\u548c4.1%\uff08SOTOPIA-Hard\uff09\uff0c\u751a\u81f3\u7565\u5fae\u8d85\u8fc7\u76f4\u63a5\u89c2\u5bdf\u4f19\u4f34\u610f\u56fe\u7684oracle\u4ee3\u7406\u3002", "conclusion": "\u6982\u7387\u610f\u56fe\u5efa\u6a21\u6709\u52a9\u4e8e\u5f00\u53d1\u793e\u4ea4\u667a\u80fdLLM\u4ee3\u7406\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u5bf9\u8bdd\u9002\u5e94\u6027\u3002"}}
{"id": "2510.18477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18477", "abs": "https://arxiv.org/abs/2510.18477", "authors": ["Haichao Ji", "Zibo Wang", "Yifei Zhu", "Meng han", "Dan Wang", "Zhu Han"], "title": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources", "comment": null, "summary": "Large Language Models (LLMs) have shown great promise in automating data\nanalytics tasks by interpreting natural language queries and generating\nmulti-operation execution plans. However, existing LLM-agent-based analytics\nframeworks operate under the assumption of centralized data access, offering\nlittle to no privacy protection. In contrast, federated analytics (FA) enables\nprivacy-preserving computation across distributed data sources, but lacks\nsupport for natural language input and requires structured, machine-readable\nqueries. In this work, we present LAFA, the first system that integrates\nLLM-agent-based data analytics with FA. LAFA introduces a hierarchical\nmulti-agent architecture that accepts natural language queries and transforms\nthem into optimized, executable FA workflows. A coarse-grained planner first\ndecomposes complex queries into sub-queries, while a fine-grained planner maps\neach subquery into a Directed Acyclic Graph of FA operations using prior\nstructural knowledge. To improve execution efficiency, an optimizer agent\nrewrites and merges multiple DAGs, eliminating redundant operations and\nminimizing computational and communicational overhead. Our experiments\ndemonstrate that LAFA consistently outperforms baseline prompting strategies by\nachieving higher execution plan success rates and reducing resource-intensive\nFA operations by a substantial margin. This work establishes a practical\nfoundation for privacy-preserving, LLM-driven analytics that supports natural\nlanguage input in the FA setting.", "AI": {"tldr": "LAFA\u662f\u9996\u4e2a\u5c06\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u6570\u636e\u5206\u6790\u4e0e\u8054\u90a6\u5206\u6790\u76f8\u7ed3\u5408\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u4ee3\u7406\u67b6\u6784\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u4f18\u5316\u7684\u53ef\u6267\u884cFA\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5206\u6790\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5206\u6790\u6846\u67b6\u5047\u8bbe\u96c6\u4e2d\u5f0f\u6570\u636e\u8bbf\u95ee\uff0c\u7f3a\u4e4f\u9690\u79c1\u4fdd\u62a4\uff1b\u800c\u8054\u90a6\u5206\u6790\u867d\u7136\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\uff0c\u4f46\u9700\u8981\u7ed3\u6784\u5316\u67e5\u8be2\u4e14\u4e0d\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3002", "method": "\u5f15\u5165\u5206\u5c42\u591a\u4ee3\u7406\u67b6\u6784\uff1a\u7c97\u7c92\u5ea6\u89c4\u5212\u5668\u5206\u89e3\u590d\u6742\u67e5\u8be2\u4e3a\u5b50\u67e5\u8be2\uff0c\u7ec6\u7c92\u5ea6\u89c4\u5212\u5668\u5c06\u5b50\u67e5\u8be2\u6620\u5c04\u4e3aFA\u64cd\u4f5c\u7684\u6709\u5411\u65e0\u73af\u56fe\uff0c\u4f18\u5316\u4ee3\u7406\u91cd\u5199\u5408\u5e76\u591a\u4e2aDAG\u4ee5\u6d88\u9664\u5197\u4f59\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLAFA\u5728\u57fa\u7ebf\u63d0\u793a\u7b56\u7565\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6267\u884c\u8ba1\u5212\u6210\u529f\u7387\uff0c\u5e76\u5927\u5e45\u51cf\u5c11\u4e86\u8d44\u6e90\u5bc6\u96c6\u578bFA\u64cd\u4f5c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u8054\u90a6\u5206\u6790\u73af\u5883\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u3001LLM\u9a71\u52a8\u5206\u6790\u5efa\u7acb\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2510.18483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18483", "abs": "https://arxiv.org/abs/2510.18483", "authors": ["Haoran Zhang", "Chenhao Zhu", "Sicong Guo", "Hanzhe Guo", "Haiming Li", "Donglin Yu"], "title": "StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking", "comment": null, "summary": "Human players do more than press buttons: they ground what they see on screen\ninto precise keyboard-mouse actions and, when stuck, they seek information\nbefore trying again. We ask whether current vision-language models (VLMs) can\ndo the same. Despite encouraging results under simplified control or tool\nscaffolds, human-like play in a real client - mapping raw screenshots to\ntemporally coherent low-level actions while deciding when to ask for guidance -\nremains an open challenge. We introduce StarBench, a turn-based RPG benchmark\nderived from Honkai: Star Rail that targets these two human-like competencies:\nmultimodal decision-making from pixels to actions and agentic information\nseeking. StarBench standardizes evaluation across eight combat tasks and two\nregimes with shared tasks and metrics: (i) direct control, where agents receive\nonly screenshots and must emit low-level primitives (click and keypress) with\nno semantic hints; and (ii) tool-assisted control, where higher-level intents\ncan be mapped to primitives by detectors and OCR outputs provide optional\ntextualized observations to ease UI grounding. To mirror human practice,\nStarBench also includes an ask-or-act diagnostic that measures whether and when\nagents choose to request brief guidance before proceeding, and how that choice\naffects subsequent performance. We report reference baselines for contemporary\nVLMs and a human reference. Results expose sizable gaps in\nperception-to-control fidelity in the direct regime, while showing that\njudicious information seeking correlates with improved success, establishing\nStarBench as a reproducible yardstick for agentic information seeking and\nmultimodal decision-making in real-client play.", "AI": {"tldr": "StarBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u300a\u5d29\u574f\uff1a\u661f\u7a79\u94c1\u9053\u300b\u7684\u56de\u5408\u5236RPG\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4ece\u50cf\u7d20\u5230\u52a8\u4f5c\u7684\u591a\u6a21\u6001\u51b3\u7b56\u548c\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u542b\u76f4\u63a5\u63a7\u5236\u548c\u5de5\u5177\u8f85\u52a9\u63a7\u5236\u4e24\u79cd\u6a21\u5f0f\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u5ba2\u6237\u7aef\u4e2d\u5b9e\u73b0\u4eba\u7c7b\u7ea7\u522b\u7684\u6e38\u620f\u80fd\u529b\u2014\u2014\u5c06\u539f\u59cb\u622a\u56fe\u6620\u5c04\u5230\u65f6\u95f4\u4e00\u81f4\u7684\u4f4e\u7ea7\u52a8\u4f5c\uff0c\u5e76\u51b3\u5b9a\u4f55\u65f6\u5bfb\u6c42\u6307\u5bfc\u2014\u2014\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86StarBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b8\u4e2a\u6218\u6597\u4efb\u52a1\u548c\u4e24\u79cd\u63a7\u5236\u6a21\u5f0f\uff1a\u76f4\u63a5\u63a7\u5236\uff08\u4ec5\u63a5\u6536\u622a\u56fe\u5e76\u8f93\u51fa\u4f4e\u7ea7\u64cd\u4f5c\uff09\u548c\u5de5\u5177\u8f85\u52a9\u63a7\u5236\uff08\u53ef\u4f7f\u7528\u68c0\u6d4b\u5668\u548cOCR\u8f93\u51fa\uff09\u3002\u8fd8\u5305\u62ecask-or-act\u8bca\u65ad\u6765\u6d4b\u91cf\u4ee3\u7406\u4f55\u65f6\u9009\u62e9\u5bfb\u6c42\u6307\u5bfc\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5728\u76f4\u63a5\u63a7\u5236\u6a21\u5f0f\u4e0b\u611f\u77e5\u5230\u63a7\u5236\u7684\u4fdd\u771f\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u800c\u660e\u667a\u7684\u4fe1\u606f\u5bfb\u6c42\u4e0e\u6539\u8fdb\u7684\u6210\u529f\u7387\u76f8\u5173\u3002", "conclusion": "StarBench\u4e3a\u771f\u5b9e\u5ba2\u6237\u7aef\u6e38\u620f\u4e2d\u7684\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u548c\u591a\u6a21\u6001\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u8861\u91cf\u6807\u51c6\u3002"}}
{"id": "2510.18488", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18488", "abs": "https://arxiv.org/abs/2510.18488", "authors": ["Ho Fai Leung", "Xiaoyan Xi", "Fei Zuo"], "title": "AndroidControl-Curated: Revealing the True Potential of GUI Agents through Benchmark Purification", "comment": null, "summary": "On-device virtual assistants like Siri and Google Assistant are increasingly\npivotal, yet their capabilities are hamstrung by a reliance on rigid,\ndeveloper-dependent APIs. GUI agents offer a powerful, API-independent\nalternative, but their adoption is hindered by the perception of poor\nperformance, as even the best models (e.g. Qwen3-VL-235B) scores are capped at\naround 60% on benchmarks like AndroidControl, far from viability for real-world\nuse. Our research reveals that issue lies not only with the models but with the\nbenchmarks themselves. We identified notable shortcomings in AndroidControl,\nincluding ambiguities and factual errors, which systematically underrates agent\ncapabilities. To address this critical oversight, we enhanced AndroidControl\ninto AndroidControl-Curated, a refined version of the benchmark improved\nthrough a rigorous purification pipeline. On this enhanced benchmark,\nstate-of-the-art models achieve success rates nearing 75% on complex tasks (15%\nimprovement), reflecting that on-device GUI agents are actually closer to\npractical deployment than previously thought. We introduce our new SOTA model,\nMagma-R1- 3B, post-trained on just 2.4k curated samples using 60 hours of an\nH20 GPU (approximately $60). Despite being 200 times smaller in parameters,\nthis model delivers performance comparable to Qwen3- VL-235B. We release both\nAndroidControl-Curated benchmark and Magma-R1 model to the research community,\nencouraging adoption of this enhanced benchmark to better reflect model\ncapabilities and accelerate the development of robust, on-device virtual\nassistants.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709GUI\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5AndroidControl\u5b58\u5728\u7f3a\u9677\uff0c\u901a\u8fc7\u6539\u8fdb\u521b\u5efa\u4e86AndroidControl-Curated\u57fa\u51c6\uff0c\u4f7fSOTA\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4ece60%\u63d0\u5347\u81f375%\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u8f7b\u91cf\u7ea7\u6a21\u578bMagma-R1-3B\uff0c\u6027\u80fd\u5ab2\u7f8e\u5927200\u500d\u7684\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u8bbe\u5907\u7aef\u865a\u62df\u52a9\u624b\u4f9d\u8d56\u50f5\u5316\u7684API\uff0cGUI\u4ee3\u7406\u63d0\u4f9b\u66ff\u4ee3\u65b9\u6848\u4f46\u88ab\u8ba4\u4e3a\u6027\u80fd\u4e0d\u8db3\u3002\u7814\u7a76\u53d1\u73b0\u95ee\u9898\u4e0d\u4ec5\u5728\u4e8e\u6a21\u578b\uff0c\u66f4\u5728\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u672c\u8eab\u7684\u7f3a\u9677\u3002", "method": "\u8bc6\u522bAndroidControl\u57fa\u51c6\u7684\u6a21\u7cca\u6027\u548c\u4e8b\u5b9e\u9519\u8bef\uff0c\u901a\u8fc7\u4e25\u683c\u51c0\u5316\u6d41\u7a0b\u6539\u8fdb\u4e3aAndroidControl-Curated\u3002\u5f00\u53d1\u8f7b\u91cf\u7ea7\u6a21\u578bMagma-R1-3B\uff0c\u4ec5\u75282.4k\u7cbe\u9009\u6837\u672c\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "\u5728\u6539\u8fdb\u540e\u7684\u57fa\u51c6\u4e0a\uff0cSOTA\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4ece\u7ea660%\u63d0\u5347\u81f3\u8fd175%\u3002Magma-R1-3B\u6a21\u578b\u53c2\u6570\u4ec5\u4e3a3B\uff0c\u6027\u80fd\u5374\u4e0e235B\u7684Qwen3-VL\u76f8\u5f53\u3002", "conclusion": "\u8bbe\u5907\u7aefGUI\u4ee3\u7406\u7684\u5b9e\u9645\u80fd\u529b\u88ab\u4f4e\u4f30\uff0c\u901a\u8fc7\u6539\u8fdb\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f00\u53d1\u9ad8\u6548\u6a21\u578b\uff0c\u8bc1\u660e\u5176\u66f4\u63a5\u8fd1\u5b9e\u9645\u90e8\u7f72\u3002\u53d1\u5e03\u65b0\u57fa\u51c6\u548c\u6a21\u578b\u4ee5\u4fc3\u8fdb\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2510.18491", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18491", "abs": "https://arxiv.org/abs/2510.18491", "authors": ["Lianchen Jia", "Chaoyang Li", "Qian Houde", "Tianchi Huang", "Jiangchuan Liu", "Lifeng Sun"], "title": "Crucible: Quantifying the Potential of Control Algorithms through LLM Agents", "comment": "NeurIPS 2025", "summary": "Control algorithms in production environments typically require domain\nexperts to tune their parameters and logic for specific scenarios. However,\nexisting research predominantly focuses on algorithmic performance under ideal\nor default configurations, overlooking the critical aspect of Tuning Potential.\nTo bridge this gap, we introduce Crucible, an agent that employs an LLM-driven,\nmulti-level expert simulation to turn algorithms and defines a formalized\nmetric to quantitatively evaluate their Tuning Potential. We demonstrate\nCrucible's effectiveness across a wide spectrum of case studies, from classic\ncontrol tasks to complex computer systems, and validate its findings in a\nreal-world deployment. Our experimental results reveal that Crucible\nsystematically quantifies the tunable space across different algorithms.\nFurthermore, Crucible provides a new dimension for algorithm analysis and\ndesign, which ultimately leads to performance improvements. Our code is\navailable at https://github.com/thu-media/Crucible.", "AI": {"tldr": "\u63d0\u51faCrucible\u6846\u67b6\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u591a\u7ea7\u4e13\u5bb6\u6a21\u62df\u6765\u91cf\u5316\u7b97\u6cd5\u7684\u8c03\u4f18\u6f5c\u529b\uff0c\u4e3a\u7b97\u6cd5\u5206\u6790\u548c\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u7ef4\u5ea6", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u5728\u7406\u60f3\u6216\u9ed8\u8ba4\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u8c03\u4f18\u6f5c\u529b\u8fd9\u4e00\u5173\u952e\u65b9\u9762", "method": "\u4f7f\u7528LLM\u9a71\u52a8\u7684\u591a\u7ea7\u4e13\u5bb6\u6a21\u62df\u6765\u8c03\u4f18\u7b97\u6cd5\uff0c\u5e76\u5b9a\u4e49\u5f62\u5f0f\u5316\u6307\u6807\u5b9a\u91cf\u8bc4\u4f30\u8c03\u4f18\u6f5c\u529b", "result": "\u5728\u4ece\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u5230\u590d\u6742\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u5e7f\u6cdb\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86Crucible\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53d1\u73b0", "conclusion": "Crucible\u7cfb\u7edf\u6027\u5730\u91cf\u5316\u4e86\u4e0d\u540c\u7b97\u6cd5\u7684\u53ef\u8c03\u7a7a\u95f4\uff0c\u4e3a\u7b97\u6cd5\u5206\u6790\u548c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7ef4\u5ea6\uff0c\u6700\u7ec8\u5e26\u6765\u6027\u80fd\u63d0\u5347"}}
{"id": "2510.18526", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18526", "abs": "https://arxiv.org/abs/2510.18526", "authors": ["Hanze Guo", "Jing Yao", "Xiao Zhou", "Xiaoyuan Yi", "Xing Xie"], "title": "Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models", "comment": "41 pages, 7 figures", "summary": "As large language models (LLMs) become increasingly integrated into\napplications serving users across diverse cultures, communities and\ndemographics, it is critical to align LLMs with pluralistic human values beyond\naverage principles (e.g., HHH). In psychological and social value theories such\nas Schwartz's Value Theory, pluralistic values are represented by multiple\nvalue dimensions paired with various priorities. However, existing methods\nencounter two challenges when aligning with such fine-grained value objectives:\n1) they often treat multiple values as independent and equally important,\nignoring their interdependence and relative priorities (value complexity); 2)\nthey struggle to precisely control nuanced value priorities, especially those\nunderrepresented ones (value steerability). To handle these challenges, we\npropose COUPLE, a COUnterfactual reasoning framework for PLuralistic valuE\nalignment. It introduces a structural causal model (SCM) to feature complex\ninterdependency and prioritization among features, as well as the causal\nrelationship between high-level value dimensions and behaviors. Moreover, it\napplies counterfactual reasoning to generate outputs aligned with any desired\nvalue objectives. Benefitting from explicit causal modeling, COUPLE also\nprovides better interpretability. We evaluate COUPLE on two datasets with\ndifferent value systems and demonstrate that COUPLE advances other baselines\nacross diverse types of value objectives.", "AI": {"tldr": "COUPLE\u662f\u4e00\u4e2a\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5904\u7406\u4ef7\u503c\u89c2\u7684\u590d\u6742\u6027\u548c\u53ef\u5f15\u5bfc\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u6587\u5316\u3001\u793e\u533a\u548c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u8d85\u8d8a\u5e73\u5747\u539f\u5219\uff08\u5982HHH\uff09\uff0c\u5c06\u6a21\u578b\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7ec6\u7c92\u5ea6\u4ef7\u503c\u76ee\u6807\u65f6\u9762\u4e34\u4ef7\u503c\u89c2\u590d\u6742\u6027\u548c\u53ef\u5f15\u5bfc\u6027\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faCOUPLE\u6846\u67b6\uff0c\u4f7f\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u6765\u8868\u5f81\u7279\u5f81\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u548c\u4f18\u5148\u7ea7\uff0c\u4ee5\u53ca\u9ad8\u5c42\u6b21\u4ef7\u503c\u7ef4\u5ea6\u4e0e\u884c\u4e3a\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002\u5e94\u7528\u53cd\u4e8b\u5b9e\u63a8\u7406\u751f\u6210\u7b26\u5408\u4efb\u610f\u671f\u671b\u4ef7\u503c\u76ee\u6807\u7684\u8f93\u51fa\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u4e0d\u540c\u4ef7\u503c\u4f53\u7cfb\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30COUPLE\uff0c\u7ed3\u679c\u663e\u793aCOUPLE\u5728\u591a\u79cd\u7c7b\u578b\u4ef7\u503c\u76ee\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "COUPLE\u901a\u8fc7\u663e\u5f0f\u56e0\u679c\u5efa\u6a21\u4e0d\u4ec5\u63d0\u5347\u4e86\u4ef7\u503c\u89c2\u5bf9\u9f50\u6027\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u5143\u4ef7\u503c\u89c2\u7684\u590d\u6742\u6027\u548c\u53ef\u5f15\u5bfc\u6027\u95ee\u9898\u3002"}}
{"id": "2510.18535", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18535", "abs": "https://arxiv.org/abs/2510.18535", "authors": ["Sarth Dubey", "Subimal Ghosh", "Udit Bhatia"], "title": "Physics-guided Emulators Reveal Resilience and Fragility under Operational Latencies and Outages", "comment": "45 pages, 5 main figures, 10 supplementary figures, 5 supplementary\n  tables", "summary": "Reliable hydrologic and flood forecasting requires models that remain stable\nwhen input data are delayed, missing, or inconsistent. However, most advances\nin rainfall-runoff prediction have been evaluated under ideal data conditions,\nemphasizing accuracy rather than operational resilience. Here, we develop an\noperationally ready emulator of the Global Flood Awareness System (GloFAS) that\ncouples long- and short-term memory networks with a relaxed water-balance\nconstraint to preserve physical coherence. Five architectures span a continuum\nof information availability: from complete historical and forecast forcings to\nscenarios with data latency and outages, allowing systematic evaluation of\nrobustness. Trained in minimally managed catchments across the United States\nand tested in more than 5,000 basins, including heavily regulated rivers in\nIndia, the emulator reproduces the hydrological core of GloFAS and degrades\nsmoothly as information quality declines. Transfer across contrasting\nhydroclimatic and management regimes yields reduced yet physically consistent\nperformance, defining the limits of generalization under data scarcity and\nhuman influence. The framework establishes operational robustness as a\nmeasurable property of hydrological machine learning and advances the design of\nreliable real-time forecasting systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u5c31\u7eea\u7684\u5168\u7403\u6d2a\u6c34\u9884\u8b66\u7cfb\u7edf\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u548c\u677e\u5f1b\u6c34\u91cf\u5e73\u8861\u7ea6\u675f\uff0c\u5728\u6570\u636e\u5ef6\u8fdf\u3001\u7f3a\u5931\u6216\u4e0d\u4e00\u81f4\u65f6\u4fdd\u6301\u7a33\u5b9a\u6027\u3002", "motivation": "\u53ef\u9760\u7684\u6c34\u6587\u548c\u6d2a\u6c34\u9884\u62a5\u9700\u8981\u6a21\u578b\u5728\u8f93\u5165\u6570\u636e\u5ef6\u8fdf\u3001\u7f3a\u5931\u6216\u4e0d\u4e00\u81f4\u65f6\u4fdd\u6301\u7a33\u5b9a\uff0c\u4f46\u5927\u591a\u6570\u964d\u96e8\u5f84\u6d41\u9884\u6d4b\u7684\u8fdb\u5c55\u90fd\u5728\u7406\u60f3\u6570\u636e\u6761\u4ef6\u4e0b\u8bc4\u4f30\uff0c\u5f3a\u8c03\u51c6\u786e\u6027\u800c\u975e\u64cd\u4f5c\u5f39\u6027\u3002", "method": "\u7ed3\u5408\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u4e0e\u677e\u5f1b\u6c34\u91cf\u5e73\u8861\u7ea6\u675f\uff0c\u5f00\u53d1\u4e94\u79cd\u67b6\u6784\u8986\u76d6\u4ece\u5b8c\u6574\u5386\u53f2\u9884\u62a5\u5230\u6570\u636e\u5ef6\u8fdf\u548c\u4e2d\u65ad\u7684\u4e0d\u540c\u4fe1\u606f\u53ef\u7528\u6027\u573a\u666f\uff0c\u5728\u7f8e\u56fd\u6700\u5c0f\u7ba1\u7406\u6d41\u57df\u8bad\u7ec3\u5e76\u57285000\u591a\u4e2a\u6d41\u57df\u6d4b\u8bd5\u3002", "result": "\u6a21\u62df\u5668\u91cd\u73b0\u4e86GloFAS\u7684\u6c34\u6587\u6838\u5fc3\uff0c\u968f\u7740\u4fe1\u606f\u8d28\u91cf\u4e0b\u964d\u800c\u5e73\u7a33\u9000\u5316\uff0c\u5728\u5bf9\u6bd4\u6c34\u6587\u6c14\u5019\u548c\u7ba1\u7406\u5236\u5ea6\u95f4\u7684\u8fc1\u79fb\u4ea7\u751f\u964d\u4f4e\u4f46\u7269\u7406\u4e00\u81f4\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u64cd\u4f5c\u7a33\u5065\u6027\u786e\u7acb\u4e3a\u6c34\u6587\u673a\u5668\u5b66\u4e60\u53ef\u6d4b\u91cf\u7684\u5c5e\u6027\uff0c\u63a8\u8fdb\u4e86\u53ef\u9760\u5b9e\u65f6\u9884\u62a5\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2510.18551", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.18551", "abs": "https://arxiv.org/abs/2510.18551", "authors": ["Yuncheng Hua", "Sion Weatherhead", "Mehdi Jafari", "Hao Xue", "Flora D. Salim"], "title": "SOCIA-Nabla: Textual Gradient Meets Multi-Agent Orchestration for Automated Simulator Generation", "comment": "11 pages, 1 figure, 2 tables. The paper is under review", "summary": "In this paper, we present SOCIA-Nabla, an end-to-end, agentic framework that\ntreats simulator construction asinstance optimization over code within a\ntextual computation graph. Specialized LLM-driven agents are embedded as graph\nnodes, and a workflow manager executes a loss-driven loop: code synthesis ->\nexecution -> evaluation -> code repair. The optimizer performs Textual-Gradient\nDescent (TGD), while human-in-the-loop interaction is reserved for task-spec\nconfirmation, minimizing expert effort and keeping the code itself as the\ntrainable object. Across three CPS tasks, i.e., User Modeling, Mask Adoption,\nand Personal Mobility, SOCIA-Nabla attains state-of-the-art overall accuracy.\nBy unifying multi-agent orchestration with a loss-aligned optimization view,\nSOCIA-Nabla converts brittle prompt pipelines into reproducible,\nconstraint-aware simulator code generation that scales across domains and\nsimulation granularities. This work is under review, and we will release the\ncode soon.", "AI": {"tldr": "SOCIA-Nabla\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6a21\u62df\u5668\u6784\u5efa\u89c6\u4e3a\u6587\u672c\u8ba1\u7b97\u56fe\u4e2d\u7684\u4ee3\u7801\u5b9e\u4f8b\u4f18\u5316\uff0c\u901a\u8fc7\u4e13\u95e8\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\u4f5c\u4e3a\u56fe\u8282\u70b9\uff0c\u6267\u884c\u4ee3\u7801\u5408\u6210\u2192\u6267\u884c\u2192\u8bc4\u4f30\u2192\u4ee3\u7801\u4fee\u590d\u7684\u635f\u5931\u9a71\u52a8\u5faa\u73af\u3002", "motivation": "\u5c06\u8106\u5f31\u7684\u63d0\u793a\u7ba1\u9053\u8f6c\u6362\u4e3a\u53ef\u590d\u73b0\u3001\u7ea6\u675f\u611f\u77e5\u7684\u6a21\u62df\u5668\u4ee3\u7801\u751f\u6210\uff0c\u7edf\u4e00\u591a\u667a\u80fd\u4f53\u7f16\u6392\u4e0e\u635f\u5931\u5bf9\u9f50\u7684\u4f18\u5316\u89c6\u89d2\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u548c\u6a21\u62df\u7c92\u5ea6\u7684\u6269\u5c55\u3002", "method": "\u4f7f\u7528\u6587\u672c\u68af\u5ea6\u4e0b\u964d(TGD)\u4f18\u5316\u5668\uff0c\u5728\u6587\u672c\u8ba1\u7b97\u56fe\u4e2d\u5d4c\u5165\u4e13\u95e8\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\u4f5c\u4e3a\u8282\u70b9\uff0c\u5de5\u4f5c\u6d41\u7ba1\u7406\u5668\u6267\u884c\u635f\u5931\u9a71\u52a8\u5faa\u73af\uff1a\u4ee3\u7801\u5408\u6210\u2192\u6267\u884c\u2192\u8bc4\u4f30\u2192\u4ee3\u7801\u4fee\u590d\uff0c\u4fdd\u7559\u4eba\u5728\u73af\u4ea4\u4e92\u7528\u4e8e\u4efb\u52a1\u89c4\u8303\u786e\u8ba4\u3002", "result": "\u5728\u4e09\u4e2aCPS\u4efb\u52a1\uff08\u7528\u6237\u5efa\u6a21\u3001\u53e3\u7f69\u91c7\u7528\u548c\u4e2a\u4eba\u79fb\u52a8\u6027\uff09\u4e2d\uff0cSOCIA-Nabla\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6574\u4f53\u51c6\u786e\u7387\u3002", "conclusion": "SOCIA-Nabla\u901a\u8fc7\u5c06\u4ee3\u7801\u672c\u8eab\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u5bf9\u8c61\uff0c\u6700\u5c0f\u5316\u4e13\u5bb6\u5de5\u4f5c\u91cf\uff0c\u5c06\u8106\u5f31\u7684\u63d0\u793a\u7ba1\u9053\u8f6c\u6362\u4e3a\u53ef\u590d\u73b0\u3001\u7ea6\u675f\u611f\u77e5\u7684\u6a21\u62df\u5668\u4ee3\u7801\u751f\u6210\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u548c\u6a21\u62df\u7c92\u5ea6\u7684\u6269\u5c55\u3002"}}
{"id": "2510.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18554", "abs": "https://arxiv.org/abs/2510.18554", "authors": ["Federico Barbero", "Xiangming Gu", "Christopher A. Choquette-Choo", "Chawin Sitawarin", "Matthew Jagielski", "Itay Yona", "Petar Veli\u010dkovi\u0107", "Ilia Shumailov", "Jamie Hayes"], "title": "Extracting alignment data in open models", "comment": null, "summary": "In this work, we show that it is possible to extract significant amounts of\nalignment training data from a post-trained model -- useful to steer the model\nto improve certain capabilities such as long-context reasoning, safety,\ninstruction following, and maths. While the majority of related work on\nmemorisation has focused on measuring success of training data extraction\nthrough string matching, we argue that embedding models are better suited for\nour specific goals. Distances measured through a high quality embedding model\ncan identify semantic similarities between strings that a different metric such\nas edit distance will struggle to capture. In fact, in our investigation,\napproximate string matching would have severely undercounted (by a conservative\nestimate of $10\\times$) the amount of data that can be extracted due to trivial\nartifacts that deflate the metric. Interestingly, we find that models readily\nregurgitate training data that was used in post-training phases such as SFT or\nRL. We show that this data can be then used to train a base model, recovering a\nmeaningful amount of the original performance. We believe our work exposes a\npossibly overlooked risk towards extracting alignment data. Finally, our work\nopens up an interesting discussion on the downstream effects of distillation\npractices: since models seem to be regurgitating aspects of their training set,\ndistillation can therefore be thought of as indirectly training on the model's\noriginal dataset.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u53ef\u4ee5\u4ece\u7ecf\u8fc7\u5bf9\u9f50\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u4e2d\u63d0\u53d6\u5927\u91cf\u5bf9\u9f50\u8bad\u7ec3\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u7528\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u5b89\u5168\u6027\u3001\u6307\u4ee4\u9075\u5faa\u548c\u6570\u5b66\u80fd\u529b\u3002\u4f7f\u7528\u5d4c\u5165\u6a21\u578b\u6bd4\u5b57\u7b26\u4e32\u5339\u914d\u66f4\u9002\u5408\u68c0\u6d4b\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "motivation": "\u63ed\u793a\u5bf9\u9f50\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u7684\u98ce\u9669\uff0c\u4ee5\u53ca\u84b8\u998f\u5b9e\u8df5\u53ef\u80fd\u5e26\u6765\u7684\u95f4\u63a5\u8bad\u7ec3\u539f\u59cb\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u9ad8\u8d28\u91cf\u7684\u5d4c\u5165\u6a21\u578b\u6765\u8861\u91cf\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684\u5b57\u7b26\u4e32\u5339\u914d\u65b9\u6cd5\uff0c\u4ece\u540e\u8bad\u7ec3\u6a21\u578b\uff08\u5982SFT\u6216RL\uff09\u4e2d\u63d0\u53d6\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u6210\u529f\u4ece\u5bf9\u9f50\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u4e2d\u63d0\u53d6\u4e86\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u7528\u4e8e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u5e76\u6062\u590d\u76f8\u5f53\u7a0b\u5ea6\u7684\u539f\u59cb\u6027\u80fd\u3002\u5b57\u7b26\u4e32\u5339\u914d\u65b9\u6cd5\u4f1a\u4e25\u91cd\u4f4e\u4f30\u53ef\u63d0\u53d6\u7684\u6570\u636e\u91cf\uff08\u7ea610\u500d\uff09\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u66b4\u9732\u4e86\u63d0\u53d6\u5bf9\u9f50\u6570\u636e\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5e76\u5f15\u53d1\u4e86\u5173\u4e8e\u84b8\u998f\u5b9e\u8df5\u4e0b\u6e38\u5f71\u54cd\u7684\u8ba8\u8bba\uff0c\u56e0\u4e3a\u6a21\u578b\u4f3c\u4e4e\u5728\u590d\u73b0\u5176\u8bad\u7ec3\u96c6\u7684\u67d0\u4e9b\u65b9\u9762\u3002"}}
{"id": "2510.18569", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18569", "abs": "https://arxiv.org/abs/2510.18569", "authors": ["Junhyeog Yun", "Hyoun Jun Lee", "Insu Jeon"], "title": "QuantEvolve: Automating Quantitative Strategy Discovery through Multi-Agent Evolutionary Framework", "comment": "25 pages, 13 figures. Accepted for oral presentation at the 2nd\n  Workshop on LLMs and Generative AI for Finance (AI4F), part of ACM ICAIF\n  2025, Singapore. Non-archival workshop", "summary": "Automating quantitative trading strategy development in dynamic markets is\nchallenging, especially with increasing demand for personalized investment\nsolutions. Existing methods often fail to explore the vast strategy space while\npreserving the diversity essential for robust performance across changing\nmarket conditions. We present QuantEvolve, an evolutionary framework that\ncombines quality-diversity optimization with hypothesis-driven strategy\ngeneration. QuantEvolve employs a feature map aligned with investor\npreferences, such as strategy type, risk profile, turnover, and return\ncharacteristics, to maintain a diverse set of effective strategies. It also\nintegrates a hypothesis-driven multi-agent system to systematically explore the\nstrategy space through iterative generation and evaluation. This approach\nproduces diverse, sophisticated strategies that adapt to both market regime\nshifts and individual investment needs. Empirical results show that QuantEvolve\noutperforms conventional baselines, validating its effectiveness. We release a\ndataset of evolved strategies to support future research.", "AI": {"tldr": "QuantEvolve\u662f\u4e00\u4e2a\u7ed3\u5408\u8d28\u91cf\u591a\u6837\u6027\u4f18\u5316\u548c\u5047\u8bbe\u9a71\u52a8\u7b56\u7565\u751f\u6210\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5f00\u53d1\u91cf\u5316\u4ea4\u6613\u7b56\u7565\uff0c\u80fd\u591f\u5728\u52a8\u6001\u5e02\u573a\u4e2d\u4fdd\u6301\u7b56\u7565\u591a\u6837\u6027\u5e76\u9002\u5e94\u5e02\u573a\u53d8\u5316\u3002", "motivation": "\u52a8\u6001\u5e02\u573a\u4e2d\u81ea\u52a8\u5316\u5f00\u53d1\u91cf\u5316\u4ea4\u6613\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u63a2\u7d22\u5e7f\u9614\u7b56\u7565\u7a7a\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u591a\u6837\u6027\uff0c\u800c\u4e2a\u6027\u5316\u6295\u8d44\u89e3\u51b3\u65b9\u6848\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002", "method": "\u4f7f\u7528\u4e0e\u6295\u8d44\u8005\u504f\u597d\u5bf9\u9f50\u7684\u7279\u5f81\u56fe\uff08\u7b56\u7565\u7c7b\u578b\u3001\u98ce\u9669\u7279\u5f81\u3001\u6362\u624b\u7387\u3001\u6536\u76ca\u7279\u5f81\u7b49\uff09\u6765\u7ef4\u6301\u591a\u6837\u5316\u6709\u6548\u7b56\u7565\uff0c\u5e76\u6574\u5408\u5047\u8bbe\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u548c\u8bc4\u4f30\u6765\u7cfb\u7edf\u63a2\u7d22\u7b56\u7565\u7a7a\u95f4\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660eQuantEvolve\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u53d1\u5e03\u4e86\u8fdb\u5316\u7b56\u7565\u6570\u636e\u96c6\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "conclusion": "QuantEvolve\u80fd\u591f\u4ea7\u751f\u591a\u6837\u5316\u3001\u590d\u6742\u7684\u7b56\u7565\uff0c\u65e2\u80fd\u9002\u5e94\u5e02\u573a\u673a\u5236\u53d8\u5316\uff0c\u53c8\u80fd\u6ee1\u8db3\u4e2a\u4eba\u6295\u8d44\u9700\u6c42\uff0c\u4e3a\u91cf\u5316\u4ea4\u6613\u7b56\u7565\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18619", "abs": "https://arxiv.org/abs/2510.18619", "authors": ["Wei Cai", "Jian Zhao", "Yuchen Yuan", "Tianle Zhang", "Ming Zhu", "Haichuan Tang", "Chi Zhang", "Xuelong Li"], "title": "VAR: Visual Attention Reasoning via Structured Search and Backtracking", "comment": null, "summary": "Multimodal Large Language Models (MLLMs), despite their advances, are\nhindered by their high hallucination tendency and heavy reliance on brittle,\nlinear reasoning processes, leading to failures in complex tasks. To address\nthese limitations, we introduce Visual Attention Reasoning (VAR), a novel\nframework that recasts grounded reasoning as a structured search over a\nreasoning trajectory space. VAR decomposes the reasoning process into two key\nstages: traceable evidence grounding and search-based chain-of-thought (CoT)\ngeneration, which incorporates a backtracking mechanism for self-correction.\nThe search is guided by a multi-faceted reward function with semantic and\ngeometric self-verification components, which penalize outputs that are not\nfaithfully grounded in the visual input. We provide a theoretical analysis for\nour search strategy, validating its capability to find the correct solution\nwith high probability. Experimental results show that our 7B model, VAR-7B,\nsets a new state-of-the-art on a comprehensive suite of hallucination and\nsafety benchmarks, significantly outperforming existing open-source models and\ndemonstrating competitive performance against leading proprietary systems.", "AI": {"tldr": "\u63d0\u51faVAR\u6846\u67b6\uff0c\u5c06\u89c6\u89c9\u63a8\u7406\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u641c\u7d22\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8bc1\u636e\u8ffd\u8e2a\u548c\u641c\u7d22\u5f0f\u601d\u7ef4\u94fe\u751f\u6210\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u9ad8\u5e7b\u89c9\u503e\u5411\u548c\u8106\u5f31\u7684\u7ebf\u6027\u63a8\u7406\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u590d\u6742\u4efb\u52a1\u5931\u8d25\u3002", "method": "\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u89e3\u4e3a\u53ef\u8ffd\u8e2a\u7684\u8bc1\u636e\u57fa\u7840\u548c\u641c\u7d22\u5f0f\u601d\u7ef4\u94fe\u751f\u6210\uff0c\u5305\u542b\u56de\u6eaf\u673a\u5236\u8fdb\u884c\u81ea\u6211\u4fee\u6b63\uff0c\u4f7f\u7528\u591a\u7ef4\u5ea6\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u8bed\u4e49\u548c\u51e0\u4f55\u81ea\u9a8c\u8bc1\u3002", "result": "7B\u6a21\u578bVAR-7B\u5728\u5e7b\u89c9\u548c\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b\u65b0\u7eaa\u5f55\uff0c\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4e0e\u9886\u5148\u4e13\u6709\u7cfb\u7edf\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "VAR\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u641c\u7d22\u548c\u81ea\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18628", "abs": "https://arxiv.org/abs/2510.18628", "authors": ["Gilles Audemard", "Sylvie Coste-Marquis", "Pierre Marquis", "Mehdi Sabiri", "Nicolas Szczepanski"], "title": "Leveraging Association Rules for Better Predictions and Better Explanations", "comment": "24 pages", "summary": "We present a new approach to classification that combines data and knowledge.\nIn this approach, data mining is used to derive association rules (possibly\nwith negations) from data. Those rules are leveraged to increase the predictive\nperformance of tree-based models (decision trees and random forests) used for a\nclassification task. They are also used to improve the corresponding\nexplanation task through the generation of abductive explanations that are more\ngeneral than those derivable without taking such rules into account.\nExperiments show that for the two tree-based models under consideration,\nbenefits can be offered by the approach in terms of predictive performance and\nin terms of explanation sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6570\u636e\u548c\u77e5\u8bc6\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u6316\u6398\u83b7\u53d6\u5173\u8054\u89c4\u5219\u6765\u63d0\u5347\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u548c\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6570\u636e\uff0c\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7684\u878d\u5165\u3002\u672c\u6587\u65e8\u5728\u7ed3\u5408\u6570\u636e\u6316\u6398\u5f97\u5230\u7684\u5173\u8054\u89c4\u5219\u6765\u589e\u5f3a\u6811\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u4ece\u6570\u636e\u4e2d\u6316\u6398\u5173\u8054\u89c4\u5219\uff08\u53ef\u80fd\u5305\u542b\u5426\u5b9a\uff09\uff0c\u5c06\u8fd9\u4e9b\u89c4\u5219\u6574\u5408\u5230\u51b3\u7b56\u6811\u548c\u968f\u673a\u68ee\u6797\u4e2d\uff0c\u7528\u4e8e\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u751f\u6210\u66f4\u6cdb\u5316\u7684\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u6811\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u751f\u6210\u66f4\u7b80\u6d01\u7684\u89e3\u91ca\u3002", "conclusion": "\u7ed3\u5408\u6570\u636e\u548c\u77e5\u8bc6\u7684\u5206\u7c7b\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u548c\u89e3\u91ca\u8d28\u91cf\u65b9\u9762\u90fd\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2510.18631", "categories": ["cs.AI", "cs.LO", "03B60"], "pdf": "https://arxiv.org/pdf/2510.18631", "abs": "https://arxiv.org/abs/2510.18631", "authors": ["Carlo Proietti", "Antonio Yuste-Ginel"], "title": "Comparative Expressivity for Structured Argumentation Frameworks with Uncertain Rules and Premises", "comment": null, "summary": "Modelling qualitative uncertainty in formal argumentation is essential both\nfor practical applications and theoretical understanding. Yet, most of the\nexisting works focus on \\textit{abstract} models for arguing with uncertainty.\nFollowing a recent trend in the literature, we tackle the open question of\nstudying plausible instantiations of these abstract models. To do so, we ground\nthe uncertainty of arguments in their components, structured within rules and\npremises. Our main technical contributions are: i) the introduction of a notion\nof expressivity that can handle abstract and structured formalisms, and ii) the\npresentation of both negative and positive expressivity results, comparing the\nexpressivity of abstract and structured models of argumentation with\nuncertainty. These results affect incomplete abstract argumentation frameworks,\nand their extension with dependencies, on the abstract side, and ASPIC+, on the\nstructured side.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f62\u5f0f\u8bba\u8bc1\u4e2d\u5b9a\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u6a21\u95ee\u9898\uff0c\u6bd4\u8f83\u4e86\u62bd\u8c61\u6a21\u578b\u548c\u7ed3\u6784\u5316\u6a21\u578b\u5728\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u7ed9\u51fa\u4e86\u6b63\u53cd\u4e24\u65b9\u9762\u7684\u8868\u8fbe\u6027\u7ed3\u679c\u3002", "motivation": "\u5728\u5f62\u5f0f\u8bba\u8bc1\u4e2d\u5efa\u6a21\u5b9a\u6027\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u548c\u7406\u8bba\u7406\u89e3\u90fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u5927\u591a\u5173\u6ce8\u62bd\u8c61\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u8fd9\u4e9b\u62bd\u8c61\u6a21\u578b\u7684\u5408\u7406\u5b9e\u4f8b\u5316\u3002", "method": "\u901a\u8fc7\u5c06\u8bba\u8bc1\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u4e8e\u5176\u7ec4\u6210\u90e8\u5206\uff08\u89c4\u5219\u548c\u524d\u63d0\uff09\u6765\u6784\u5efa\u7ed3\u6784\u5316\u6a21\u578b\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u80fd\u591f\u5904\u7406\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u5f62\u5f0f\u7684\u8868\u8fbe\u6027\u6982\u5ff5\uff0c\u5e76\u6bd4\u8f83\u4e86\u62bd\u8c61\u6a21\u578b\u548c\u7ed3\u6784\u5316\u6a21\u578b\u7684\u8868\u8fbe\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u6b63\u53cd\u4e24\u65b9\u9762\u7684\u8868\u8fbe\u6027\u7ed3\u679c\uff0c\u5f71\u54cd\u4e86\u4e0d\u5b8c\u6574\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u53ca\u5176\u4f9d\u8d56\u6269\u5c55\uff08\u62bd\u8c61\u65b9\u9762\uff09\u548cASPIC+\uff08\u7ed3\u6784\u5316\u65b9\u9762\uff09\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f62\u5f0f\u8bba\u8bc1\u4e2d\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u8868\u8fbe\u6027\uff0c\u5bf9\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.18633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18633", "abs": "https://arxiv.org/abs/2510.18633", "authors": ["Roxana Petcu", "Kenton Murray", "Daniel Khashabi", "Evangelos Kanoulas", "Maarten de Rijke", "Dawn Lawrie", "Kevin Duh"], "title": "Query Decomposition for RAG: Balancing Exploration-Exploitation", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems address complex user requests by\ndecomposing them into subqueries, retrieving potentially relevant documents for\neach, and then aggregating them to generate an answer. Efficiently selecting\ninformative documents requires balancing a key trade-off: (i) retrieving\nbroadly enough to capture all the relevant material, and (ii) limiting\nretrieval to avoid excessive noise and computational cost. We formulate query\ndecomposition and document retrieval in an exploitation-exploration setting,\nwhere retrieving one document at a time builds a belief about the utility of a\ngiven sub-query and informs the decision to continue exploiting or exploring an\nalternative. We experiment with a variety of bandit learning methods and\ndemonstrate their effectiveness in dynamically selecting the most informative\nsub-queries. Our main finding is that estimating document relevance using rank\ninformation and human judgments yields a 35% gain in document-level precision,\n15% increase in {\\alpha}-nDCG, and better performance on the downstream task of\nlong-form generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u5b50\u67e5\u8be2\u6765\u5e73\u8861\u68c0\u7d22\u7684\u5e7f\u5ea6\u548c\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u6863\u68c0\u7d22\u7cbe\u5ea6\u548c\u957f\u6587\u672c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\u5e73\u8861\u68c0\u7d22\u5e7f\u5ea6\u4e0e\u6548\u7387\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\uff0c\u65e2\u8981\u6355\u83b7\u6240\u6709\u76f8\u5173\u6750\u6599\uff0c\u53c8\u8981\u907f\u514d\u8fc7\u5ea6\u68c0\u7d22\u5e26\u6765\u7684\u566a\u58f0\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5c06\u67e5\u8be2\u5206\u89e3\u548c\u6587\u6863\u68c0\u7d22\u5efa\u6a21\u4e3a\u5229\u7528-\u63a2\u7d22\u8bbe\u7f6e\uff0c\u4f7f\u7528\u591a\u79cd\u8001\u864e\u673a\u5b66\u4e60\u65b9\u6cd5\u52a8\u6001\u9009\u62e9\u6700\u6709\u4fe1\u606f\u91cf\u7684\u5b50\u67e5\u8be2\uff0c\u5e76\u5229\u7528\u6392\u540d\u4fe1\u606f\u548c\u4eba\u5de5\u5224\u65ad\u6765\u4f30\u8ba1\u6587\u6863\u76f8\u5173\u6027\u3002", "result": "\u4f7f\u7528\u6392\u540d\u4fe1\u606f\u548c\u4eba\u5de5\u5224\u65ad\u4f30\u8ba1\u6587\u6863\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u4e86\u6587\u6863\u7ea7\u7cbe\u5ea635%\u7684\u63d0\u5347\uff0c\u03b1-nDCG\u6307\u680715%\u7684\u589e\u957f\uff0c\u5e76\u5728\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u57fa\u4e8e\u8001\u864e\u673a\u5b66\u4e60\u7684\u52a8\u6001\u5b50\u67e5\u8be2\u9009\u62e9\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u68c0\u7d22\u7684\u5229\u7528\u4e0e\u63a2\u7d22\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2510.18659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18659", "abs": "https://arxiv.org/abs/2510.18659", "authors": ["Dong Yun", "Marco Schouten", "Dim Papadopoulos"], "title": "Sherlock Your Queries: Learning to Ask the Right Questions for Dialogue-Based Retrieval", "comment": null, "summary": "User queries in information retrieval are often ambiguous, making it\nchallenging for systems to identify a user's target from a single query. While\nrecent dialogue-based interactive retrieval systems can clarify user intent,\nthey are inefficient as they often lack an explicit strategy to ask the most\ninformative questions. To address this limitation, we propose SherlockLLM, a\ndialogue-driven retrieval framework that learns an optimal questioning strategy\nvia Reinforcement Learning (RL) and avoids the need for large-scale annotated\ndialogue data. In our framework, an agent is trained to generate a sequence of\nbinary questions to efficiently narrow down the search space. To validate our\napproach, we introduce a benchmark with both structured and unstructured tasks.\nExperimental results show that SherlockLLM is a robust and efficient solution.\nOn the structured tasks, its performance matches strong baselines and\napproaches the theoretical optimal defined by binary search. On the challenging\nunstructured task, our agent significantly outperforms these baselines,\nshowcasing its ability to learn a highly effective information-seeking dialogue\npolicy.", "AI": {"tldr": "SherlockLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u8bdd\u9a71\u52a8\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u4e8c\u8fdb\u5236\u95ee\u9898\u5e8f\u5217\u6765\u9ad8\u6548\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u89e3\u51b3\u4fe1\u606f\u68c0\u7d22\u4e2d\u7528\u6237\u67e5\u8be2\u6a21\u7cca\u7684\u95ee\u9898\u3002", "motivation": "\u4fe1\u606f\u68c0\u7d22\u4e2d\u7528\u6237\u67e5\u8be2\u5f80\u5f80\u5177\u6709\u6a21\u7cca\u6027\uff0c\u73b0\u6709\u5bf9\u8bdd\u5f0f\u4ea4\u4e92\u68c0\u7d22\u7cfb\u7edf\u7f3a\u4e4f\u660e\u786e\u7684\u7b56\u7565\u6765\u8be2\u95ee\u6700\u6709\u4fe1\u606f\u91cf\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7406\u751f\u6210\u4e8c\u8fdb\u5236\u95ee\u9898\u5e8f\u5217\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u6807\u6ce8\u5bf9\u8bdd\u6570\u636e\uff0c\u901a\u8fc7\u4f18\u5316\u63d0\u95ee\u7b56\u7565\u6765\u9ad8\u6548\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\uff0c\u63a5\u8fd1\u4e8c\u5206\u641c\u7d22\u7684\u7406\u8bba\u6700\u4f18\uff1b\u5728\u975e\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86\u5b66\u4e60\u9ad8\u6548\u4fe1\u606f\u5bfb\u6c42\u5bf9\u8bdd\u7b56\u7565\u7684\u80fd\u529b\u3002", "conclusion": "SherlockLLM\u662f\u4e00\u4e2a\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b66\u4e60\u9ad8\u5ea6\u6709\u6548\u7684\u4fe1\u606f\u5bfb\u6c42\u5bf9\u8bdd\u7b56\u7565\uff0c\u5728\u6a21\u7cca\u67e5\u8be2\u7684\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.18751", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.18751", "abs": "https://arxiv.org/abs/2510.18751", "authors": ["Patterson Hsieh", "Jerry Yeh", "Mao-Chi He", "Wen-Han Hsieh", "Elvis Hsieh"], "title": "Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation", "comment": null, "summary": "Climate change is intensifying the occurrence of harmful algal bloom (HAB),\nparticularly cyanobacteria, which threaten aquatic ecosystems and human health\nthrough oxygen depletion, toxin release, and disruption of marine biodiversity.\nTraditional monitoring approaches, such as manual water sampling, remain\nlabor-intensive and limited in spatial and temporal coverage. Recent advances\nin vision-language models (VLMs) for remote sensing have shown potential for\nscalable AI-driven solutions, yet challenges remain in reasoning over imagery\nand quantifying bloom severity. In this work, we introduce ALGae Observation\nand Segmentation (ALGOS), a segmentation-and-reasoning system for HAB\nmonitoring that combines remote sensing image understanding with severity\nestimation. Our approach integrates GeoSAM-assisted human evaluation for\nhigh-quality segmentation mask curation and fine-tunes vision language model on\nseverity prediction using the Cyanobacteria Aggregated Manual Labels (CAML)\nfrom NASA. Experiments demonstrate that ALGOS achieves robust performance on\nboth segmentation and severity-level estimation, paving the way toward\npractical and automated cyanobacterial monitoring systems.", "AI": {"tldr": "ALGOS\u662f\u4e00\u4e2a\u7528\u4e8e\u6709\u5bb3\u85fb\u534e\u76d1\u6d4b\u7684\u5206\u5272\u4e0e\u63a8\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u9065\u611f\u56fe\u50cf\u7406\u89e3\u548c\u4e25\u91cd\u7a0b\u5ea6\u4f30\u8ba1\uff0c\u901a\u8fc7GeoSAM\u8f85\u52a9\u4eba\u5de5\u8bc4\u4f30\u751f\u6210\u9ad8\u8d28\u91cf\u5206\u5272\u63a9\u7801\uff0c\u5e76\u57fa\u4e8eNASA\u6570\u636e\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e25\u91cd\u7a0b\u5ea6\u9884\u6d4b\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u4e86\u6709\u5bb3\u85fb\u534e\u7684\u53d1\u751f\uff0c\u7279\u522b\u662f\u84dd\u85fb\uff0c\u5a01\u80c1\u6c34\u751f\u751f\u6001\u7cfb\u7edf\u548c\u4eba\u7c7b\u5065\u5eb7\u3002\u4f20\u7edf\u76d1\u6d4b\u65b9\u6cd5\u52b3\u52a8\u5bc6\u96c6\u4e14\u65f6\u7a7a\u8986\u76d6\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408GeoSAM\u8f85\u52a9\u4eba\u5de5\u8bc4\u4f30\u8fdb\u884c\u9ad8\u8d28\u91cf\u5206\u5272\u63a9\u7801\u751f\u6210\uff0c\u5e76\u57fa\u4e8eNASA\u7684CAML\u6570\u636e\u96c6\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e25\u91cd\u7a0b\u5ea6\u9884\u6d4b\u3002", "result": "ALGOS\u5728\u5206\u5272\u548c\u4e25\u91cd\u7a0b\u5ea6\u4f30\u8ba1\u65b9\u9762\u5747\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5b9e\u73b0\u5b9e\u7528\u548c\u81ea\u52a8\u5316\u7684\u84dd\u85fb\u76d1\u6d4b\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.18803", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18803", "abs": "https://arxiv.org/abs/2510.18803", "authors": ["Shirin Tavakoli Kafiabad", "Andrea Schiffauerova", "Ashkan Ebadi"], "title": "Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location", "comment": "35 pages", "summary": "Optimizing national scientific investment requires a clear understanding of\nevolving research trends and the demographic and geographical forces shaping\nthem, particularly in light of commitments to equity, diversity, and inclusion.\nThis study addresses this need by analyzing 18 years (2005-2022) of research\nproposals funded by the Natural Sciences and Engineering Research Council of\nCanada (NSERC). We conducted a comprehensive comparative evaluation of three\ntopic modelling approaches: Latent Dirichlet Allocation (LDA), Structural Topic\nModelling (STM), and BERTopic. We also introduced a novel algorithm, named\nCOFFEE, designed to enable robust covariate effect estimation for BERTopic.\nThis advancement addresses a significant gap, as BERTopic lacks a native\nfunction for covariate analysis, unlike the probabilistic STM. Our findings\nhighlight that while all models effectively delineate core scientific domains,\nBERTopic outperformed by consistently identifying more granular, coherent, and\nemergent themes, such as the rapid expansion of artificial intelligence.\nAdditionally, the covariate analysis, powered by COFFEE, confirmed distinct\nprovincial research specializations and revealed consistent gender-based\nthematic patterns across various scientific disciplines. These insights offer a\nrobust empirical foundation for funding organizations to formulate more\nequitable and impactful funding strategies, thereby enhancing the effectiveness\nof the scientific ecosystem.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86LDA\u3001STM\u548cBERTopic\u4e09\u79cd\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5728\u5206\u6790\u52a0\u62ff\u5927NSERC\u7814\u7a76\u63d0\u6848\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u5f00\u53d1\u4e86COFFEE\u7b97\u6cd5\u6765\u589e\u5f3aBERTopic\u7684\u534f\u53d8\u91cf\u5206\u6790\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u7701\u7ea7\u7814\u7a76\u4e13\u4e1a\u5316\u548c\u6027\u522b\u4e3b\u9898\u6a21\u5f0f\u3002", "motivation": "\u4f18\u5316\u56fd\u5bb6\u79d1\u5b66\u6295\u8d44\u9700\u8981\u4e86\u89e3\u7814\u7a76\u8d8b\u52bf\u6f14\u53d8\u53ca\u4eba\u53e3\u5730\u7406\u56e0\u7d20\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5173\u6ce8\u516c\u5e73\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u7684\u80cc\u666f\u4e0b\u3002", "method": "\u5206\u6790\u4e8618\u5e74NSERC\u8d44\u52a9\u7684\u7814\u7a76\u63d0\u6848\uff0c\u6bd4\u8f83LDA\u3001STM\u548cBERTopic\u4e09\u79cd\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1COFFEE\u7b97\u6cd5\u6765\u589e\u5f3aBERTopic\u7684\u534f\u53d8\u91cf\u5206\u6790\u3002", "result": "BERTopic\u5728\u8bc6\u522b\u66f4\u7ec6\u7c92\u5ea6\u3001\u8fde\u8d2f\u548c\u65b0\u5174\u4e3b\u9898\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5982\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u6269\u5f20\uff1b\u534f\u53d8\u91cf\u5206\u6790\u63ed\u793a\u4e86\u7701\u7ea7\u7814\u7a76\u4e13\u4e1a\u5316\u548c\u8de8\u5b66\u79d1\u4e00\u81f4\u7684\u6027\u522b\u4e3b\u9898\u6a21\u5f0f\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8d44\u52a9\u673a\u6784\u5236\u5b9a\u66f4\u516c\u5e73\u548c\u6709\u6548\u7684\u8d44\u52a9\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\u7684\u6548\u7387\u3002"}}
