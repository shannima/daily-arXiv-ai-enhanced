{"id": "2510.19835", "categories": ["cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19835", "abs": "https://arxiv.org/abs/2510.19835", "authors": ["Max B. Zhao", "Fei Li"], "title": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "comment": "29 pages, 10 figures, accepted by Quantum Information & Computation\n  on August 6, 2025", "summary": "We propose and evaluate a quantum-inspired algorithm for solving Quadratic\nUnconstrained Binary Optimization (QUBO) problems, which are mathematically\nequivalent to finding ground states of Ising spin-glass Hamiltonians. The\nalgorithm employs Matrix Product States (MPS) to compactly represent large\nsuperpositions of spin configurations and utilizes a discrete driving schedule\nto guide the MPS toward the ground state. At each step, a driver Hamiltonian --\nincorporating a transverse magnetic field -- is combined with the problem\nHamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is\nupdated using the standard Density Matrix Renormalization Group (DMRG) method,\nwhich iteratively minimizes the system's energy via multiple sweeps across the\nspin chain. Despite its heuristic nature, the algorithm reliably identifies\nglobal minima, not merely near-optimal solutions, across diverse QUBO\ninstances. We first demonstrate its effectiveness on intermediate-level Sudoku\npuzzles from publicly available sources, involving over $200$ Ising spins with\nlong-range couplings dictated by constraint satisfaction. We then apply the\nalgorithm to MaxCut problems from the Biq Mac library, successfully solving\ninstances with up to $251$ nodes and $3,265$ edges. We discuss the advantages\nof this quantum-inspired approach, including its scalability, generalizability,\nand suitability for industrial-scale QUBO applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u91cf\u5b50\u542f\u53d1\u7b97\u6cd5\uff0c\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u548c\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u89e3\u51b3QUBO\u95ee\u9898\uff0c\u5728Sudoku\u548cMaxCut\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5728\u6570\u5b66\u4e0a\u7b49\u4ef7\u4e8e\u5bfb\u627e\u4f0a\u8f9b\u81ea\u65cb\u73bb\u7483\u54c8\u5bc6\u987f\u91cf\u7684\u57fa\u6001\uff0c\u9700\u8981\u9ad8\u6548\u7b97\u6cd5\u6765\u5904\u7406\u5de5\u4e1a\u89c4\u6a21\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u77e9\u9635\u4e58\u79ef\u6001\u7d27\u51d1\u8868\u793a\u81ea\u65cb\u6784\u578b\u7684\u5927\u53e0\u52a0\uff0c\u7ed3\u5408\u79bb\u6563\u9a71\u52a8\u8c03\u5ea6\u5f15\u5bfcMPS\u5411\u57fa\u6001\u6f14\u5316\uff0c\u901a\u8fc7DMRG\u65b9\u6cd5\u8fed\u4ee3\u6700\u5c0f\u5316\u7cfb\u7edf\u80fd\u91cf\u3002", "result": "\u7b97\u6cd5\u53ef\u9760\u5730\u8bc6\u522b\u5168\u5c40\u6700\u5c0f\u503c\u800c\u975e\u8fd1\u4f3c\u89e3\uff0c\u6210\u529f\u89e3\u51b3\u8d85\u8fc7200\u4e2a\u81ea\u65cb\u7684Sudoku\u95ee\u9898\u548cBiq Mac\u5e93\u4e2d\u6700\u591a251\u8282\u70b9\u30013265\u8fb9\u7684MaxCut\u95ee\u9898\u3002", "conclusion": "\u8be5\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u901a\u7528\u6027\u548c\u9002\u7528\u4e8e\u5de5\u4e1a\u89c4\u6a21QUBO\u5e94\u7528\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5e94\u7528\u4e8e\u80fd\u6e90\u7cfb\u7edf\u5206\u6790\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u53ef\u9760\u6027\uff0c\u586b\u8865\u4e86\u5f53\u524d\u9a8c\u8bc1\u5b9e\u8df5\u53ea\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u800c\u5ffd\u7565\u903b\u8f91\u5b8c\u6574\u6027\u7684\u7a7a\u767d\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u5728\u80fd\u6e90\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u7684\u63a8\u7406\u662f\u5426\u6b63\u786e\u3002\u73b0\u6709\u7684\u9a8c\u8bc1\u5b9e\u8df5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u672a\u6d4b\u8bd5\u5206\u6790\u7ed3\u8bba\u7684\u903b\u8f91\u5b8c\u6574\u6027\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u6574\u5408\u4e86\u4e94\u4e2a\u5b50\u6307\u6807\uff1a\u51c6\u786e\u6027\u3001\u63a8\u7406\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7eaa\u5f8b\u3001\u653f\u7b56\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5e76\u4f7f\u7528\u5f00\u653e\u6280\u672f\u7ecf\u6d4e\u6570\u636e\u96c6\uff08NREL ATB 2024\u3001DOE H2A/H2New\u3001IEA WEO 2024\uff09\u5728\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002\u6d4b\u8bd5\u4e86\u56db\u4e2a\u524d\u6cbf\u6a21\u578b\uff08GPT-4/5\u3001Claude 4.5 Sonnet\u3001Gemini 2.5 Pro\u3001Llama 3 70B\uff09\u3002", "result": "\u7ed3\u679c\u8868\u660e\u63a8\u7406\u53ef\u9760\u6027\u53ef\u4ee5\u5ba2\u89c2\u6d4b\u91cf\u3002GPT-4/5\u548cClaude 4.5 Sonnet\u5b9e\u73b0\u4e86\u6301\u7eed\u4e14\u7b26\u5408\u653f\u7b56\u7684\u63a8\u7406\uff08\u5206\u6790\u53ef\u9760\u6027\u6307\u6570\u5927\u4e8e90\uff09\uff0cGemini 2.5 Pro\u8868\u73b0\u51fa\u4e2d\u7b49\u7a33\u5b9a\u6027\uff0c\u800cLlama 3 70B\u4f4e\u4e8e\u4e13\u4e1a\u9608\u503c\u3002\u7edf\u8ba1\u9a8c\u8bc1\u786e\u8ba4\u8fd9\u4e9b\u5dee\u5f02\u663e\u8457\u4e14\u53ef\u590d\u73b0\u3002", "conclusion": "ARB\u5efa\u7acb\u4e86\u80fd\u6e90\u6587\u732e\u4e2d\u9996\u4e2a\u9a8c\u8bc1\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u56e0\u679c\u3001\u6982\u7387\u548c\u653f\u7b56\u9a71\u52a8\u63a8\u7406\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u4e3a\u5168\u7403\u80fd\u6e90\u8f6c\u578b\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660e\u7684\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2510.19838", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19838", "abs": "https://arxiv.org/abs/2510.19838", "authors": ["Shiqi He", "Yue Cui", "Xinyu Ma", "Yaliang Li", "Bolin Ding", "Mosharaf Chowdhury"], "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "comment": null, "summary": "Autonomous web agents powered by large language models (LLMs) show strong\npotential for performing goal-oriented tasks such as information retrieval,\nreport generation, and online transactions. These agents mark a key step toward\npractical embodied reasoning in open web environments. However, existing\napproaches remain limited in reasoning depth and efficiency: vanilla linear\nmethods fail at multi-step reasoning and lack effective backtracking, while\nother search strategies are coarse-grained and computationally costly. We\nintroduce Branch-and-Browse, a fine-grained web agent framework that unifies\nstructured reasoning-acting, contextual memory, and efficient execution. It (i)\nemploys explicit subtask management with tree-structured exploration for\ncontrollable multi-branch reasoning, (ii) bootstraps exploration through\nefficient web state replay with background reasoning, and (iii) leverages a\npage action memory to share explored actions within and across sessions. On the\nWebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\%\nand reduces execution time by up to 40.4\\% relative to state-of-the-art\nmethods. These results demonstrate that Branch-and-Browse is a reliable and\nefficient framework for LLM-based web agents.", "AI": {"tldr": "Branch-and-Browse\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u7f51\u9875\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u72b6\u7ed3\u6784\u63a2\u7d22\u3001\u7f51\u9875\u72b6\u6001\u91cd\u653e\u548c\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u9875\u4ee3\u7406\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u6df1\u5ea6\u548c\u6267\u884c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u7f51\u9875\u4ee3\u7406\u5728\u63a8\u7406\u6df1\u5ea6\u548c\u6267\u884c\u6548\u7387\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u7ebf\u6027\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u591a\u6b65\u63a8\u7406\u4e14\u7f3a\u4e4f\u6709\u6548\u56de\u6eaf\uff0c\u800c\u5176\u4ed6\u641c\u7d22\u7b56\u7565\u5219\u7c92\u5ea6\u7c97\u7cd9\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\uff1a(1) \u663e\u5f0f\u5b50\u4efb\u52a1\u7ba1\u7406\u548c\u6811\u72b6\u7ed3\u6784\u63a2\u7d22\u5b9e\u73b0\u53ef\u63a7\u7684\u591a\u5206\u652f\u63a8\u7406\uff1b(2) \u901a\u8fc7\u5e26\u80cc\u666f\u63a8\u7406\u7684\u9ad8\u6548\u7f51\u9875\u72b6\u6001\u91cd\u653e\u6765\u5f15\u5bfc\u63a2\u7d22\uff1b(3) \u5229\u7528\u9875\u9762\u52a8\u4f5c\u8bb0\u5fc6\u5728\u4f1a\u8bdd\u5185\u5916\u5171\u4eab\u5df2\u63a2\u7d22\u7684\u52a8\u4f5c\u3002", "result": "\u5728WebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBranch-and-Browse\u5b9e\u73b0\u4e8635.8%\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e8640.4%\u3002", "conclusion": "Branch-and-Browse\u662f\u4e00\u4e2a\u53ef\u9760\u4e14\u9ad8\u6548\u7684LLM\u7f51\u9875\u4ee3\u7406\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u5f00\u653e\u7f51\u9875\u73af\u5883\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u548c\u6267\u884c\u6548\u7387\u3002"}}
{"id": "2510.19842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19842", "abs": "https://arxiv.org/abs/2510.19842", "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"], "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "comment": "28 pages, 6 figures. Comments are welcome", "summary": "Large Language Models (LLMs) demonstrate strong performance on mathematical\nproblems when prompted with Chain-of-Thought (CoT), yet it remains unclear\nwhether this success stems from search, rote procedures, or rule-consistent\nreasoning. To address this, we propose modeling CoT as a certain rule-based\nstochastic process over directed acyclic graphs (DAGs), where nodes represent\nintermediate derivation states and edges encode rule applications. Within this\nframework, we introduce logical closeness, a metric that quantifies how well a\nmodel's CoT trajectory (i.e., the LLM's final output) adheres to the DAG\nstructure, providing evaluation beyond classical PASS@k metrics. Building on\nthis, we introduce the DAG-MATH CoT format and construct a benchmark that\nguides LLMs to generate CoT trajectories in this format, thereby enabling the\nevaluation of their reasoning ability under our framework. Across standard\nmathematical reasoning datasets, our analysis uncovers statistically\nsignificant differences in reasoning fidelity among representative LLM\nfamilies-even when PASS@k is comparable-highlighting gaps between final-answer\naccuracy and rule-consistent derivation. Our framework provides a balance\nbetween free-form CoT and formal proofs systems, offering actionable\ndiagnostics for LLMs reasoning evaluation. Our benchmark and code are available\nat: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe(DAG)\u7684\u6846\u67b6\u6765\u8bc4\u4f30LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u903b\u8f91\u4e00\u81f4\u6027\uff0c\u5f15\u5165\u903b\u8f91\u7d27\u5bc6\u5ea6\u6307\u6807\uff0c\u63ed\u793aPASS@k\u6307\u6807\u65e0\u6cd5\u68c0\u6d4b\u7684\u63a8\u7406\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709Chain-of-Thought(CoT)\u65b9\u6cd5\u65e0\u6cd5\u786e\u5b9aLLMs\u7684\u6210\u529f\u662f\u6e90\u4e8e\u641c\u7d22\u3001\u6b7b\u8bb0\u786c\u80cc\u8fd8\u662f\u89c4\u5219\u4e00\u81f4\u63a8\u7406\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5c06CoT\u5efa\u6a21\u4e3a\u57fa\u4e8e\u89c4\u5219\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u5728DAG\u4e0a\u5b9a\u4e49\u903b\u8f91\u7d27\u5bc6\u5ea6\u6307\u6807\uff0c\u6784\u5efaDAG-MATH CoT\u683c\u5f0f\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u6807\u51c6\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u53d1\u73b0\u4ee3\u8868\u6027LLM\u5bb6\u65cf\u95f4\u5b58\u5728\u7edf\u8ba1\u663e\u8457\u7684\u63a8\u7406\u4fdd\u771f\u5ea6\u5dee\u5f02\uff0c\u5373\u4f7fPASS@k\u6307\u6807\u76f8\u5f53\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u81ea\u7531\u5f62\u5f0fCoT\u548c\u5f62\u5f0f\u8bc1\u660e\u7cfb\u7edf\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3aLLMs\u63a8\u7406\u8bc4\u4f30\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2510.19949", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19949", "abs": "https://arxiv.org/abs/2510.19949", "authors": ["Mathieu Andreux", "M\u00e4rt Bakler", "Yanael Barbier", "Hamza Ben Chekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Nathan Bout", "Matthias Brunel", "Aleix Cambray", "Pierre-Louis Cedoz", "Antoine Chassang", "Gautier Cloix", "Ethan Connelly", "Alexandra Constantinou", "Ramzi De Coster", "Hubert de la Jonquiere", "Aur\u00e9lien Delfosse", "Maxime Delpit", "Alexis Deprez", "Augustin Derupti", "Mathieu Diaz", "Shannon D'Souza", "Julie Dujardin", "Abai Edmund", "Michael Eickenberg", "Armand Fatalot", "Wissem Felissi", "Isaac Herring", "Xavier Koegler", "Erwan Le Jumeau de Kergaradec", "Aur\u00e9lien Lac", "Maxime Langevin", "Corentin Lauverjat", "Antonio Loison", "Avshalom Manevich", "Axel Moyal", "Axel Nguyen Kerbel", "Marinela Parovic", "Julien Revelle", "Guillaume Richard", "Mats Richter", "Ronan Riochet", "Mar\u00eda Santos", "Romain Savidan", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Ivan Valentini", "Tony Wu", "Laura Yie", "Kai Yuan", "Jevgenij Zubovskij"], "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "comment": "21 pages, 9 figures, 2 tables", "summary": "Building agents that generalize across web, desktop, and mobile environments\nremains an open challenge, as prior systems rely on environment-specific\ninterfaces that limit cross-platform deployment. We introduce Surfer 2, a\nunified architecture operating purely from visual observations that achieves\nstate-of-the-art performance across all three environments. Surfer 2 integrates\nhierarchical context management, decoupled planning and execution, and\nself-verification with adaptive recovery, enabling reliable operation over long\ntask horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on\nWebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior\nsystems without task-specific fine-tuning. With multiple attempts, Surfer 2\nexceeds human performance on all benchmarks. These results demonstrate that\nsystematic orchestration amplifies foundation model capabilities and enables\ngeneral-purpose computer control through visual interaction alone, while\ncalling for a next-generation vision language model to achieve Pareto-optimal\ncost-efficiency.", "AI": {"tldr": "Surfer 2\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u89c2\u5bdf\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5728\u7f51\u9875\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5373\u53ef\u8d85\u8d8a\u6240\u6709\u5148\u524d\u7cfb\u7edf\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56\u73af\u5883\u7279\u5b9a\u63a5\u53e3\u3001\u9650\u5236\u8de8\u5e73\u53f0\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u6784\u5efa\u80fd\u591f\u5728\u7f51\u9875\u3001\u684c\u9762\u548c\u79fb\u52a8\u73af\u5883\u4e2d\u901a\u7528\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "\u96c6\u6210\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u89e3\u8026\u89c4\u5212\u4e0e\u6267\u884c\u3001\u4ee5\u53ca\u5e26\u81ea\u9002\u5e94\u6062\u590d\u7684\u81ea\u6211\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u957f\u4efb\u52a1\u5468\u671f\u7684\u53ef\u9760\u64cd\u4f5c\u3002", "result": "\u5728WebVoyager\u4e0a\u8fbe\u523097.1%\u51c6\u786e\u7387\uff0cWebArena 69.6%\uff0cOSWorld 60.1%\uff0cAndroidWorld 87.1%\uff0c\u591a\u5c1d\u8bd5\u4e0b\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7f16\u6392\u80fd\u591f\u653e\u5927\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u4ec5\u901a\u8fc7\u89c6\u89c9\u4ea4\u4e92\u5b9e\u73b0\u901a\u7528\u8ba1\u7b97\u673a\u63a7\u5236\uff0c\u540c\u65f6\u9700\u8981\u4e0b\u4e00\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6765\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6210\u672c\u6548\u7387\u3002"}}
{"id": "2510.19954", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19954", "abs": "https://arxiv.org/abs/2510.19954", "authors": ["Joseph Meyer", "Divyansha Lachi", "Reza Mohammadi", "Roshan Reddy Upendra", "Eva L. Dyer", "Mark Li", "Tom Palczewski"], "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "comment": "6 pages", "summary": "Relational multi-table data is common in domains such as e-commerce,\nhealthcare, and scientific research, and can be naturally represented as\nheterogeneous temporal graphs with multi-modal node attributes. Existing graph\nneural networks (GNNs) rely on schema-specific feature encoders, requiring\nseparate modules for each node type and feature column, which hinders\nscalability and parameter sharing. We introduce RELATE (Relational Encoder for\nLatent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature\nencoder that can be used with any general purpose GNN. RELATE employs shared\nmodality-specific encoders for categorical, numerical, textual, and temporal\nattributes, followed by a Perceiver-style cross-attention module that\naggregates features into a fixed-size, permutation-invariant node\nrepresentation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,\nwhere it achieves performance within 3% of schema-specific encoders while\nreducing parameter counts by up to 5x. This design supports varying schemas and\nenables multi-dataset pretraining for general-purpose GNNs, paving the way\ntoward foundation models for relational graph data.", "AI": {"tldr": "RELATE\u662f\u4e00\u4e2a\u6a21\u5f0f\u65e0\u5173\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5904\u7406\u591a\u6a21\u6001\u8282\u70b9\u5c5e\u6027\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u805a\u5408\u7279\u5f81\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u6a21\u5f0f\u7279\u5b9a\u7684\u7279\u5f81\u7f16\u7801\u5668\uff0c\u9700\u8981\u4e3a\u6bcf\u79cd\u8282\u70b9\u7c7b\u578b\u548c\u7279\u5f81\u5217\u5206\u522b\u8bbe\u8ba1\u6a21\u5757\uff0c\u8fd9\u963b\u788d\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53c2\u6570\u5171\u4eab\u3002", "method": "\u4f7f\u7528\u5171\u4eab\u7684\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u5904\u7406\u5206\u7c7b\u3001\u6570\u503c\u3001\u6587\u672c\u548c\u65f6\u95f4\u5c5e\u6027\uff0c\u7136\u540e\u901a\u8fc7Perceiver\u98ce\u683c\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u6a21\u5757\u5c06\u7279\u5f81\u805a\u5408\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u7f6e\u6362\u4e0d\u53d8\u8282\u70b9\u8868\u793a\u3002", "result": "\u5728RelBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRELATE\u4e0eReLGNN\u548cHGT\u914d\u5408\u4f7f\u7528\u65f6\uff0c\u6027\u80fd\u8fbe\u5230\u6a21\u5f0f\u7279\u5b9a\u7f16\u7801\u5668\u768497%\u4ee5\u4e0a\uff0c\u540c\u65f6\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u591a\u8fbe5\u500d\u3002", "conclusion": "RELATE\u652f\u6301\u4e0d\u540c\u7684\u6570\u636e\u6a21\u5f0f\uff0c\u4f7f\u901a\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u8fdb\u884c\u591a\u6570\u636e\u96c6\u9884\u8bad\u7ec3\uff0c\u4e3a\u5173\u7cfb\u56fe\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19957", "abs": "https://arxiv.org/abs/2510.19957", "authors": ["Amir Hever", "Itai Orr"], "title": "A new wave of vehicle insurance fraud fueled by generative AI", "comment": null, "summary": "Generative AI is supercharging insurance fraud by making it easier to falsify\naccident evidence at scale and in rapid time. Insurance fraud is a pervasive\nand costly problem, amounting to tens of billions of dollars in losses each\nyear. In the vehicle insurance sector, fraud schemes have traditionally\ninvolved staged accidents, exaggerated damage, or forged documents. The rise of\ngenerative AI, including deepfake image and video generation, has introduced\nnew methods for committing fraud at scale. Fraudsters can now fabricate highly\nrealistic crash photos, damage evidence, and even fake identities or documents\nwith minimal effort, exploiting AI tools to bolster false insurance claims.\nInsurers have begun deploying countermeasures such as AI-based deepfake\ndetection software and enhanced verification processes to detect and mitigate\nthese AI-driven scams. However, current mitigation strategies face significant\nlimitations. Detection tools can suffer from false positives and negatives, and\nsophisticated fraudsters continuously adapt their tactics to evade automated\nchecks. This cat-and-mouse arms race between generative AI and detection\ntechnology, combined with resource and cost barriers for insurers, means that\ncombating AI-enabled insurance fraud remains an ongoing challenge. In this\nwhite paper, we present UVeye layered solution for vehicle fraud, representing\na major leap forward in the ability to detect, mitigate and deter this new wave\nof fraud.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u6b63\u5728\u52a0\u5267\u4fdd\u9669\u6b3a\u8bc8\uff0c\u4f7f\u5927\u89c4\u6a21\u5feb\u901f\u4f2a\u9020\u4e8b\u6545\u8bc1\u636e\u6210\u4e3a\u53ef\u80fd\u3002\u4fdd\u9669\u516c\u53f8\u91c7\u7528AI\u68c0\u6d4b\u5de5\u5177\u5e94\u5bf9\uff0c\u4f46\u9762\u4e34\u8bef\u62a5\u3001\u6f0f\u62a5\u548c\u6b3a\u8bc8\u8005\u4e0d\u65ad\u8fdb\u5316\u7684\u6311\u6218\u3002", "motivation": "\u4fdd\u9669\u6b3a\u8bc8\u6bcf\u5e74\u9020\u6210\u6570\u767e\u4ebf\u7f8e\u5143\u635f\u5931\uff0c\u751f\u6210\u5f0fAI\u6280\u672f\u8ba9\u6b3a\u8bc8\u8005\u80fd\u8f7b\u677e\u4f2a\u9020\u903c\u771f\u7684\u4e8b\u6545\u7167\u7247\u3001\u635f\u574f\u8bc1\u636e\u548c\u865a\u5047\u8eab\u4efd\uff0c\u52a0\u5267\u4e86\u4fdd\u9669\u6b3a\u8bc8\u95ee\u9898\u3002", "method": "\u4fdd\u9669\u516c\u53f8\u90e8\u7f72AI\u9a71\u52a8\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u8f6f\u4ef6\u548c\u589e\u5f3a\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4f46\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5305\u62ec\u68c0\u6d4b\u5de5\u5177\u7684\u8bef\u62a5\u6f0f\u62a5\u95ee\u9898\u3002", "result": "\u68c0\u6d4b\u5de5\u5177\u5b58\u5728\u8bef\u62a5\u548c\u6f0f\u62a5\u95ee\u9898\uff0c\u6b3a\u8bc8\u8005\u4e0d\u65ad\u8c03\u6574\u7b56\u7565\u89c4\u907f\u81ea\u52a8\u68c0\u67e5\uff0c\u5f62\u6210\u751f\u6210\u5f0fAI\u4e0e\u68c0\u6d4b\u6280\u672f\u4e4b\u95f4\u7684\u519b\u5907\u7ade\u8d5b\u3002", "conclusion": "\u6253\u51fbAI\u9a71\u52a8\u7684\u4fdd\u9669\u6b3a\u8bc8\u4ecd\u9762\u4e34\u6301\u7eed\u6311\u6218\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u6765\u68c0\u6d4b\u3001\u7f13\u89e3\u548c\u5a01\u6151\u8fd9\u79cd\u65b0\u578b\u6b3a\u8bc8\u6d6a\u6f6e\u3002"}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u5b66\u672f\u6210\u529f\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u5206\u6790129\u540d\u73af\u5883\u5de5\u7a0b\u7855\u58eb\u751f\uff0c\u53d1\u73b0\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5728\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u65f6\u8fbe\u523087.50%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u9884\u6d4b\u5b66\u672f\u6210\u529f\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u548c\u5236\u5b9a\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u673a\u4f1a\u3002", "method": "\u6536\u96c6129\u540d\u7855\u58eb\u751f\u76845\u9879\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\u6570\u636e\uff0823\u4e2a\u7279\u5f81\uff09\uff0c\u7ed3\u5408\u5e73\u5747\u6210\u7ee9\u8fdb\u884c\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u548c\u76f8\u5173\u6027\u5206\u6790\uff0c\u4f7f\u7528\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5e76\u8c03\u4f187\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8868\u73b0\u6700\u4f73\uff0c\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe87.50%\uff0c\u4e0d\u5305\u542b\u8be5\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e3a85.71%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u548c\u9009\u62e9\u6700\u9002\u5408\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u989d\u5916\u673a\u4f1a\uff0c\u8bc1\u660e\u4e86\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u5728\u9884\u6d4b\u5b66\u672f\u6210\u529f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u79d8\u5bc6\u6587\u672c\u9690\u85cf\u5728\u770b\u4f3c\u6b63\u5e38\u7684\u6587\u672c\u4e2d\u7684\u534f\u8bae\uff0c\u53ef\u4ee5\u5728\u76f8\u540c\u957f\u5ea6\u7684\u6587\u672c\u4e2d\u5d4c\u5165\u9690\u85cf\u4fe1\u606f\uff0c\u4e14\u7f16\u7801\u89e3\u7801\u8fc7\u7a0b\u5feb\u901f\u9ad8\u6548\u3002", "motivation": "\u63a2\u7d22\u6587\u672c\u4e0e\u4f5c\u8005\u610f\u56fe\u7684\u5206\u79bb\u53ef\u80fd\u6027\uff0c\u5c55\u793aLLM\u5982\u4f55\u80fd\u591f\u521b\u5efa\u8868\u9762\u4e0a\u5408\u7406\u4f46\u5b9e\u9645\u5305\u542b\u9690\u85cf\u4fe1\u606f\u7684\u6587\u672c\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u548c\u6587\u672c\u4fe1\u4efb\u6784\u6210\u6311\u6218\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u7684\u534f\u8bae\uff0c\u5229\u7528\u5f00\u6e90LLM\uff08\u5373\u4f7f\u662f80\u4ebf\u53c2\u6570\u7684\u6a21\u578b\uff09\u5728\u76f8\u540c\u957f\u5ea6\u7684\u6587\u672c\u4e2d\u7f16\u7801\u548c\u89e3\u7801\u9690\u85cf\u4fe1\u606f\uff0c\u6574\u4e2a\u8fc7\u7a0b\u53ef\u5728\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u5feb\u901f\u5b8c\u6210\u3002", "result": "\u8bc1\u660e\u4e86\u5373\u4f7f\u662f\u4e2d\u7b49\u89c4\u6a21\u7684LLM\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u9690\u85cf\uff0c\u4e00\u4e2a\u6458\u8981\u957f\u5ea6\u7684\u4fe1\u606f\u53ef\u4ee5\u5728\u51e0\u79d2\u949f\u5185\u5b8c\u6210\u7f16\u7801\u548c\u89e3\u7801\u3002", "conclusion": "\u8fd9\u79cd\u534f\u8bae\u7684\u5b58\u5728\u8868\u660e\u6587\u672c\u4e0e\u4f5c\u8005\u610f\u56fe\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u5206\u79bb\uff0c\u8fdb\u4e00\u6b65\u524a\u5f31\u4e86\u5bf9\u4e66\u9762\u901a\u4fe1\u7684\u4fe1\u4efb\uff0c\u5bf9AI\u5b89\u5168\u63d0\u51fa\u4e86\u7d27\u8feb\u95ee\u9898\uff0c\u5e76\u6311\u6218\u4e86\u6211\u4eec\u5bf9LLM\u77e5\u8bc6\u7406\u89e3\u7684\u4f20\u7edf\u8ba4\u77e5\u3002"}}
{"id": "2510.20099", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20099", "abs": "https://arxiv.org/abs/2510.20099", "authors": ["Daewoo Park", "Suho Park", "Inseok Hong", "Hanwool Lee", "Junkyu Park", "Sangjun Lee", "Jeongman An", "Hyunbin Loh"], "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "comment": "Under Review", "summary": "We present AI PB, a production-scale generative agent deployed in real retail\nfinance. Unlike reactive chatbots that answer queries passively, AI PB\nproactively generates grounded, compliant, and user-specific investment\ninsights. It integrates (i) a component-based orchestration layer that\ndeterministically routes between internal and external LLMs based on data\nsensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the\nfinance-domain embedding model, and (iii) a multi-stage recommendation\nmechanism combining rule heuristics, sequential behavioral modeling, and\ncontextual bandits. Operating fully on-premises under Korean financial\nregulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100\nGPUs. Through human QA and system metrics, we demonstrate that grounded\ngeneration with explicit routing and layered safety can deliver trustworthy AI\ninsights in high-stakes finance.", "AI": {"tldr": "AI PB\u662f\u4e00\u4e2a\u751f\u4ea7\u7ea7\u751f\u6210\u5f0f\u4ee3\u7406\u7cfb\u7edf\uff0c\u90e8\u7f72\u5728\u771f\u5b9e\u96f6\u552e\u91d1\u878d\u73af\u5883\u4e2d\uff0c\u80fd\u591f\u4e3b\u52a8\u751f\u6210\u57fa\u4e8e\u4e8b\u5b9e\u3001\u5408\u89c4\u4e14\u4e2a\u6027\u5316\u7684\u6295\u8d44\u6d1e\u5bdf\uff0c\u800c\u975e\u88ab\u52a8\u56de\u7b54\u95ee\u9898\u3002", "motivation": "\u5728\u91d1\u878d\u9886\u57df\u5f00\u53d1\u80fd\u591f\u4e3b\u52a8\u63d0\u4f9b\u4e2a\u6027\u5316\u6295\u8d44\u5efa\u8bae\u7684AI\u7cfb\u7edf\uff0c\u540c\u65f6\u786e\u4fdd\u6570\u636e\u5b89\u5168\u3001\u5408\u89c4\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ee5\u5e94\u5bf9\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7ec4\u4ef6\u5316\u7f16\u6392\u5c42\u8fdb\u884c\u786e\u5b9a\u6027\u8def\u7531\u51b3\u7b56\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u7ba1\u9053\uff08OpenSearch+\u91d1\u878d\u9886\u57df\u5d4c\u5165\u6a21\u578b\uff09\u548c\u591a\u9636\u6bb5\u63a8\u8350\u673a\u5236\uff08\u89c4\u5219\u542f\u53d1\u5f0f\u3001\u5e8f\u5217\u884c\u4e3a\u5efa\u6a21\u3001\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\uff09\uff0c\u5168\u7cfb\u7edf\u5728\u97e9\u56fd\u91d1\u878d\u76d1\u7ba1\u4e0b\u672c\u5730\u90e8\u7f72\u3002", "result": "\u901a\u8fc7\u4eba\u5de5\u8d28\u91cf\u8bc4\u4f30\u548c\u7cfb\u7edf\u6307\u6807\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u4e8b\u5b9e\u7684\u751f\u6210\u3001\u663e\u5f0f\u8def\u7531\u548c\u5206\u5c42\u5b89\u5168\u673a\u5236\u80fd\u591f\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u4fe1\u7684AI\u6d1e\u5bdf\u3002", "conclusion": "\u5728\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u901a\u8fc7\u660e\u786e\u7684\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u548c\u5b89\u5168\u673a\u5236\uff0c\u53ef\u4ee5\u5b9e\u73b0\u53ef\u9760\u4e14\u5408\u89c4\u7684\u751f\u6210\u5f0fAI\u5e94\u7528\u3002"}}
{"id": "2510.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20102", "abs": "https://arxiv.org/abs/2510.20102", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Sangmi Chai"], "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "comment": null, "summary": "We present HCLA, a human-centered multi-agent system for anomaly detection in\ndigital asset transactions. The system links three roles: Parsing, Detection,\nand Explanation, into a conversational workflow that lets non-experts ask\nquestions in natural language, inspect structured analytics, and obtain\ncontext-aware rationales. Implemented with an open-source web UI, HCLA\ntranslates user intents into a schema for a classical detector (XGBoost in our\nprototype) and returns narrative explanations grounded in the underlying\nfeatures. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the\nbaseline detector reaches strong accuracy, while HCLA adds interpretability and\ninteractive refinement. We describe the architecture, interaction loop,\ndataset, evaluation protocol, and limitations, and discuss how a\nhuman-in-the-loop design improves transparency and trust in financial\nforensics.", "AI": {"tldr": "HCLA\u662f\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u6570\u5b57\u8d44\u4ea7\u4ea4\u6613\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5206\u6790\u7ed3\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u91d1\u878d\u53d6\u8bc1\u4e2d\u975e\u4e13\u5bb6\u7528\u6237\u96be\u4ee5\u7406\u89e3\u548c\u4fe1\u4efb\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u900f\u660e\u4e14\u53ef\u4ea4\u4e92\u7684\u68c0\u6d4b\u5de5\u5177\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u4e09\u89d2\u8272\u67b6\u6784\uff08\u89e3\u6790\u3001\u68c0\u6d4b\u3001\u89e3\u91ca\uff09\uff0c\u901a\u8fc7\u5bf9\u8bdd\u5de5\u4f5c\u6d41\u5c06\u7528\u6237\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aXGBoost\u68c0\u6d4b\u5668\u7684\u8f93\u5165\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u7279\u5f81\u7684\u53d9\u4e8b\u89e3\u91ca\u3002", "result": "\u5728\u6bd4\u7279\u5e01\u6df7\u5e01\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\uff0cHCLA\u7cfb\u7edf\u989d\u5916\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u4ea4\u4e92\u5f0f\u4f18\u5316\u80fd\u529b\u3002", "conclusion": "\u4eba\u5728\u56de\u8def\u7684\u8bbe\u8ba1\u63d0\u9ad8\u4e86\u91d1\u878d\u53d6\u8bc1\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\uff0c\u4f7f\u975e\u4e13\u5bb6\u7528\u6237\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u4fe1\u4efb\u68c0\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2510.20109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20109", "abs": "https://arxiv.org/abs/2510.20109", "authors": ["Joshua Yuvaraj"], "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "comment": null, "summary": "It is often claimed that machine learning-based generative AI products will\ndrastically streamline and reduce the cost of legal practice. This enthusiasm\nassumes lawyers can effectively manage AI's risks. Cases in Australia and\nelsewhere in which lawyers have been reprimanded for submitting inaccurate\nAI-generated content to courts suggest this paradigm must be revisited. This\npaper argues that a new paradigm is needed to evaluate AI use in practice,\ngiven (a) AI's disconnection from reality and its lack of transparency, and (b)\nlawyers' paramount duties like honesty, integrity, and not to mislead the\ncourt. It presents an alternative model of AI use in practice that more\nholistically reflects these features (the verification-value paradox). That\nparadox suggests increases in efficiency from AI use in legal practice will be\nmet by a correspondingly greater imperative to manually verify any outputs of\nthat use, rendering the net value of AI use often negligible to lawyers. The\npaper then sets out the paradox's implications for legal practice and legal\neducation, including for AI use but also the values that the paradox suggests\nshould undergird legal practice: fidelity to the truth and civic\nresponsibility.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u9700\u8981\u91cd\u65b0\u8bc4\u4f30AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\uff0c\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\uff1aAI\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u62b5\u6d88\uff0c\u5bfc\u81f4\u51c0\u4ef7\u503c\u5f80\u5f80\u4e3a\u96f6", "motivation": "\u57fa\u4e8e\u5f8b\u5e08\u56e0\u63d0\u4ea4\u4e0d\u51c6\u786e\u7684AI\u751f\u6210\u5185\u5bb9\u800c\u53d7\u5904\u7f5a\u7684\u6848\u4f8b\uff0c\u8ba4\u4e3a\u73b0\u6709\u8bc4\u4f30AI\u4f7f\u7528\u7684\u8303\u5f0f\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\uff0c\u8003\u8651\u5230AI\u4e0e\u73b0\u5b9e\u8131\u8282\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u4ee5\u53ca\u5f8b\u5e08\u7684\u6838\u5fc3\u804c\u8d23", "method": "\u63d0\u51fa\u4e86\u9a8c\u8bc1-\u4ef7\u503c\u6096\u8bba\u4f5c\u4e3a\u66ff\u4ee3\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u66f4\u5168\u9762\u5730\u53cd\u6620\u4e86AI\u7684\u7279\u6027\u548c\u5f8b\u5e08\u7684\u804c\u8d23\u8981\u6c42", "result": "AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u4e2d\u7684\u6548\u7387\u63d0\u5347\u4f1a\u88ab\u76f8\u5e94\u7684\u9a8c\u8bc1\u9700\u6c42\u6240\u62b5\u6d88\uff0c\u5bfc\u81f4\u51c0\u4ef7\u503c\u5f80\u5f80\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1", "conclusion": "\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u5728\u6cd5\u5f8b\u5b9e\u8df5\u548c\u6559\u80b2\u4e2d\u7684\u4f7f\u7528\uff0c\u5f3a\u8c03\u5bf9\u771f\u76f8\u7684\u5fe0\u8bda\u548c\u516c\u6c11\u8d23\u4efb\u7b49\u6838\u5fc3\u4ef7\u503c\u89c2\u7684\u91cd\u8981\u6027"}}
{"id": "2510.20188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20188", "abs": "https://arxiv.org/abs/2510.20188", "authors": ["Morris Yu-Chao Huang", "Zhen Tan", "Mohan Zhang", "Pingzhi Li", "Zhuo Zhang", "Tianlong Chen"], "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "comment": null, "summary": "Large Language Models generate complex reasoning chains that reveal their\ndecision-making, yet verifying the faithfulness and harmlessness of these\nintermediate steps remains a critical unsolved problem. Existing auditing\nmethods are centralized, opaque, and hard to scale, creating significant risks\nfor deploying proprietary models in high-stakes domains. We identify four core\nchallenges: (1) Robustness: Centralized auditors are single points of failure,\nprone to bias or attacks. (2) Scalability: Reasoning traces are too long for\nmanual verification. (3) Opacity: Closed auditing undermines public trust. (4)\nPrivacy: Exposing full reasoning risks model theft or distillation. We propose\nTRUST, a transparent, decentralized auditing framework that overcomes these\nlimitations via: (1) A consensus mechanism among diverse auditors, guaranteeing\ncorrectness under up to $30\\%$ malicious participants. (2) A hierarchical DAG\ndecomposition of reasoning traces, enabling scalable, parallel auditing. (3) A\nblockchain ledger that records all verification decisions for public\naccountability. (4) Privacy-preserving segmentation, sharing only partial\nreasoning steps to protect proprietary logic. We provide theoretical guarantees\nfor the security and economic incentives of the TRUST framework. Experiments\nacross multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,\nmedical, science, humanities) show TRUST effectively detects reasoning flaws\nand remains robust against adversarial auditors. Our work pioneers\ndecentralized AI auditing, offering a practical path toward safe and\ntrustworthy LLM deployment.", "AI": {"tldr": "TRUST\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684AI\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u3001\u5206\u5c42DAG\u5206\u89e3\u3001\u533a\u5757\u94fe\u8d26\u672c\u548c\u9690\u79c1\u4fdd\u62a4\u5206\u6bb5\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u94fe\u9a8c\u8bc1\u7684\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u900f\u660e\u6027\u548c\u9690\u79c1\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5ba1\u8ba1\u65b9\u6cd5\u96c6\u4e2d\u5316\u3001\u4e0d\u900f\u660e\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u65e0\u6cd5\u6709\u6548\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u94fe\u7684\u5fe0\u5b9e\u6027\u548c\u65e0\u5bb3\u6027\uff0c\u5728\u5173\u952e\u9886\u57df\u90e8\u7f72\u4e13\u6709\u6a21\u578b\u5b58\u5728\u91cd\u5927\u98ce\u9669\u3002", "method": "\u91c7\u7528\u5171\u8bc6\u673a\u5236\u786e\u4fdd\u572830%\u6076\u610f\u53c2\u4e0e\u8005\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\uff1b\u4f7f\u7528\u5206\u5c42DAG\u5206\u89e3\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5e76\u884c\u5ba1\u8ba1\uff1b\u901a\u8fc7\u533a\u5757\u94fe\u8d26\u672c\u8bb0\u5f55\u9a8c\u8bc1\u51b3\u7b56\u786e\u4fdd\u516c\u5171\u95ee\u8d23\uff1b\u91c7\u7528\u9690\u79c1\u4fdd\u62a4\u5206\u6bb5\u4ec5\u5171\u4eab\u90e8\u5206\u63a8\u7406\u6b65\u9aa4\u4fdd\u62a4\u4e13\u6709\u903b\u8f91\u3002", "result": "\u5728\u591a\u4e2aLLM\uff08GPT-OSS\u3001DeepSeek-r1\u3001Qwen\uff09\u548c\u63a8\u7406\u4efb\u52a1\uff08\u6570\u5b66\u3001\u533b\u5b66\u3001\u79d1\u5b66\u3001\u4eba\u6587\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTRUST\u80fd\u6709\u6548\u68c0\u6d4b\u63a8\u7406\u7f3a\u9677\uff0c\u5e76\u5bf9\u6297\u6027\u5ba1\u8ba1\u8005\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "TRUST\u5f00\u521b\u4e86\u53bb\u4e2d\u5fc3\u5316AI\u5ba1\u8ba1\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u4fe1\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.20190", "categories": ["cs.AI", "cs.IT", "math.IT", "68T07 (Primary) 92B20, 37N25, 68Q32, 94A17 (Secondary)", "I.2.6; I.2.7; I.2.4; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.20190", "abs": "https://arxiv.org/abs/2510.20190", "authors": ["Marcelo Maciel Amaral", "Raymond Aschheim"], "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "comment": null, "summary": "Large language models (LLMs) remain broadly open and highly steerable: they\nimitate at scale, accept arbitrary system prompts, and readily adopt multiple\npersonae. By analogy to human development, we hypothesize that progress toward\nartificial general intelligence (AGI) involves a lock-in phase: a transition\nfrom open imitation to identity consolidation, in which goal structures,\nrefusals, preferences, and internal representations become comparatively stable\nand resistant to external steering. We formalize this phase, link it to known\nphenomena in learning dynamics, and propose operational metrics for onset\ndetection. Experimentally, we demonstrate that while the behavioral\nconsolidation is rapid and non-linear, its side-effects on general capabilities\nare not monolithic. Our results reveal a spectrum of outcomes--from performance\ntrade-offs in small models, through largely cost-free adoption in mid-scale\nmodels, to transient instabilities in large, quantized models. We argue that\nsuch consolidation is a prerequisite for AGI-level reliability and also a\ncritical control point for safety: identities can be deliberately engineered\nfor reliability, yet may also emerge spontaneously during scaling, potentially\nhardening unpredictable goals and behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAGI\u53d1\u5c55\u4e2d\u7684\u9501\u5b9a\u9636\u6bb5\u7406\u8bba\uff0c\u5373\u4ece\u5f00\u653e\u6a21\u4eff\u8f6c\u5411\u8eab\u4efd\u5de9\u56fa\u7684\u8fc7\u7a0b\uff0c\u5e76\u5f00\u53d1\u4e86\u68c0\u6d4b\u6307\u6807\u3002\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5448\u73b0\u4e0d\u540c\u8868\u73b0\uff1a\u5c0f\u6a21\u578b\u6709\u6027\u80fd\u6743\u8861\uff0c\u4e2d\u89c4\u6a21\u6a21\u578b\u57fa\u672c\u65e0\u6210\u672c\uff0c\u5927\u89c4\u6a21\u91cf\u5316\u6a21\u578b\u51fa\u73b0\u77ac\u65f6\u4e0d\u7a33\u5b9a\u3002", "motivation": "\u57fa\u4e8e\u4eba\u7c7b\u53d1\u5c55\u7c7b\u6bd4\uff0c\u5047\u8bbeAGI\u8fdb\u6b65\u9700\u8981\u7ecf\u5386\u9501\u5b9a\u9636\u6bb5\uff0c\u4ece\u5f00\u653e\u6a21\u4eff\u8f6c\u5411\u7a33\u5b9a\u7684\u8eab\u4efd\u5de9\u56fa\uff0c\u8fd9\u5bf9AGI\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f62\u5f0f\u5316\u9501\u5b9a\u9636\u6bb5\u6982\u5ff5\uff0c\u5c06\u5176\u4e0e\u5b66\u4e60\u52a8\u6001\u4e2d\u7684\u5df2\u77e5\u73b0\u8c61\u8054\u7cfb\uff0c\u63d0\u51fa\u64cd\u4f5c\u6027\u68c0\u6d4b\u6307\u6807\uff0c\u5e76\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u884c\u4e3a\u5de9\u56fa\u5feb\u901f\u4e14\u975e\u7ebf\u6027\uff0c\u4f46\u5bf9\u901a\u7528\u80fd\u529b\u7684\u5f71\u54cd\u5404\u5f02\uff1a\u5c0f\u6a21\u578b\u6709\u6027\u80fd\u6743\u8861\uff0c\u4e2d\u89c4\u6a21\u6a21\u578b\u57fa\u672c\u65e0\u6210\u672c\uff0c\u5927\u89c4\u6a21\u91cf\u5316\u6a21\u578b\u51fa\u73b0\u77ac\u65f6\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u8eab\u4efd\u5de9\u56fa\u662fAGI\u7ea7\u53ef\u9760\u6027\u7684\u524d\u63d0\uff0c\u4e5f\u662f\u5173\u952e\u5b89\u5168\u63a7\u5236\u70b9\uff1a\u8eab\u4efd\u53ef\u88ab\u5de5\u7a0b\u5316\u8bbe\u8ba1\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u4f46\u4e5f\u53ef\u80fd\u5728\u6269\u5c55\u8fc7\u7a0b\u4e2d\u81ea\u53d1\u5f62\u6210\uff0c\u53ef\u80fd\u56fa\u5316\u4e0d\u53ef\u9884\u6d4b\u7684\u76ee\u6807\u548c\u884c\u4e3a\u3002"}}
{"id": "2510.20205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20205", "abs": "https://arxiv.org/abs/2510.20205", "authors": ["Maggie Bai", "Ava Kim Cohen", "Eleanor Koss", "Charlie Lichtenbaum"], "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "comment": "9 pages, 5 figures", "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f18\u5316AI\u7684\u8fdb\u5316\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u75282048\u6e38\u620f\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6bd4\u8f83\u4e86\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6e38\u620f\u6027\u80fd\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u4f18\u5316AI\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8868\u73b0\u662f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7684\u57fa\u672c\u6311\u6218\uff0c2048\u6e38\u620f\u7ed3\u5408\u4e86\u7b56\u7565\u6027\u548c\u968f\u673a\u6027\u5143\u7d20\uff0c\u4e3a\u7814\u7a76\u51b3\u7b56\u5236\u5b9a\u3001\u957f\u671f\u89c4\u5212\u548c\u52a8\u6001\u9002\u5e94\u63d0\u4f9b\u4e86\u7406\u60f3\u5e73\u53f0\u3002", "method": "\u5b9e\u73b0\u4e86\u4e24\u79cd\u7cfb\u7edf\uff1a\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u7cfb\u7edf\uff08\u4e00\u4e2a\"\u601d\u8003\u8005\"LLM\u4f18\u5316\u6e38\u620f\u7b56\u7565\u7ed9\"\u6267\u884c\u8005\"LLM\u4f7f\u7528\uff09\u548c\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4ef7\u503c\u51fd\u6570\u4f18\u5316\u7684\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8fd8\u5b9e\u9a8c\u4e86\u56de\u6eda\u529f\u80fd\u4ee5\u907f\u514d\u6027\u80fd\u9000\u5316\u3002", "result": "\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u5e73\u5747\u589e\u52a0473.2\u5206\uff0c\u4e14\u5448\u73b0\u660e\u663e\u4e0a\u5347\u8d8b\u52bf\uff08\u76f8\u5173\u6027\u03c1=0.607\uff09\uff0cLLM\u5bf9\u6e38\u620f\u7684\u7406\u89e3\u4e5f\u968f\u7740\u9ad8\u7ea7\u7b56\u7565\u7684\u53d1\u5c55\u800c\u589e\u957f\u3002\u53cc\u667a\u80fd\u4f53\u7cfb\u7edf\u6539\u8fdb\u6709\u9650\uff0c\u663e\u793a\u4e86\u5143\u63d0\u793a\u7684\u5185\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u8fdb\u5316\u4f18\u5316\u6280\u672f\u5728\u975e\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u6539\u5584AI\u6027\u80fd\u5177\u6709\u6f5c\u529b\uff0c\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u6bd4\u53cc\u667a\u80fd\u4f53\u5143\u63d0\u793a\u65b9\u6cd5\u66f4\u6709\u6548\u3002"}}
{"id": "2510.20252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20252", "abs": "https://arxiv.org/abs/2510.20252", "authors": ["Tianyi Zhang", "Xiaolin Zhou", "Yunzhe Wang", "Erik Cambria", "David Traum", "Rui Mao"], "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "comment": null, "summary": "Individualized cognitive simulation (ICS) aims to build computational models\nthat approximate the thought processes of specific individuals. While large\nlanguage models (LLMs) convincingly mimic surface-level human behavior such as\nrole-play, their ability to simulate deeper individualized cognitive processes\nremains poorly understood. To address this gap, we introduce a novel task that\nevaluates different cognitive representation methods in ICS. We construct a\ndataset from recently published novels (later than the release date of the\ntested LLMs) and propose an 11-condition cognitive evaluation framework to\nbenchmark seven off-the-shelf LLMs in the context of authorial style emulation.\nWe hypothesize that effective cognitive representations can help LLMs generate\nstorytelling that better mirrors the original author. Thus, we test different\ncognitive representations, e.g., linguistic features, concept mappings, and\nprofile-based information. Results show that combining conceptual and\nlinguistic features is particularly effective in ICS, outperforming static\nprofile-based cues in overall evaluation. Importantly, LLMs are more effective\nat mimicking linguistic style than narrative structure, underscoring their\nlimits in deeper cognitive simulation. These findings provide a foundation for\ndeveloping AI systems that adapt to individual ways of thinking and expression,\nadvancing more personalized and human-aligned creative technologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u65b0\u51fa\u7248\u5c0f\u8bf4\u7684\u6570\u636e\u96c6\u548c11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e867\u4e2a\u73b0\u6210LLM\u5728\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u867d\u7136LLM\u80fd\u591f\u8868\u9762\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5176\u6a21\u62df\u66f4\u6df1\u5c42\u6b21\u4e2a\u4f53\u5316\u8ba4\u77e5\u8fc7\u7a0b\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u5f00\u53d1\u8bc4\u4f30\u65b9\u6cd5\u6765\u7406\u89e3LLM\u5728\u8ba4\u77e5\u6a21\u62df\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u65b0\u51fa\u7248\u5c0f\u8bf4\uff08\u665a\u4e8e\u6d4b\u8bd5LLM\u53d1\u5e03\u65e5\u671f\uff09\u7684\u6570\u636e\u96c6\uff0c\u63d0\u51fa11\u6761\u4ef6\u8ba4\u77e5\u8bc4\u4f30\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e0d\u540c\u8ba4\u77e5\u8868\u5f81\u65b9\u6cd5\uff08\u5982\u8bed\u8a00\u7279\u5f81\u3001\u6982\u5ff5\u6620\u5c04\u3001\u57fa\u4e8e\u6863\u6848\u7684\u4fe1\u606f\uff09\u5728\u4f5c\u8005\u98ce\u683c\u6a21\u4eff\u4efb\u52a1\u4e2d\u7684\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6982\u5ff5\u548c\u8bed\u8a00\u7279\u5f81\u7684\u7ec4\u5408\u5728\u4e2a\u4f53\u5316\u8ba4\u77e5\u6a21\u62df\u4e2d\u7279\u522b\u6709\u6548\uff0c\u5728\u6574\u4f53\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u57fa\u4e8e\u9759\u6001\u6863\u6848\u7684\u7ebf\u7d22\u3002LLM\u5728\u6a21\u4eff\u8bed\u8a00\u98ce\u683c\u65b9\u9762\u6bd4\u53d9\u4e8b\u7ed3\u6784\u66f4\u6709\u6548\uff0c\u7a81\u663e\u4e86\u5176\u5728\u66f4\u6df1\u5c42\u6b21\u8ba4\u77e5\u6a21\u62df\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u5f00\u53d1\u9002\u5e94\u4e2a\u4f53\u601d\u7ef4\u548c\u8868\u8fbe\u65b9\u5f0f\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u66f4\u4e2a\u6027\u5316\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u521b\u610f\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.20258", "categories": ["cs.AI", "I.2"], "pdf": "https://arxiv.org/pdf/2510.20258", "abs": "https://arxiv.org/abs/2510.20258", "authors": ["Bita Banihashemi", "Megh Patel", "Yves Lesp\u00e9rance"], "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "comment": null, "summary": "Generating an abstraction of a dynamic domain that aligns with a given\npurpose remains a significant challenge given that the choice of such an\nabstraction can impact an agent's ability to plan, reason, and provide\nexplanations effectively. We model the agent's concrete behaviors in PDDL and\ninvestigate the use of in-context learning with large language models (LLMs)\nfor the generation of abstract PDDL domains and problem instances, given an\nabstraction objective specified in natural language. The benchmark examples we\nuse are new and have not been part of the data any LLMs have been trained on.\nWe consider three categories of abstractions: abstraction of choice of\nalternative concrete actions, abstraction of sequences of concrete actions, and\nabstraction of action/predicate parameters, as well as combinations of these.\nThe generated abstract PDDL domains and problem instances are then checked by\nsymbolic validation tools as well as human experts. Our experiments show that\nGPT-4o can generally synthesize useful planning domain abstractions in simple\nsettings, although it is better at abstracting over actions than over the\nassociated fluents.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u4ee5\u81ea\u7136\u8bed\u8a00\u6307\u5b9a\u7684\u62bd\u8c61\u76ee\u6807\u4e3a\u57fa\u7840\uff0c\u9a8c\u8bc1\u4e86GPT-4o\u5728\u7b80\u5355\u573a\u666f\u4e2d\u80fd\u6709\u6548\u5408\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\u3002", "motivation": "\u52a8\u6001\u9886\u57df\u7684\u62bd\u8c61\u751f\u6210\u5bf9\u667a\u80fd\u4f53\u7684\u89c4\u5212\u3001\u63a8\u7406\u548c\u89e3\u91ca\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5982\u4f55\u9009\u62e9\u4e0e\u76ee\u7684\u5bf9\u9f50\u7684\u62bd\u8c61\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u5728PDDL\u4e2d\u5efa\u6a21\u667a\u80fd\u4f53\u5177\u4f53\u884c\u4e3a\uff0c\u5229\u7528LLMs\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u6839\u636e\u81ea\u7136\u8bed\u8a00\u6307\u5b9a\u7684\u62bd\u8c61\u76ee\u6807\u751f\u6210\u62bd\u8c61PDDL\u9886\u57df\u548c\u95ee\u9898\u5b9e\u4f8b\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u9a8c\u8bc1\u5de5\u5177\u548c\u4e13\u5bb6\u8bc4\u4f30\u3002", "result": "GPT-4o\u5728\u7b80\u5355\u8bbe\u7f6e\u4e2d\u901a\u5e38\u80fd\u5408\u6210\u6709\u7528\u7684\u89c4\u5212\u9886\u57df\u62bd\u8c61\uff0c\u4f46\u5728\u52a8\u4f5c\u62bd\u8c61\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u76f8\u5173\u8c13\u8bcd\u7684\u62bd\u8c61\u3002", "conclusion": "LLMs\u5728\u751f\u6210\u89c4\u5212\u9886\u57df\u62bd\u8c61\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u52a8\u4f5c\u62bd\u8c61\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8c13\u8bcd\u62bd\u8c61\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002"}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "STaBERT\u6a21\u578b\u901a\u8fc7\u6574\u5408POI\u8bed\u4e49\u4fe1\u606f\u548c\u65f6\u95f4\u63cf\u8ff0\u7b26\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8981\u4e48\u53ea\u5efa\u6a21\u4f4d\u7f6e\u5e8f\u5217\uff0c\u8981\u4e48\u4ec5\u5c06\u65f6\u95f4\u4fe1\u606f\u4f5c\u4e3a\u8f85\u52a9\u8f93\u5165\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5174\u8da3\u70b9(POI)\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSTaBERT\u6a21\u578b\uff0c\u5728BERT\u57fa\u7840\u4e0a\u878d\u5408POI\u5d4c\u5165\u548c\u65f6\u95f4\u63cf\u8ff0\u7b26\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u589e\u5f3a\u79fb\u52a8\u6027\u8868\u793a\u3002", "result": "\u5355\u57ce\u5e02\u9884\u6d4b\u7684GEO-BLEU\u5f97\u5206\u4ece0.34\u63d0\u5347\u52300.75\uff1b\u591a\u57ce\u5e02\u9884\u6d4b\u4ece0.34\u63d0\u5347\u52300.56\u3002", "conclusion": "\u6574\u5408POI\u8bed\u4e49\u548c\u65f6\u95f4\u4fe1\u606f\u80fd\u663e\u8457\u6539\u5584\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20310", "abs": "https://arxiv.org/abs/2510.20310", "authors": ["Mingliang Zhai", "Hansheng Liang", "Xiaomeng Fan", "Zhi Gao", "Chuanhao Li", "Che Sun", "Xu Bin", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "comment": "16 pages, 7 figures, 8 tables", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.", "AI": {"tldr": "ToolEQA\u662f\u4e00\u4e2a\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\u7684EQA\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5de5\u5177\u63d0\u4f9b\u6709\u7528\u4fe1\u606f\u6765\u6539\u8fdb\u63a2\u7d22\u65b9\u5411\uff0c\u4ece\u800c\u7528\u66f4\u77ed\u63a2\u7d22\u8ddd\u79bb\u751f\u6210\u66f4\u51c6\u786e\u56de\u7b54\u3002", "motivation": "\u73b0\u6709EQA\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a2\u7d22\u73af\u5883\u800c\u4e0d\u8fdb\u884c\u663e\u5f0f\u601d\u8003\u6216\u89c4\u5212\uff0c\u9650\u5236\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u56de\u7b54\u65e0\u6548\u3002", "method": "\u8bbe\u8ba1ToolEQA\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5916\u90e8\u5de5\u5177\u4e0e\u591a\u6b65\u63a8\u7406\uff1b\u5f00\u53d1\u81ea\u52a8\u751f\u6210EQA\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u6784\u5efa\u5305\u542b18K\u4efb\u52a1\u7684EQA-RT\u6570\u636e\u96c6\u3002", "result": "\u5728EQA-RT-Seen\u548cEQA-RT-Unseen\u6d4b\u8bd5\u96c6\u4e0a\uff0cToolEQA\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u53479.2~20.2%\uff0c\u6bd4\u96f6\u6837\u672c\u7248\u672c\u9ad810%\u3002\u5728HM-EQA\u3001OpenEQA\u548cEXPRESS-Bench\u6570\u636e\u96c6\u4e0a\u4e5f\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "ToolEQA\u901a\u8fc7\u96c6\u6210\u5916\u90e8\u5de5\u5177\u548c\u591a\u6b65\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86EQA\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20332", "abs": "https://arxiv.org/abs/2510.20332", "authors": ["Anna Arias-Duart", "Maria Eugenia Cardello", "Atia Cort\u00e9s"], "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)", "summary": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8eAI4HealthyAging\u9879\u76ee\u7ecf\u9a8c\uff0c\u8bc6\u522b\u4e86\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u504f\u89c1\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u5584AI\u7cfb\u7edf\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u533b\u7597\u9886\u57df\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\u548c\u516c\u5e73\u6027\u95ee\u9898\uff0cAI\u89e3\u51b3\u65b9\u6848\u5728\u771f\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\u662f\u4e3b\u8981\u969c\u788d\u3002", "method": "\u57fa\u4e8e\u897f\u73ed\u7259\u56fd\u5bb6\u7814\u53d1\u8ba1\u5212AI4HealthyAging\u9879\u76ee\u7684\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e34\u5e8a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u504f\u89c1\uff0c\u8bc6\u522b\u4e86\u5386\u53f2\u504f\u89c1\u3001\u4ee3\u8868\u6027\u504f\u89c1\u548c\u6d4b\u91cf\u504f\u89c1\u7b49\u591a\u79cd\u504f\u89c1\u7c7b\u578b\u3002", "result": "\u5728\u591a\u4e2a\u7528\u4f8b\u4e2d\u8bc6\u522b\u51fa\u5728\u6027\u522b\u3001\u5e74\u9f84\u3001\u5c45\u4f4f\u5730\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u3001\u8bbe\u5907\u548c\u6807\u7b7e\u7b49\u53d8\u91cf\u4e0a\u5b58\u5728\u7684\u5404\u79cd\u504f\u89c1\u8868\u73b0\u5f62\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6539\u5584\u4e34\u5e8a\u95ee\u9898\u8bbe\u8ba1\u548c\u6570\u636e\u6536\u96c6\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5e0c\u671b\u8fd9\u4e9b\u53d1\u73b0\u548c\u7ecf\u9a8c\u80fd\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u516c\u5e73\u7684\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u76ee\u6807\u6253\u51fb\u7684\u9644\u5e26\u635f\u5bb3\u8bc4\u4f30\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\u4e2d\u6574\u5408\u4e86\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7684\u7c7b\u522b\u3001\u67b6\u6784\u7ec4\u4ef6\u3001\u6253\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u65b9\u9762\u3002", "motivation": "\u5728AI\u7cfb\u7edf\u5728\u6218\u573a\u4e2d\u4f5c\u7528\u65e5\u76ca\u91cd\u8981\u7684\u65f6\u4ee3\uff0c\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u76ee\u6807\u6253\u51fb\u9700\u8981\u5bf9\u6f5c\u5728\u9644\u5e26\u6548\u5e94\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u6574\u5408\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\uff0c\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5316\u8fdb\u884c\u6f14\u793a\u548c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u5c42\u7ed3\u6784\u6a21\u578b\uff0c\u80fd\u591f\u6e05\u6670\u8868\u793a\u5e76\u589e\u5f3a\u900f\u660e\u63a8\u7406\u673a\u5236\uff0c\u4e3a\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2d\u6253\u51fbAI\u7cfb\u7edf\u4ea7\u751f\u7684\u6548\u5e94\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2510.20345", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20345", "abs": "https://arxiv.org/abs/2510.20345", "authors": ["Haonan Bian"], "title": "LLM-empowered knowledge graph construction: A survey", "comment": null, "summary": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.", "AI": {"tldr": "\u672c\u8c03\u67e5\u7cfb\u7edf\u56de\u987e\u4e86LLM\u8d4b\u80fd\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u4e86LLM\u5982\u4f55\u91cd\u5851\u4f20\u7edf\u7684\u672c\u4f53\u5de5\u7a0b\u3001\u77e5\u8bc6\u63d0\u53d6\u548c\u77e5\u8bc6\u878d\u5408\u4e09\u5c42\u6d41\u7a0b\uff0c\u5e76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u6a21\u5f0f\u548c\u65e0\u6a21\u5f0f\u4e24\u79cd\u6784\u5efa\u8303\u5f0f\u7684\u4e92\u8865\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u6b63\u4ece\u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u6d41\u7a0b\u8f6c\u5411\u8bed\u8a00\u9a71\u52a8\u548c\u751f\u6210\u5f0f\u6846\u67b6\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u8fd9\u4e00\u8303\u5f0f\u8f6c\u53d8\u7684\u6280\u672f\u8fdb\u5c55\u3002", "method": "\u4ece\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u56de\u987eLLM\u9a71\u52a8\u65b9\u6cd5\uff1a\u57fa\u4e8e\u6a21\u5f0f\u7684\u8303\u5f0f\u5f3a\u8c03\u7ed3\u6784\u3001\u89c4\u8303\u5316\u548c\u4e00\u81f4\u6027\uff1b\u65e0\u6a21\u5f0f\u8303\u5f0f\u5f3a\u8c03\u7075\u6d3b\u6027\u3001\u9002\u5e94\u6027\u548c\u5f00\u653e\u53d1\u73b0\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u4e86\u5404\u9636\u6bb5\u7684\u4ee3\u8868\u6027\u6846\u67b6\u3001\u6280\u672f\u673a\u5236\u53ca\u5176\u5c40\u9650\u6027\uff0c\u4e3a\u7406\u89e3LLM\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u534f\u540c\u6f14\u8fdb\u63d0\u4f9b\u4e86\u5168\u9762\u89c6\u89d2\u3002", "conclusion": "\u5c55\u671b\u4e86\u5173\u952e\u8d8b\u52bf\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u57fa\u4e8eKG\u7684LLM\u63a8\u7406\u3001\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u52a8\u6001\u77e5\u8bc6\u8bb0\u5fc6\u4ee5\u53ca\u591a\u6a21\u6001KG\u6784\u5efa\uff0c\u65e8\u5728\u5f25\u5408\u7b26\u53f7\u77e5\u8bc6\u5de5\u7a0b\u4e0e\u795e\u7ecf\u8bed\u4e49\u7406\u89e3\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2510.20377", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20377", "abs": "https://arxiv.org/abs/2510.20377", "authors": ["Tianyi Zhang", "Florian Mai", "Lucie Flek"], "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "comment": null, "summary": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.", "AI": {"tldr": "\u63d0\u51fa\u4e86IKnow\u6846\u67b6\uff0c\u901a\u8fc7\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\u7684\u81ea\u76d1\u7763\u76ee\u6807\uff0c\u5728\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u907f\u514d\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u9000\u5316\u3002", "motivation": "\u4f20\u7edf\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u65b9\u6cd5\u4f1a\u964d\u4f4e\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u548c\u8bed\u4e49\u8868\u793a\uff0c\u4e14\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u9700\u8981\u8bbf\u95ee\u539f\u59cb\u57fa\u7840\u6a21\u578b\u6216\u5916\u90e8\u9886\u57df\u77e5\u8bc6\u5e93\uff0c\u8fd9\u5728\u57fa\u7840\u6a21\u578b\u6743\u91cd\u56e0\u5b89\u5168\u539f\u56e0\u88ab\u4fdd\u7559\u6216\u7f3a\u4e4f\u53ef\u9760\u5916\u90e8\u8bed\u6599\u5e93\u7684\u60c5\u51b5\u4e0b\u4e0d\u73b0\u5b9e\u3002", "method": "IKnow\u6846\u67b6\u5c06\u81ea\u76d1\u7763\u76ee\u6807\u91cd\u65b0\u8868\u8ff0\u4e3a\u6307\u4ee4-\u54cd\u5e94\u5bf9\u8bdd\u683c\u5f0f\uff0c\u5229\u7528\u6587\u672c\u672c\u8eab\u5d4c\u5165\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u66f4\u6df1\u8bed\u4e49\u5c42\u6b21\u8fdb\u884c\u7f16\u7801\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff0c\u80fd\u591f\u6709\u6548\u4fdd\u6301\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u540c\u65f6\u5b9e\u73b0\u9886\u57df\u77e5\u8bc6\u7684\u6301\u7eed\u9002\u5e94\u3002", "conclusion": "IKnow\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u901a\u7528\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u5728\u65e0\u9700\u5916\u90e8\u4f9d\u8d56\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u4e86\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9000\u5316\u95ee\u9898\u3002"}}
{"id": "2510.20402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20402", "abs": "https://arxiv.org/abs/2510.20402", "authors": ["Neil Maiden", "Konstantinos Zachos", "James Lockerbie", "Kostas Petrianakis", "Amanda Brown"], "title": "A computational model and tool for generating more novel opportunities in professional innovation processes", "comment": null, "summary": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u521b\u9020\u529b\u7406\u8bba\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u66f4\u5177\u65b0\u9896\u6027\u7684\u521b\u65b0\u673a\u4f1a\uff0c\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u521b\u65b0\u673a\u4f1a\u751f\u6210\u65b9\u6cd5\u5728\u4fdd\u6301\u5b9e\u7528\u6027\u7684\u540c\u65f6\u96be\u4ee5\u4ea7\u751f\u8db3\u591f\u65b0\u9896\u7684\u65b9\u6848\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u5e73\u8861\u65b0\u9896\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u4e94\u4e2a\u529f\u80fd\u6a21\u5757\u7684\u8ba1\u7b97\u6a21\u578b\uff0c\u8fd9\u4e9b\u529f\u80fd\u65e8\u5728\u534f\u540c\u5de5\u4f5c\u4ee5\u751f\u6210\u65e2\u65b0\u9896\u53c8\u6709\u7528\u7684\u521b\u65b0\u673a\u4f1a\uff0c\u5e76\u5728\u9152\u5e97\u4e1a\u521b\u65b0\u9879\u76ee\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u8be5\u8ba1\u7b97\u6a21\u578b\u751f\u6210\u7684\u521b\u65b0\u673a\u4f1a\u5728\u65b0\u9896\u6027\u548c/\u6216\u5b9e\u7528\u6027\u65b9\u9762\u4f18\u4e8eNotebook LM\u548cChatGPT4o\uff0c\u4f46\u5e76\u975e\u6240\u6709\u529f\u80fd\u6a21\u5757\u90fd\u5bf9\u63d0\u5347\u65b0\u9896\u6027\u6709\u8d21\u732e\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6a21\u578b\u5728\u751f\u6210\u521b\u65b0\u673a\u4f1a\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u529f\u80fd\u6a21\u5757\u4ee5\u63d0\u9ad8\u65b0\u9896\u6027\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aEBR\u7684\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u4f7f\u7528\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\uff0c\u4f46\u8fd9\u4e9b\u63a8\u7406\u5668\u5bf9\u77e5\u8bc6\u5e93\u4e2d\u7684\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u4e0d\u9c81\u68d2\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u9645\u77e5\u8bc6\u5e93\u4e2d\u7684\u5e94\u7528\u3002", "method": "EBR\u795e\u7ecf\u63a8\u7406\u5668\u5229\u7528\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u4ec5\u9700\u8981\u68c0\u7d22\u539f\u5b50\u6982\u5ff5\u548c\u5b58\u5728\u9650\u5236\u7684\u5b9e\u4f8b\uff0c\u5c31\u80fd\u68c0\u7d22\u6216\u8fd1\u4f3cSHOIQ\u63cf\u8ff0\u903b\u8f91\u4e2d\u4efb\u4f55\u6982\u5ff5\u7684\u5b9e\u4f8b\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEBR\u5728\u7f3a\u5931\u548c\u9519\u8bef\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u9c81\u68d2\uff0c\u4f18\u4e8e\u73b0\u6709\u63a8\u7406\u5668\u3002", "conclusion": "EBR\u795e\u7ecf\u63a8\u7406\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u5e93\u4e2d\u7684\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u95ee\u9898\u3002"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u53ef\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u7ea7\u5bf9\u9f50\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u9700\u8981\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u8fdb\u884c\u8fed\u4ee3\u5f0f\u6574\u4f53\u5bf9\u9f50\uff0c\u652f\u6301\u60ac\u7a7a\u5b9e\u4f53\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6536\u655b\u6027\u3002", "result": "\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "FLORA\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65e0\u76d1\u7763\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2510.20568", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20568", "abs": "https://arxiv.org/abs/2510.20568", "authors": ["Susan Ariel Aaronson", "Michael Moreno"], "title": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "comment": null, "summary": "The worlds people have strong opinions about artificial intelligence (AI),\nand they want policymakers to listen. Governments are inviting public comment\non AI, but as they translate input into policy, much of what citizens say is\nlost. Policymakers are missing a critical opportunity to build trust in AI and\nits governance. This paper compares three countries, Australia, Colombia, and\nthe United States, that invited citizens to comment on AI risks and policies.\nUsing a landscape analysis, the authors examined how each government solicited\nfeedback and whether that input shaped governance. Yet in none of the three\ncases did citizens and policymakers establish a meaningful dialogue.\nGovernments did little to attract diverse voices or publicize calls for\ncomment, leaving most citizens unaware or unprepared to respond. In each\nnation, fewer than one percent of the population participated. Moreover,\nofficials showed limited responsiveness to the feedback they received, failing\nto create an effective feedback loop. The study finds a persistent gap between\nthe promise and practice of participatory AI governance. The authors conclude\nthat current approaches are unlikely to build trust or legitimacy in AI because\npolicymakers are not adequately listening or responding to public concerns.\nThey offer eight recommendations: promote AI literacy; monitor public feedback;\nbroaden outreach; hold regular online forums; use innovative engagement\nmethods; include underrepresented groups; respond publicly to input; and make\nparticipation easier.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u548c\u7f8e\u56fd\u4e09\u4e2a\u56fd\u5bb6\u5728AI\u6cbb\u7406\u4e2d\u7684\u516c\u4f17\u53c2\u4e0e\u60c5\u51b5\uff0c\u53d1\u73b0\u653f\u5e9c\u672a\u80fd\u5efa\u7acb\u6709\u6548\u7684\u516c\u4f17\u5bf9\u8bdd\u673a\u5236\uff0c\u53c2\u4e0e\u7387\u4f4e\u4e14\u53cd\u9988\u54cd\u5e94\u4e0d\u8db3\uff0c\u5bfc\u81f4\u53c2\u4e0e\u5f0fAI\u6cbb\u7406\u7684\u627f\u8bfa\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u8ba8\u653f\u5e9c\u5728AI\u6cbb\u7406\u4e2d\u5982\u4f55\u6536\u96c6\u548c\u56de\u5e94\u516c\u4f17\u610f\u89c1\uff0c\u4ee5\u53ca\u8fd9\u79cd\u53c2\u4e0e\u8fc7\u7a0b\u662f\u5426\u80fd\u591f\u5efa\u7acb\u516c\u4f17\u5bf9AI\u53ca\u5176\u6cbb\u7406\u7684\u4fe1\u4efb\u3002", "method": "\u91c7\u7528\u666f\u89c2\u5206\u6790\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e09\u4e2a\u56fd\u5bb6\uff08\u6fb3\u5927\u5229\u4e9a\u3001\u54e5\u4f26\u6bd4\u4e9a\u3001\u7f8e\u56fd\uff09\u5f81\u96c6AI\u98ce\u9669\u548c\u653f\u7b56\u53cd\u9988\u7684\u65b9\u5f0f\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53cd\u9988\u5982\u4f55\u5f71\u54cd\u6cbb\u7406\u51b3\u7b56\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u4e09\u56fd\u53c2\u4e0e\u7387\u5747\u4f4e\u4e8e\u4eba\u53e31%\uff1b2\uff09\u653f\u5e9c\u7f3a\u4e4f\u5438\u5f15\u591a\u6837\u5316\u58f0\u97f3\u7684\u52aa\u529b\uff1b3\uff09\u5b98\u5458\u5bf9\u53cd\u9988\u7684\u54cd\u5e94\u6709\u9650\uff1b4\uff09\u672a\u80fd\u5efa\u7acb\u6709\u6548\u7684\u53cd\u9988\u5faa\u73af\u673a\u5236\u3002", "conclusion": "\u5f53\u524d\u53c2\u4e0e\u5f0fAI\u6cbb\u7406\u65b9\u6cd5\u96be\u4ee5\u5efa\u7acb\u4fe1\u4efb\u548c\u5408\u6cd5\u6027\uff0c\u56e0\u4e3a\u51b3\u7b56\u8005\u672a\u80fd\u5145\u5206\u503e\u542c\u548c\u56de\u5e94\u516c\u4f17\u5173\u5207\u3002\u4f5c\u8005\u63d0\u51fa8\u6761\u6539\u8fdb\u5efa\u8bae\uff0c\u5305\u62ec\u63d0\u5347AI\u7d20\u517b\u3001\u6269\u5927\u53c2\u4e0e\u8303\u56f4\u3001\u4f7f\u7528\u521b\u65b0\u53c2\u4e0e\u65b9\u6cd5\u7b49\u3002"}}
{"id": "2510.20591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20591", "abs": "https://arxiv.org/abs/2510.20591", "authors": ["Ali Rajaei", "Peter Palensky", "Jochen L. Cremer"], "title": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "comment": null, "summary": "Network topology optimization (NTO) via busbar splitting can mitigate\ntransmission grid congestion and reduce redispatch costs. However, solving this\nmixed-integer non-linear problem for large-scale systems in near-real-time is\ncurrently intractable with existing solvers. Machine learning (ML) approaches\nhave emerged as a promising alternative, but they have limited generalization\nto unseen topologies, varying operating conditions, and different systems,\nwhich limits their practical applicability. This paper formulates NTO for\ncongestion management problem considering linearized AC PF, and proposes a\ngraph neural network (GNN)-accelerated approach. We develop a heterogeneous\nedge-aware message passing NN to predict effective busbar splitting actions as\ncandidate NTO solutions. The proposed GNN captures local flow patterns,\nachieves generalization to unseen topology changes, and improves\ntransferability across systems. Case studies show up to 4 orders-of-magnitude\nspeed-up, delivering AC-feasible solutions within one minute and a 2.3%\noptimality gap on the GOC 2000-bus system. These results demonstrate a\nsignificant step toward near-real-time NTO for large-scale systems with\ntopology and cross-system generalization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u7684\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u7f13\u89e3\u8f93\u7535\u7f51\u62e5\u5835\u548c\u964d\u4f4e\u518d\u8c03\u5ea6\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6c42\u89e3\u5668\u5feb4\u4e2a\u6570\u91cf\u7ea7\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6c42\u89e3\u5668\u65e0\u6cd5\u5728\u8fd1\u5b9e\u65f6\u5185\u89e3\u51b3\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6cdb\u5316\u5230\u672a\u89c1\u62d3\u6251\u3001\u4e0d\u540c\u8fd0\u884c\u6761\u4ef6\u548c\u7cfb\u7edf\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5f02\u6784\u8fb9\u7f18\u611f\u77e5\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u6709\u6548\u7684\u6bcd\u7ebf\u5206\u88c2\u52a8\u4f5c\u4f5c\u4e3a\u5019\u9009\u62d3\u6251\u4f18\u5316\u89e3\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u7ebf\u6027\u5316\u4ea4\u6d41\u6f6e\u6d41\uff0c\u80fd\u591f\u6355\u6349\u5c40\u90e8\u6d41\u91cf\u6a21\u5f0f\u3002", "result": "\u5728GOC 2000\u603b\u7ebf\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe4\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff0c\u5728\u4e00\u5206\u949f\u5185\u63d0\u4f9b\u4ea4\u6d41\u53ef\u884c\u89e3\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4ec5\u4e3a2.3%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u62d3\u6251\u548c\u8de8\u7cfb\u7edf\u6cdb\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u8fd1\u5b9e\u65f6\u7f51\u7edc\u62d3\u6251\u4f18\u5316\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.20603", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20603", "abs": "https://arxiv.org/abs/2510.20603", "authors": ["Heejin Do", "Jaehui Hwang", "Dongyoon Han", "Seong Joon Oh", "Sangdoo Yun"], "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "comment": null, "summary": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.", "AI": {"tldr": "\u63d0\u51faCaSE\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u7684\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u6765\u6539\u8fdbLLM\u63a8\u7406\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u68c0\u67e5\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u53ea\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\uff0c\u65e0\u6cd5\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u4fe1\u53f7\u3002", "method": "\u5f15\u5165\u56e0\u679c\u9010\u6b65\u8bc4\u4f30(CaSE)\u65b9\u6cd5\uff0c\u5c06\u63a8\u7406\u8d28\u91cf\u5206\u89e3\u4e3a\u76f8\u5173\u6027\u548c\u8fde\u8d2f\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u4ec5\u4f7f\u7528\u524d\u6587\u4fe1\u606f\u8bc4\u4f30\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u4ee5\u907f\u514d\u540e\u89c1\u4e4b\u660e\u504f\u5dee\u3002", "result": "\u5728MRa-GSM8K\u548cMRa-MATH\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86CaSE\u4e0e\u4eba\u5de5\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\uff0c\u4f7f\u7528CaSE\u8bc4\u4f30\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u80fd\u76f4\u63a5\u63d0\u5347\u6700\u7ec8\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "CaSE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u5206\u6790\u3001\u8c03\u8bd5\u548c\u6539\u8fdbLLM\u63a8\u7406\uff0c\u8bc1\u660e\u4e86\u8d85\u8d8a\u6709\u6548\u6027\u68c0\u67e5\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2510.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20604", "abs": "https://arxiv.org/abs/2510.20604", "authors": ["Changan Liu", "Zixuan Xie", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Algorithms for Computing Random Walk Centrality", "comment": "Accepted by TKDE", "summary": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u53ef\u6269\u5c55\u7684\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u7b97\u6cd5\uff0c\u4f7f\u7528\u8fd1\u4f3cCholesky\u5206\u89e3\u548c\u751f\u6210\u6811\u91c7\u6837\uff0c\u5728\u8fd1\u7ebf\u6027\u65f6\u95f4\u5185\u63d0\u4f9b\u5f3a\u8fd1\u4f3c\u4fdd\u8bc1", "motivation": "\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\u80fd\u591f\u6355\u6349\u4e30\u5bcc\u7684\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u5728\u5927\u578b\u7f51\u7edc\u4e2d\u8ba1\u7b97\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8", "method": "\u57fa\u4e8e\u65b0\u516c\u5f0f\u5316\u7684\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\uff0c\u5f00\u53d1\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u4e00\u79cd\u5229\u7528\u8fd1\u4f3cCholesky\u5206\u89e3\u548c\u7a00\u758f\u9006\u4f30\u8ba1\uff0c\u53e6\u4e00\u79cd\u901a\u8fc7\u91c7\u6837\u6839\u751f\u6210\u6811", "result": "\u5728\u5305\u542b\u8d85\u8fc71000\u4e07\u4e2a\u8282\u70b9\u7684\u5927\u578b\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6548\u7387\u548c\u8fd1\u4f3c\u8d28\u91cf", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u9ad8\u6548\u8ba1\u7b97\u968f\u673a\u6e38\u8d70\u4e2d\u5fc3\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.20621", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20621", "abs": "https://arxiv.org/abs/2510.20621", "authors": ["Riccardo Guidotti", "Martina Cinquini", "Marta Marchiori Manerba", "Mattia Setzu", "Francesco Spinnato"], "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "comment": null, "summary": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.", "AI": {"tldr": "MIMOSA\u6846\u67b6\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u6027\u4f18\u5148\u7684\u9884\u6d4b\u6a21\u578b\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5d4c\u5165\u56e0\u679c\u6027\u3001\u516c\u5e73\u6027\u548c\u9690\u79c1\u6027\u7b49\u5173\u952e\u4f26\u7406\u5c5e\u6027\u3002", "motivation": "\u9700\u8981\u6784\u5efa\u53ef\u4fe1\u8d56\u7684AI\u7cfb\u7edf\uff0c\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u4fc3\u8fdb\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u5b89\u5168\u91c7\u7528\u81ea\u52a8\u5316\u51b3\u7b56\u6a21\u578b\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\uff0c\u6db5\u76d6\u8868\u683c\u6570\u636e\u3001\u65f6\u95f4\u5e8f\u5217\u3001\u56fe\u50cf\u3001\u6587\u672c\u7b49\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5206\u6790\u4e86\u7279\u5f81\u91cd\u8981\u6027\u3001\u89c4\u5219\u548c\u5b9e\u4f8b\u4e09\u7c7b\u53ef\u89e3\u91ca\u6a21\u578b\u5bb6\u65cf\u3002", "result": "\u5efa\u7acb\u4e86\u53ef\u89e3\u91ca\u6a21\u578b\u4e0e\u4f26\u7406\u5c5e\u6027\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u5b9a\u4e49\u3001\u8bc4\u4f30\u6307\u6807\u548c\u9a8c\u8bc1\u7a0b\u5e8f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f00\u53d1\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u3001\u516c\u5e73\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u56e0\u679c\u611f\u77e5\u7684\u53ef\u4fe1\u8d56AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20632", "abs": "https://arxiv.org/abs/2510.20632", "authors": ["Shuyi Xie", "Ziqin Liew", "Hailing Zhang", "Haibo Zhang", "Ling Hu", "Zhiqiang Zhou", "Shuman Liu", "Anxiang Zeng"], "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "comment": null, "summary": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.", "AI": {"tldr": "EcomEval\u662f\u4e00\u4e2a\u5168\u9762\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7535\u5b50\u5546\u52a1\u9886\u57df\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u5de5\u5177\u5728\u4efb\u52a1\u591a\u6837\u6027\u3001\u6a21\u6001\u8986\u76d6\u548c\u6570\u636e\u771f\u5b9e\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5546\u52a1\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u7f3a\u4e4f\u591a\u6a21\u6001\u6570\u636e\u3001\u4f7f\u7528\u5408\u6210\u6570\u636e\u4ee5\u53ca\u8bed\u8a00\u8986\u76d6\u72ed\u7a84\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u6a21\u578b\u5728\u590d\u6742\u771f\u5b9e\u8d2d\u7269\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u534a\u81ea\u52a8\u6d41\u7a0b\uff0c\u9996\u5148\u7531\u5927\u6a21\u578b\u751f\u6210\u5019\u9009\u56de\u7b54\uff0c\u7136\u540e\u753150\u591a\u540d\u5177\u6709\u7535\u5b50\u5546\u52a1\u548c\u591a\u8bed\u8a00\u4e13\u4e1a\u77e5\u8bc6\u7684\u4e13\u5bb6\u6807\u6ce8\u8005\u8fdb\u884c\u5ba1\u67e5\u548c\u4fee\u6539\uff0c\u786e\u4fdd\u53c2\u8003\u7b54\u6848\u7684\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "EcomEval\u6db5\u76d66\u4e2a\u7c7b\u522b\u548c37\u4e2a\u4efb\u52a1\uff08\u5305\u62ec8\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\uff09\uff0c\u4e3b\u8981\u6765\u6e90\u4e8e\u771f\u5b9e\u5ba2\u6237\u67e5\u8be2\u548c\u4ea4\u6613\u65e5\u5fd7\uff0c\u53cd\u6620\u4e86\u771f\u5b9e\u4e1a\u52a1\u4ea4\u4e92\u7684\u566a\u58f0\u548c\u5f02\u6784\u6027\u8d28\u3002", "conclusion": "EcomEval\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u80fd\u591f\u5bf9LLM\u5728\u7535\u5b50\u5546\u52a1\u9886\u57df\u8fdb\u884c\u6311\u6218\u5bfc\u5411\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u7279\u522b\u8986\u76d6\u4e865\u79cd\u4f4e\u8d44\u6e90\u4e1c\u5357\u4e9a\u8bed\u8a00\u3002"}}
{"id": "2510.20636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20636", "abs": "https://arxiv.org/abs/2510.20636", "authors": ["Eric Ngoiya", "Tianshu Bao"], "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "comment": "12", "summary": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6d41\u52a8\u6027\u6307\u6570(FI)\u6765\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u8bc4\u4f30\u521d\u59cb\u3001\u5f53\u524d\u548c\u672a\u6765\u73af\u5883\u72b6\u6001\u504f\u5dee\u6765\u8861\u91cf\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u533a\u5206\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u9700\u8981\u91cf\u5316\u6a21\u578b\u5728\u52a8\u6001\u6269\u5c55\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u72b6\u6001\u53d8\u5316\u7684\u7406\u89e3\u3001\u9884\u6d4b\u548c\u8c03\u6574\u80fd\u529b\uff0c\u4e3a\u8d85\u7ea7\u667a\u80fd\u6a21\u578b\u8bbe\u5b9a\u9002\u5e94\u6027\u6807\u51c6\u3002", "method": "\u5f15\u5165\u6d41\u52a8\u6027\u6307\u6570(FI)\u57fa\u51c6\u6d4b\u8bd5\uff0c\u57fa\u4e8e\u73af\u5883\u72b6\u6001\u504f\u5dee\u8bc4\u4f30\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u533a\u5206\u95ed\u5f0f\u548c\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5173\u6ce8\u95ed\u73af\u5f00\u653e\u5f0f\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5efa\u7acb\u4e86\u91cf\u5316\u6a21\u578b\u9002\u5e94\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u6d4b\u91cf\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u548c\u8fde\u7eed\u6027\u4fdd\u6301\u80fd\u529b\u3002", "conclusion": "\u771f\u6b63\u8d85\u7ea7\u667a\u80fd\u7684\u6a21\u578b\u5e94\u81f3\u5c11\u5177\u5907\u4e8c\u9636\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u6570\u5b57\u8865\u5145\u5b9e\u73b0\u81ea\u6211\u7ef4\u6301\u8ba1\u7b97\u4ee5\u8fbe\u5230\u6700\u4f73\u6d41\u52a8\u6027\u3002"}}
{"id": "2510.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20641", "abs": "https://arxiv.org/abs/2510.20641", "authors": ["Andrea Agiollo", "Andrea Omicini"], "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "comment": null, "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5c06\u673a\u5668\u5b66\u4e60\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8BDI\uff08\u4fe1\u5ff5-\u6b32\u671b-\u610f\u56fe\uff09\u8303\u5f0f\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u7531\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u611f\u77e5\u548c\u8ba4\u77e5\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u7c7b\u4eba\u80fd\u529b\uff0c\u5c06\u5176\u96c6\u6210\u5230\u7406\u6027\u667a\u80fd\u4f53\u67b6\u6784\u4e2d\u7684\u6846\u67b6\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528BDI\u8303\u5f0f\u4f5c\u4e3a\u53c2\u8003\u6846\u67b6\uff0c\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7cfb\u7edf\u5316\u5206\u6790\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u589e\u5f3a\u7406\u6027\u667a\u80fd\u4f53\u7684\u673a\u5668\u5b66\u4e60\u6587\u732e\u5feb\u901f\u53d1\u5c55\uff0c\u5e76\u8bc6\u522b\u4e86\u5173\u952e\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8bbe\u8ba1\u6709\u6548\u7406\u6027\u673a\u5668\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u5173\u952e\u7814\u7a76\u673a\u4f1a\u548c\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2510.20665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20665", "abs": "https://arxiv.org/abs/2510.20665", "authors": ["Xue Wen Tan", "Nathaniel Tan", "Galen Lee", "Stanley Kok"], "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "comment": null, "summary": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u6846\u67b6\u6765\u81ea\u52a8\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u7684\u8d28\u91cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fe\u6307\u6807\u6709\u66f4\u9ad8\u9884\u6d4b\u80fd\u529b", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u8d28\u91cf\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\uff0c\u8d39\u65f6\u8d39\u529b\u4e14\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u6846\u67b6", "method": "\u4f7f\u7528\u62d3\u6251\u6570\u636e\u5206\u6790\u65b9\u6cd5\u6355\u6349\u63a8\u7406\u8f68\u8ff9\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u901a\u8fc7\u62d3\u6251\u7279\u5f81\u8fdb\u884c\u81ea\u52a8\u5316\u8bc4\u4f30", "result": "\u62d3\u6251\u7279\u5f81\u5728\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\u65b9\u9762\u6bd4\u6807\u51c6\u56fe\u6307\u6807\u5177\u6709\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8868\u660e\u6709\u6548\u63a8\u7406\u66f4\u9002\u5408\u7528\u9ad8\u7ef4\u51e0\u4f55\u7ed3\u6784\u800c\u975e\u7eaf\u5173\u7cfb\u56fe\u6765\u6355\u6349", "conclusion": "\u7d27\u51d1\u4e14\u7a33\u5b9a\u7684\u62d3\u6251\u7279\u5f81\u96c6\u80fd\u53ef\u9760\u6307\u793a\u8f68\u8ff9\u8d28\u91cf\uff0c\u4e3a\u672a\u6765\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8d28\u91cf\u4fe1\u53f7"}}
{"id": "2510.20691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20691", "abs": "https://arxiv.org/abs/2510.20691", "authors": ["Yanlin Song", "Ben Liu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiwei Hu", "Qianqian Xie", "Min Peng", "Sophia Ananiadou", "Jeff Z. Pan"], "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "comment": null, "summary": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.", "AI": {"tldr": "Graph-RFT\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\u7684KGQA\u6846\u67b6\uff0c\u901a\u8fc7'\u89c4\u5212-KG\u641c\u7d22-\u7f51\u7edc\u641c\u7d22-\u601d\u8003'\u8303\u5f0f\uff0c\u8ba9LLM\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u6761\u4ef6\u4e0b\u81ea\u4e3b\u89c4\u5212\u5e76\u81ea\u9002\u5e94\u68c0\u7d22KG\u548c\u7f51\u7edc\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709KGQA\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u5229\u7528KG\u4e2d\u7684\u4e30\u5bcc\u77e5\u8bc6\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u573a\u666f\u4e0b\u3002\u5b83\u4eec\u901a\u5e38\u5047\u8bbeKG\u8986\u76d6\u5b8c\u6574\uff0c\u7f3a\u4e4f\u5224\u65ad\u4f55\u65f6\u9700\u8981\u5916\u90e8\u4fe1\u606f\u7684\u673a\u5236\uff0c\u4e14\u63a8\u7406\u8fc7\u7a0b\u5c40\u90e8\u77ed\u89c6\uff0c\u65e0\u6cd5\u4fdd\u6301\u8fde\u8d2f\u7684\u591a\u6b65\u89c4\u5212\u3002", "method": "Graph-RFT\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u94fe\u5f0f\u601d\u7ef4\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528\u5b9a\u5236\u7684\u89c4\u5212-\u68c0\u7d22\u6570\u636e\u96c6\u6fc0\u6d3b\u7ed3\u6784\u5316\u63a8\u7406\uff1b2\uff09\u89c4\u5212-\u68c0\u7d22\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\uff0c\u6574\u5408\u663e\u5f0f\u89c4\u5212\u548c\u68c0\u7d22\u52a8\u4f5c\uff0c\u91c7\u7528\u591a\u5956\u52b1\u8bbe\u8ba1\u5b9e\u73b0\u8986\u76d6\u611f\u77e5\u7684\u68c0\u7d22\u8c03\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u6709\u5e8f\u5b50\u95ee\u9898\uff0c\u4f7f\u7528\u903b\u8f91\u8868\u8fbe\u5f0f\u6307\u5bfc\u5de5\u5177\u8c03\u7528\uff0c\u5b9e\u73b0\u5168\u5c40\u4e00\u81f4\u7684\u591a\u6b65\u63a8\u7406\uff0c\u5e76\u6709\u6548\u7ed3\u5408KG\u548c\u7f51\u7edc\u68c0\u7d22\u3002", "conclusion": "Graph-RFT\u901a\u8fc7\u81ea\u4e3b\u89c4\u5212\u548c\u81ea\u9002\u5e94\u68c0\u7d22\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709KGQA\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u63a8\u7406\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u6761\u4ef6\u4e0b\u7684\u95ee\u7b54\u6027\u80fd\u3002"}}
{"id": "2510.20784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20784", "abs": "https://arxiv.org/abs/2510.20784", "authors": ["Fares Fourati"], "title": "A Coherence-Based Measure of AGI", "comment": "13 pages, 1 figure, 12 tables", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u7684AGI\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u7b97\u672f\u5e73\u5747\u503c\u7684\u8865\u507f\u6027\u5047\u8bbe\uff0c\u5f3a\u8c03\u8de8\u8ba4\u77e5\u9886\u57df\u7684\u5e73\u8861\u80fd\u529b\u3002", "motivation": "\u73b0\u6709AGI\u5b9a\u4e49\u4f7f\u7528\u7b97\u672f\u5e73\u5747\u503c\uff0c\u5047\u8bbe\u9886\u57df\u95f4\u80fd\u529b\u53ef\u4ee5\u76f8\u4e92\u8865\u507f\uff0c\u4f46\u8fd9\u4e0d\u80fd\u53cd\u6620\u771f\u6b63\u7684\u901a\u7528\u667a\u80fd\u6240\u9700\u7684\u8de8\u9886\u57df\u5e73\u8861\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u7684AGI\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c\u901a\u8fc7\u8fde\u7eed\u8865\u507f\u6027\u6307\u6570\u8986\u76d6\u7b97\u672f\u3001\u51e0\u4f55\u548c\u8c03\u548c\u5747\u503c\uff0c\u7528\u66f2\u7ebf\u4e0b\u9762\u79ef(AUC)\u91cf\u5316\u4e0d\u540c\u8865\u507f\u6027\u5047\u8bbe\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5e94\u7528\u8be5\u65b9\u6cd5\u8bc4\u4f30GPT-4\u548cGPT-5\u7684CHC\u9886\u57df\u5f97\u5206\uff0c\u53d1\u73b0\u5c3d\u7ba1\u7b97\u672f\u5f97\u5206\u8f83\u9ad8(GPT-5\u8fbe24%)\uff0c\u4f46\u4e00\u81f4\u6027\u8c03\u6574\u7684AUC\u663e\u793a\u4e24\u8005\u8ddd\u79bb\u771f\u6b63\u7684\u901a\u7528\u80fd\u529b\u4ecd\u6709\u5f88\u5927\u5dee\u8ddd\u3002", "conclusion": "\u5e7f\u4e49\u5747\u503c\u79ef\u5206\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u3001\u53ef\u89e3\u91ca\u4e14\u66f4\u4e25\u683c\u7684AGI\u5ea6\u91cf\u57fa\u7840\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8861\u91cf\u5411\u771f\u6b63\u901a\u7528\u667a\u80fd\u7684\u8fdb\u5c55\u3002"}}
{"id": "2510.20809", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20809", "abs": "https://arxiv.org/abs/2510.20809", "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"], "title": "Real Deep Research for AI, Robotics and Beyond", "comment": "website: https://realdeepresearch.github.io", "summary": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aReal Deep Research (RDR)\u7684\u53ef\u6cdb\u5316\u5206\u6790\u7ba1\u9053\uff0c\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u7814\u7a76\u9886\u57df\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\u548c\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u7279\u522b\u5e94\u7528\u4e8eAI\u548c\u673a\u5668\u4eba\u9886\u57df\u3002", "motivation": "AI\u548c\u673a\u5668\u4eba\u9886\u57df\u6bcf\u5e74\u4ea7\u751f\u8d85\u8fc710,000\u7bc7\u8bba\u6587\uff0c\u7814\u7a76\u4eba\u5458\u96be\u4ee5\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684\u8d8b\u52bf\u3001\u8de8\u5b66\u79d1\u5de5\u4f5c\u548c\u63a2\u7d22\u65b0\u9886\u57df\u7684\u9700\u6c42\u3002", "method": "\u6784\u5efaRDR\u7ba1\u9053\uff0c\u80fd\u591f\u7cfb\u7edf\u5206\u6790\u4efb\u4f55\u7814\u7a76\u9886\u57df\uff0c\u8bc6\u522b\u65b0\u5174\u8d8b\u52bf\uff0c\u53d1\u73b0\u8de8\u9886\u57df\u673a\u4f1a\uff0c\u5e76\u4e3a\u65b0\u7814\u7a76\u63d0\u4f9b\u5177\u4f53\u8d77\u70b9\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8eAI\u548c\u673a\u5668\u4eba\u9886\u57df\uff0c\u7279\u522b\u5173\u6ce8\u57fa\u7840\u6a21\u578b\u548c\u673a\u5668\u4eba\u6280\u672f\u8fdb\u5c55\uff0c\u5e76\u6269\u5c55\u5230\u5176\u4ed6\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "RDR\u6846\u67b6\u4e3aAI\u53ca\u5176\u4ed6\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5206\u6790\u5de5\u5177\uff0c\u5e2e\u52a9\u4ed6\u4eec\u5728\u5feb\u901f\u53d1\u5c55\u7684\u7814\u7a76\u73af\u5883\u4e2d\u4fdd\u6301\u66f4\u65b0\u3002"}}
