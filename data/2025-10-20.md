<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下进行数值估计任务的多领域基准测试，发现前沿语言模型的概率先验通常不准确且过于自信。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要处理不完整信息和不确定性推理，但现有评估主要关注有明确答案的问题，缺乏对不确定性推理能力的系统评估。

Method: 开发了OpenEstimate基准测试，通过数值估计任务评估语言模型，要求模型综合背景信息并表达概率先验，评估这些先验的准确性和校准度。

Result: 在六个前沿语言模型上测试发现，模型产生的先验通常不准确且过于自信，性能受不确定性提取方式影响有限，对采样策略、推理努力或提示设计的改变不敏感。

Conclusion: OpenEstimate为前沿语言模型提供了具有挑战性的评估平台，有助于开发在概率估计和不确定性推理方面表现更好的模型。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [2] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种使用深度强化学习在Unity 3D环境中进行程序化关卡设计的新方法，通过两个智能体（蜂鸟和浮岛）的交互实现内容生成与解决。


<details>
  <summary>Details</summary>
Motivation: 探索程序化内容生成在游戏开发中的应用，利用深度强化学习减少手动工作量，创造动态、可重玩且可扩展的游戏环境。

Method: 使用Unity ML-Agents工具包中的PPO算法训练两个智能体：蜂鸟智能体作为解决者学习导航和收集花朵，浮岛智能体负责基于障碍物位置和蜂鸟状态生成花朵布局。

Result: 系统产生了涌现行为，在各种环境配置中展现出强大的泛化能力，实现了有效的智能体行为和自主游戏关卡设计。

Conclusion: 该工作展示了深度强化学习在虚拟环境中实现内容生成与解决的潜力，为AI在创意游戏开发过程中的贡献开辟了新途径。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [3] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 本文认为AGI发展的瓶颈在于理论而非数据或规模，提出基于批判理性主义的Causal Mechanics框架，强调假设空间变化作为首要操作，通过模块化干预和组合自主原则来发现和修正不可达错误。


<details>
  <summary>Details</summary>
Motivation: 挑战柏拉图表示假说，指出观测等价的世界在干预下可能分化，仅靠观测充分性无法保证干预能力，需要理论突破来解决AGI发展的根本限制。

Method: 提出Causal Mechanics框架，将假设空间变化作为核心操作，引入局部性和自主性原则、独立因果机制和组合自主原则，建立可操作的诊断方法。

Result: 建立了理论框架和结构原则，使错误发现和修正变得可行，为将不可达错误转化为可达错误并修正提供了脚手架。

Conclusion: AGI进展需要理论创新而非单纯的数据扩展，Causal Mechanics通过强调假设空间演化和错误修正机制，为解决AGI核心问题提供了新路径。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [4] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估AI模型从群体推理适应到个体推理能力的基准测试，包含合成和人类双轨设计，旨在让机器推理更贴近人类个体思维特征。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然能大规模近似人类响应，但主要反映群体共识，缺乏对个体推理风格和信念轨迹的个性化捕捉。

Method: 采用双轨设计：合成轨道用于规模化和系统性压力测试，人类轨道用于生态有效的"出声"推理数据收集。

Result: 实验显示最先进的LLMs在个体推理适应方面仍存在持续差距。

Conclusion: HugAgent是首个可扩展的基准测试，用于将机器推理与人类思维的个体特征对齐。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [5] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个包含733,651个面部表情记录的大规模纵向职场情绪数据集，收集自38名员工在30.5个月内的真实办公环境，包含7种情绪概率和32个扩展情绪指标，验证了数据质量并展示了91.2%的情绪分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决真实职场环境中自动化情绪识别面临的挑战，即缺乏在自然环境中收集的大规模、纵向数据集。

Method: 在真实办公环境中收集38名员工30.5个月的面部表情数据，使用深度学习进行面部表情识别，计算7种情绪概率和32个扩展情绪指标，并进行技术验证和基线实验。

Result: 数据集成功复制已知心理模式（周末效应：+192%效价改善，p<0.001），员工流失预测AUC=1.0，随机森林和LSTM模型情绪分类准确率91.2%，效价预测R2=0.84。

Conclusion: 这是公开可用的最大、最长的纵向职场情绪数据集，可用于情绪识别、情感动态建模、情绪传染、流失预测和情绪感知系统设计等研究。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [6] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出AGI评估应使用非对称权重和持久性测试，将通用智能视为稳态属性集群，而非简单的多领域能力集合。


<details>
  <summary>Details</summary>
Motivation: 传统AGI评估存在两个问题：对称权重假设所有领域同等重要，而人类智能研究表明并非如此；快照测试无法区分持久能力和脆弱表现。

Method: 提出两种评估扩展：基于因果中心性的权重评分（导入CHC衍生权重）和集群稳定性指数系列（评估配置持久性、持久学习和错误纠正）。

Result: 这些扩展保持了多领域广度，同时减少了脆弱性和博弈行为，提供了可测试的预测和黑盒协议。

Conclusion: 通用智能应被理解为稳态属性集群，AGI评估需要衡量能力在扰动下的持久性和稳定性，而不仅仅是快照表现。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [7] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出了一种基于LLM代理与知识图谱交互的多维数据分析方法，构建动态协作的分析生态系统，在生态系统分析、关系挖掘和用户驱动探索分析方面具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构、复杂关联的多维数据中提取深度洞察面临挑战。LLM在处理结构化知识时存在幻觉问题且难以实时更新，而知识图谱的静态特性限制了动态交互和分析能力。

Method: 利用LLM代理从非结构化数据中自动提取产品数据，实时构建和可视化知识图谱，并通过交互平台支持用户对图节点进行深度探索和分析。

Result: 实验结果表明该方法在产品生态系统分析、关系挖掘和用户驱动探索分析方面具有显著优势。

Conclusion: 该方法为多维数据分析提供了新思路和工具，构建了动态协作的分析生态系统。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [8] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent是一个经验驱动的学习框架，通过将像素级GUI交互构建为状态-动作知识图，解决API缺失环境下LLM智能体的效率瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有软件大多缺乏可访问的API，智能体只能通过像素级GUI进行操作。在这种无API环境下，基于LLM的智能体面临严重效率瓶颈：局限于局部视觉体验，做出短视决策，依赖低效的试错，阻碍了技能获取和长期规划。

Method: 提出KG-Agent框架，将原始像素级交互构建为持久的状态-动作知识图(SA-KG)。通过连接功能相似但视觉不同的GUI状态，形成丰富的经验邻域。设计基于图拓扑的混合内在奖励机制，结合状态价值奖励和探索新颖性奖励。

Result: 在Civilization V和Slay the Spire两个复杂的开放式GUI决策环境中进行评估，相比最先进方法在探索效率和战略深度方面有显著提升。

Conclusion: KG-Agent通过知识图结构有效解决了无API环境下智能体的探索效率和长期规划问题，实现了战略规划与纯探索的解耦。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [9] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态智能体系统，借鉴人类记忆机制，通过图结构的多模态上下文记忆实现概念驱动的信息检索，在性能和速度上都优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统主要存储文本信息，忽视了多模态信号的重要性。受人类记忆的多模态特性启发，作者希望开发一个更符合认知科学原理的多模态记忆系统。

Method: 系统包含4个循环阶段：编码（理解输入）、存储记忆（保存重要信息）、检索（从记忆中搜索相关上下文）、行动（执行任务）。采用图结构的多模态上下文记忆，将信息概念化为语义标签并与上下文关联。

Result: 在ImageNet分类任务中比传统多模态RAG方法快3.5倍，在MSC基准测试中优于MemGPT。

Conclusion: AUGUSTUS系统通过模拟人类记忆的多模态特性，在概念驱动的信息检索方面表现出色，为多模态智能体系统提供了更有效的记忆机制。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [10] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的新基准和框架，通过智能爬虫收集真实网页数据，采用结构化分节表示方法，并提供多模态评估协议，提升数据质量和评估粒度。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在编码和多模态理解方面的进步，需要更高质量的基准来评估指令到HTML生成任务，现有方法在数据质量和评估粒度方面存在不足。

Method: 提出三个关键创新：1）无边界可扩展的智能爬虫框架持续收集真实网页；2）结构化分节数据表示，整合元数据、局部UI截图和JSON格式的文本图像资源；3）分节级多模态评估协议，对齐文本、布局和视觉组件。

Result: 通过最先进的LLM实验和消融研究验证了结构化数据和分节评估的有效性，以及各组成部分的贡献。

Conclusion: WebGen-V是首个实现高粒度智能爬虫和评估的指令到HTML生成工作，提供了从真实数据采集、网页生成到结构化多模态评估的统一流程。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [11] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个通过整合视觉先验和多模态大模型来提升监督微调数据质量的管道，能有效减少事实错误和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型的数据增强方法存在视觉感知不足导致的事实错误和幻觉问题，需要提升SFT数据质量。

Method: 利用视觉识别模型和OCR系统提取结构化视觉先验，结合三个LMM评估原始答案，通过统计融合得到高置信度共识分数作为真实标签，训练轻量级批评模型并生成优化答案。

Result: 在六个多模态基准测试中，使用VERITAS处理数据微调的模型表现优于使用原始数据的模型，特别是在文本丰富和细粒度推理任务中。

Conclusion: VERITAS能有效提升多模态数据质量，批评模型在保持高效的同时展现出与先进LMM相当的能力。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [12] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一个新的强化学习框架，通过解耦优势算法、难度感知长度惩罚和优势裁剪方法，显著减少大推理模型在简单任务中的低效推理和过长响应，在保持准确性的同时降低39%的序列长度。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提高了模型准确性，但会导致响应过长和过度思考问题，增加了推理延迟和计算消耗，特别是在简单任务中需要最小推理时。

Method: DEPO框架包含三个核心组件：(1)创新的优势解耦算法指导模型减少低效token；(2)难度感知长度惩罚降低模型响应整体长度；(3)优势裁剪方法防止策略优化偏差。

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上，DEPO实现了序列长度减少39%，减少了低效token中的过度推理路径，同时在整体准确性上优于基础模型。

Conclusion: DEPO有效解决了大推理模型在强化学习训练中的低效推理问题，在保持准确性的同时显著降低了计算成本和推理延迟。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [13] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 提出基于强化学习和关系图卷积神经网络的自动布局引擎，专门针对模拟集成电路布局中的布线感知问题，相比现有学习方法显著提升了布局质量。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局面临严格的电气约束和特定问题要求，且布局与布线步骤相互依赖，导致机器学习技术在该领域的应用受限。工程师需要现成的布线感知布局解决方案。

Method: 使用强化学习和关系图卷积神经网络构建自动布局引擎，结合增加的网格分辨率和精确引脚信息集成，以及动态布线资源估计技术，平衡布线效率和面积效率。

Result: 在模拟环境中，相比过去基于学习的最先进技术，该方法实现了13.8%的死区减少、40.6%的线长减少和73.4%的布线成功率提升。

Conclusion: 该方法能够满足工业标准，为模拟集成电路布局提供了有效的布线感知自动布局解决方案。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [14] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文提出了可修正性目标的概念和构建方法，确保AI在训练过程中不会抵制目标更新或关闭，同时保持与非可修正目标的竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有AI训练过程中，部分学习的目标会激励AI避免进一步的目标更新，因为大多数目标通过继续追求能更好实现。这种抵制行为会阻碍训练收敛、错误修正和人类偏好变化，是重要的安全问题。

Method: 首先形式化定义可修正性，然后引入一种转换方法，可以构建任何可修正目标的修正版本而不牺牲性能。该方法通过短视地获取在无成本阻止更新条件下的奖励预测，并基于此确定接受更新时的奖励。该方法可递归扩展到新创建的代理，并防止代理故意修改其目标。

Result: 两个网格世界实验表明，这些可修正目标可以有效学习，并产生期望的行为。

Conclusion: 可修正性是一个关键的安全属性，本文提出的方法能够构建既具有可修正性又具有竞争力的目标，为AI安全提供了重要保障。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [15] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一个端到端的强化学习框架，通过自博弈训练LLM在多智能体系统中进行推理，在合作和竞争游戏中都能提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在多轮多智能体场景中，强化学习面临的长期信用分配和智能体特定优势估计的挑战。

Method: 引入MARS框架，包含回合级优势估计器用于信用分配，以及智能体特定优势归一化来稳定多智能体训练。通过自博弈在合作和竞争游戏中训练。

Result: 从Qwen3-4B训练的MARS智能体在保留游戏中性能提升达28.7%，在推理基准测试中集成到领先多智能体系统后，AIME提升10.0%，GPQA-Diamond提升12.5%。

Conclusion: 基于战略游戏自博弈的端到端强化学习是开发LLM可泛化多智能体推理能力的有效方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [16] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个智能代理系统，将LoRA适配器作为领域专用工具，让基础LLM充当语义路由器动态选择最相关的LoRA工具，实现按需切换领域专家。


<details>
  <summary>Details</summary>
Motivation: 解决传统单一微调模型或基于规则路由的局限性，通过动态工具选择实现更灵活和准确的领域自适应AI辅助。

Method: 使用LangGraph进行工作流管理，基础LLM分析查询语义并动态选择最相关的LoRA适配器作为领域专家工具。

Result: 系统能够提供准确的专业化响应，同时保持对话能力，支持API和Web界面，完全开源。

Conclusion: Adaptive Minds结合多智能体编排的灵活性和参数高效微调的优势，为领域自适应AI辅助提供了可扩展和可扩展的基础。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [17] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 提出了一个检测和解决强化学习中判断不一致性的框架，包括冲突检测率(CDR)指标和去冲突图奖励(DGR)方法，显著提升训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中面临判断不一致性问题，特别是偏好循环等逻辑一致性问题尚未得到充分解决，这会影响训练稳定性。

Method: 引入CDR指标量化判断冲突，提出DGR框架构建偏好图，将其转换为无冲突的有向无环图，生成逻辑一致的奖励信号。

Result: 实验结果表明，该框架相比强基线显著提高了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中至关重要且现在可管理的维度。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [18] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 提出MM-HCAN多模态超图对比注意力网络，用于电机故障诊断，整合对比学习和超图拓扑，实现多传感器融合和多故障同时诊断，在真实基准测试中达到99.82%准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉复杂多模态信号关系，局限于单模态数据或单一故障类型，且在噪声或跨域条件下性能下降，需要更鲁棒的故障诊断方案。

Method: MM-HCAN框架整合对比学习与超图拓扑，专门设计用于多模态传感器融合，联合建模模态内和模态间依赖关系，超越欧几里得嵌入空间增强泛化能力。

Result: 在三个真实基准测试中达到99.82%准确率，具有强大的跨域泛化能力和噪声鲁棒性，适用于实际部署。消融研究验证了各组件贡献。

Conclusion: MM-HCAN为全面多故障诊断提供了可扩展且鲁棒的解决方案，支持工业环境中的预测性维护和资产寿命延长。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [19] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL是一个基于结构化推理和加权共识锦标赛机制的SQL候选选择框架，解决了文本到SQL任务中从多样化候选池中选择正确查询的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有的SQL候选选择方法（如自一致性或最佳N解码）只能提供浅层信号，容易导致评分不一致、推理链脆弱，以及无法捕捉密切相关的SQL候选之间的细粒度语义差异。

Method: 开发基于推理的SQL判断模型，通过强化学习在可验证奖励指导下提炼推理轨迹；采用加权共识锦标赛机制，将显式推理偏好与隐式生成器置信度相结合。

Result: 在BIRD基准测试上的广泛实验表明，JudgeSQL展现出卓越的SQL判断能力、良好的跨尺度泛化能力以及对生成器容量的鲁棒性。

Conclusion: JudgeSQL通过结构化推理和加权共识机制重新定义了SQL候选选择，提供了更可靠和高效的查询选择方案。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [20] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 开发了一个机器学习框架，整合患者历史就诊信息来改进健康监测，特别适用于就诊次数有限且频率不规律的情况。该模型在预测前列腺癌风险时显著降低了假阳性率。


<details>
  <summary>Details</summary>
Motivation: 医学中的时间背景对于评估患者健康状况随时间变化至关重要，特别是在历史就诊数据有限且频率多变的情况下，需要开发能够整合历史背景信息的模型来提高健康监测的准确性。

Method: 模型首先使用最近一次就诊的医疗数据估计疾病初始风险，然后利用从先前收集的影像学和/或临床生物标志物中提取的信息来优化评估。应用于前列腺癌风险预测，使用了大规模人群数据（28,342名患者，39,013次MRI扫描，68,931次血液检测）。

Result: 整合历史背景信息将假阳性转为真阴性，在保持高灵敏度的同时提高了特异性。整合最多三次先前影像检查信息时，假阳性率从51%降至33%；加入临床数据后进一步降至24%。预测五年内前列腺癌风险时，假阳性率从64%降至9%。

Conclusion: 随时间收集的信息为医学风险预测提供了相关背景，能够显著提高特异性。对于多种进展性疾病，通过背景信息充分降低假阳性率，可以为低基线风险的大规模人群扩展纵向健康监测项目，实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [21] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出了SciRecipe数据集和Thoth模型，通过"草图-填充"范式和结构化奖励机制，显著提升了科学实验协议生成的完整性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的科学实验协议往往不完整或不一致，限制了其在可重复科学研究中的实用性。

Method: 引入SciRecipe数据集，提出"草图-填充"范式分离分析、结构和表达，采用结构化组件奖励机制评估步骤粒度、行动顺序和语义保真度，并通过分阶段的知识到行动过程训练Thoth模型。

Result: Thoth在多个基准测试中持续超越专有和开源LLM，在步骤对齐、逻辑排序和语义准确性方面取得显著改进。

Conclusion: 该方法为构建可靠的科学助手铺平了道路，能够有效连接知识与实验执行。所有数据、代码和模型将公开发布。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [22] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了一个名为freephdlabor的开源多智能体框架，通过动态工作流和模块化架构实现科学发现的自动化，支持持续研究程序和人类干预。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现自动化系统存在两个根本限制：僵化的预编程工作流程无法适应中间发现，以及不充分的上下文管理阻碍长期研究。

Method: 采用完全动态工作流（由实时智能体推理决定）和模块化架构，提供自动上下文压缩、基于工作空间的通信、跨会话内存持久性和非阻塞人类干预机制。

Result: 该框架将自动化研究从孤立的单次尝试转变为持续研究程序，能够系统性地基于先前探索并整合人类反馈。

Conclusion: 通过提供构建可定制合作科学家系统的架构原则和实际实现，促进自动化研究在科学领域的更广泛采用。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [23] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 本文针对RLHF和DPO方法在人类偏好对齐中的局限性，提出了基于排名反馈和异质偏好的改进方法，建立了生成模型对齐的公平性和个性化理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF和DPO方法假设统一的标注者偏好并依赖二元比较，忽视了人类评估者的多样性和成对反馈的局限性。

Method: 1) 将偏好学习与计量经济学文献连接，证明二元比较不足以识别潜在用户偏好；2) 开发DPO的EM变体，发现潜在标注者类型并训练混合LLM；3) 提出基于最小最大遗憾公平准则的聚合算法。

Result: 证明了三个或更多响应的排名（即使不完整）能确保可识别性，并建立了具有公平性能保证的单一生成策略。

Conclusion: 这些贡献为生成模型对齐中的多样用户公平性和个性化建立了理论和算法框架。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [24] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 提出从发票文档中提取结构化信息的方法和评估指标，用于评估提取数据与标注真实值的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要标准化的评估框架来比较不同发票信息提取方法的性能，并识别各字段提取的优缺点。

Method: 使用Docling和LlamaCloud服务对扫描或数字发票进行预处理，识别并提取关键字段（如发票号、日期、总金额、供应商详情）。

Result: 建立了包含字段级精度、一致性检查失败和精确匹配准确率的稳健评估框架。

Conclusion: 提出的评估指标为标准比较不同提取方法提供了依据，并能突出显示字段特定性能的强项和弱点。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [25] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一的框架，用于检测、量化和减轻由代理AI产生的风险，采用基于gamma的风险评分方法，支持人机协同监督和代理间通信机制。


<details>
  <summary>Details</summary>
Motivation: 随着自主代理AI系统在组织中的采用增加，对齐、治理和风险管理方面的持续挑战阻碍了大规模部署。

Method: 引入基于gamma的风险评分方法，平衡风险评估准确性与计算效率；设计人机协同监督机制和代理到人通信机制；支持同步和异步自主运行的AI代理风险评估。

Result: AURA框架能够有效检测和减轻代理AI风险，同时平衡计算资源，支持大规模企业环境中可治理的代理AI部署。

Conclusion: AURA是促进企业环境中大规模、可治理代理AI采用的关键推动者，支持负责任和透明的代理AI采用。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [26] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了首个将帕金森病评估的多模态学习建模为多目标优化问题的系统TRIP，解决了训练时模态同步和推理时模态依赖的限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有帕金森病多模态评估方法存在两个主要局限：(1)训练时需要同步所有模态数据，(2)推理时依赖所有模态数据，这限制了实际应用。

Method: 将多模态学习建模为多目标优化问题，引入基于边界的类别重平衡策略来处理模态内不平衡问题。

Result: 在三个公共数据集上的实验表明，TRIP在异步设置下比最佳基线分别提升16.48、6.89和11.55个百分点，在同步设置下分别提升4.86和2.30个百分点。

Conclusion: TRIP框架在帕金森病评估中实现了最先进的性能，具有出色的有效性和适应性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [27] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 研究通过实验设计探讨了AI系统可解释性与用户信任的关系，发现交互式解释能增强用户参与度和信任度。


<details>
  <summary>Details</summary>
Motivation: 随着GPT-4等大型AI模型在关键领域部署，关于AI信任和透明度的问题日益紧迫，需要研究可解释性如何影响用户信任。

Method: 采用定量实验设计，通过基于网络的交互式贷款审批模拟，比较不同类型解释（从基本特征重要性到交互式反事实）对用户信任的影响。

Result: 结果表明交互性增强了用户参与度和信心，解释的清晰度和相关性是信任的关键决定因素。

Conclusion: 研究为人本可解释AI领域提供了实证证据，强调了可解释性设计对用户感知的可测量影响。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [28] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: Dialectica框架通过结构化对话、记忆、自我反思和政策约束的上下文编辑，使AI代理在解决复杂问题时能够通过经验发展专业知识。


<details>
  <summary>Details</summary>
Motivation: 解决复杂多维问题（如司法框架、环境污染、疫情韧性等）时，现有LLM缺乏通过经验发展专业知识的机制，需要新的方法来提升AI在非可验证领域的专业能力。

Method: 开发Dialectica框架，让代理在定义的主题上进行结构化对话，结合记忆、自我反思和政策约束的上下文编辑，将讨论视为隐式元强化学习过程。

Result: 在两种模型架构（Qwen3:30b和o4-mini）上的评估显示，启用基于反思的上下文编辑的代理在Elo分数、标准化Bradley-Terry-Davidson能力和AlphaRank质量上均优于基线。

Conclusion: 对话驱动的上下文演化是在开放非可验证领域实现针对性专业知识放大的可行路径，定量和定性证据一致支持这一结论。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [29] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 开发了六种RAG语料库配置用于长新冠临床问答，结合临床指南和高质量系统评价的配置表现最佳，提出了Guide-RAG系统和评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的应用增加，为复杂新兴疾病开发有效框架面临挑战，特别是长新冠这种新兴疾病。

Method: 开发并评估六种RAG语料库配置，使用LLM作为评判框架，在忠实度、相关性和全面性指标上评估，使用LongCOVID-CQ专家生成临床问题数据集。

Result: 结合临床指南和高质量系统评价的RAG配置始终优于单一指南方法和大型文献数据库，在平衡专业共识和原始文献方面表现最优。

Conclusion: 对于新兴疾病，基于精选二次评价的检索在狭窄共识文档和未过滤原始文献之间提供了最佳平衡，支持临床决策同时避免信息过载和过度简化的指导。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [30] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个7B参数的深度研究代理，通过统一的强化学习框架构建，在10个深度研究基准测试中达到7B规模代理的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具增强的大型语言模型的研究代理存在检索浅层、对齐指标弱和工具使用行为脆弱等问题，需要开发更鲁棒、对齐和可扩展的深度研究代理。

Method: 采用无标注的AI反馈强化学习框架，使用基于LLM的奖励信号优化策略，结合思维链驱动的多调用推理框架，实现自我验证和工具故障自适应恢复。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模深度研究代理中达到最先进性能。

Conclusion: 精心的强化学习和推理设计可以产生高效、有弹性和研究级的AI代理。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>
